<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>data401-nlp - Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="data401-nlp - Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)">
<meta property="og:description" content="Interactive NLP course labs for Jupyter, Colab, and Deepnote">
<meta property="og:site_name" content="data401-nlp">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">data401-nlp</span>
    </a>
  </div>
        <div class="quarto-navbar-tools">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./eda_spacy_part2.html">Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">README</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_core.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">00_core.html</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 1 - Introduction to the SpaCy Pipeline</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_spacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2 - Leveraging SpaCy for Comparative Textual EDA (Part 1)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_spacy_part2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 3 Skills: Regular Expressions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zero_frequency_compression_unigrams_bigrams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Zero-Frequency Problem in Text Compression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-sentiment_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 4 - Sparse vectors and Sentiment Analysis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_helpers_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">99_helpers_test.html</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./platform_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Platform Compatibility Tests</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">helpers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Environment Detection helper (env.py)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLM chat helper (llm.py)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/submit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notebook Submission Helper (submit.py)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/spacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">spaCy Model Helper (spacy.py)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#load-libraries-and-models" id="toc-load-libraries-and-models" class="nav-link active" data-scroll-target="#load-libraries-and-models">Load libraries and models</a></li>
  <li><a href="#set-up-the-dataframe-from-last-week" id="toc-set-up-the-dataframe-from-last-week" class="nav-link" data-scroll-target="#set-up-the-dataframe-from-last-week">Set up the Dataframe from last week</a></li>
  <li><a href="#preface---distributional-analysis" id="toc-preface---distributional-analysis" class="nav-link" data-scroll-target="#preface---distributional-analysis">Preface - Distributional Analysis</a></li>
  <li><a href="#a---word-association-patterns" id="toc-a---word-association-patterns" class="nav-link" data-scroll-target="#a---word-association-patterns">A - Word Association Patterns</a>
  <ul>
  <li><a href="#collocations" id="toc-collocations" class="nav-link" data-scroll-target="#collocations">Collocations</a></li>
  <li><a href="#word-associations-summary" id="toc-word-associations-summary" class="nav-link" data-scroll-target="#word-associations-summary">Word Associations Summary</a></li>
  </ul></li>
  <li><a href="#b---parts-of-speech-patterns" id="toc-b---parts-of-speech-patterns" class="nav-link" data-scroll-target="#b---parts-of-speech-patterns">B - Parts-of-Speech Patterns</a></li>
  <li><a href="#c---named-entity-recognition" id="toc-c---named-entity-recognition" class="nav-link" data-scroll-target="#c---named-entity-recognition">C - Named Entity Recognition</a>
  <ul>
  <li><a href="#interpreting-these-results" id="toc-interpreting-these-results" class="nav-link" data-scroll-target="#interpreting-these-results">Interpreting these results</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection">Reflection</a></li>
  </ul></li>
  <li><a href="#d---llm-analysis" id="toc-d---llm-analysis" class="nav-link" data-scroll-target="#d---llm-analysis">D - LLM Analysis</a>
  <ul>
  <li><a href="#d.1---hashtags" id="toc-d.1---hashtags" class="nav-link" data-scroll-target="#d.1---hashtags">D.1 - Hashtags</a>
  <ul class="collapse">
  <li><a href="#reflection-1" id="toc-reflection-1" class="nav-link" data-scroll-target="#reflection-1">Reflection</a></li>
  </ul></li>
  <li><a href="#d.2-stance-detection" id="toc-d.2-stance-detection" class="nav-link" data-scroll-target="#d.2-stance-detection">D.2 Stance Detection</a>
  <ul class="collapse">
  <li><a href="#reflection-2" id="toc-reflection-2" class="nav-link" data-scroll-target="#reflection-2">Reflection</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#lab-summary" id="toc-lab-summary" class="nav-link" data-scroll-target="#lab-summary">Lab Summary</a></li>
  <li><a href="#lab-reflection" id="toc-lab-reflection" class="nav-link" data-scroll-target="#lab-reflection">Lab Reflection</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/su-dataAI/data401-nlp/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>In the last lab you learned about: - Text preprocessing including vocabulary, frequency counts, and analyses. - Raw frequency, normalization, and relative measures for comparing different groups. - Dispersion showing where language appears in the corpus. - Distributional patterns - observable in visualizations like KWIC.</p>
<p>Objectives: - Analyze <strong>distributional patterns</strong> in text using normalized frequency counts to <strong>compare language use across groups</strong>. - Operationalize <strong>word association through bigrams and collocations</strong>, and explain how association measures differ from raw frequency. - Compute and <strong>interpret Pointwise Mutual Information (PMI) to identify exclusive or slogan-like word pairings</strong>, while understanding its bias toward rare events. - Apply linguistic annotation with spaCy (POS tagging and NER) to <strong>explore grammatical and entity-level patterns in text</strong>. - Evaluate the <strong>limits of linguistic annotation on social media data</strong>, recognizing noise introduced by hashtags, emojis, and non-standard syntax. - Use <strong>sampling and normalization</strong> responsibly to make comparisons across corpora of different sizes. - <strong>Reflect on how statistical association methods</strong> connect to modern NLP and LLMs, particularly how embeddings internalize frequency and surprise signals.</p>
<p><strong>Useful References:</strong></p>
<ul>
<li>Brezina, Vaclav (2018). <a href="http://corpora.lancs.ac.uk/stats/materials.php">Statistics in Corpus Linguistics</a>: A Practical Guide.</li>
<li><a href="https://spacy.io/api">SpaCy API</a>. https://spacy.io/api</li>
<li><a href="https://socialsci.libretexts.org/Bookshelves/Linguistics/Analyzing_Meaning_-_An_Introduction_to_Semantics_and_Pragmatics_(Kroeger)/16%3A_Modality/16.01%3A_16.1_Possibility_and_necessity">Possibility and Necessity. Chapter 16-16.2</a> in Analyzing Meaning - An Introduction to Semantics and Pragmatics (Kroeger)</li>
</ul>
<p>Note about this lab: your focus should be on speculating and introspecting on observed phenomena. You’ll be asked to consider how or why an LLM can do things that pose challenges for traditional NLP and statistical methods. As before, think and respond before asking an AI model for insight. We’ll go much more deeply into how things work as we go in this class.</p>
<p>While this lab is labeled EDA part 2, non of it is strictly needed by your EDA. This lab should stimulate your thinking about EDA beyond reporting relative frequencies.</p>
<div id="2ccf4b23-f946-4f1c-9fab-fc107fad12d6" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If you are colab, un-comment the pip install below.</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This will not be necessary on DeepNote or your local installation</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install data401_nlp</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="load-libraries-and-models" class="level2">
<h2 class="anchored" data-anchor-id="load-libraries-and-models">Load libraries and models</h2>
<div id="4ce5e88f" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Environment (must run first)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> data401_nlp</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data401_nlp.__version__)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Core libs</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0.6
0.0.7</code></pre>
</div>
</div>
<div id="1896d0dc-cd41-4e31-bea0-3430f60f8013" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This checks to make sure your SUBMIT_API_KEY is present</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SUBMIT_API_KEY present:"</span>, <span class="bu">bool</span>(os.getenv(<span class="st">"SUBMIT_API_KEY"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a0687314-d114-41eb-bd6f-ed0829b2a2c4" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.env <span class="im">import</span> load_env</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.llm <span class="im">import</span> make_chat, LLM_MODELS</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>load_env()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>DEFAULT_MODEL <span class="op">=</span> LLM_MODELS[<span class="dv">0</span>] <span class="co"># Assumes Claude key... adjust if needed.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Selected model:"</span>, DEFAULT_MODEL)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> make_chat(DEFAULT_MODEL)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Selected model: anthropic/claude-sonnet-4-5</code></pre>
</div>
</div>
<div id="adec9d3b-99bb-4a2c-a28f-57adbbb5efbb" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># You must explicitly opt in, if you want to use and run cells with external LLM calls</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>ENABLE_LLM <span class="op">=</span> <span class="va">True</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1ed74821-f651-4d5b-b7fd-e412d91af5ef" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_status(chat_fn):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ENABLE_LLM:</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"disabled"</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        chat_fn(<span class="st">"ping"</span>, max_tokens<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"ready"</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"misconfigured"</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LLM status:"</span>, llm_status(chat))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>LLM status: ready</code></pre>
</div>
</div>
<div id="504e801f-6c79-44c7-83ed-11947de37e3b" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_and_test_chat(model_name):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ENABLE_LLM:</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span>  <span class="co"># silent no-op</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        chat <span class="op">=</span> make_chat(model_name)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        chat(<span class="st">"ping"</span>, max_tokens<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> chat</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span>  <span class="co"># silent fail</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="48689f00-b1bf-4781-bf75-502891443f37" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_available():</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ENABLE_LLM <span class="kw">and</span> chat <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="set-up-the-dataframe-from-last-week" class="level2">
<h2 class="anchored" data-anchor-id="set-up-the-dataframe-from-last-week">Set up the Dataframe from last week</h2>
<div id="7cab6214-9733-4532-83b5-3b87a2fe1a8d" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.spacy <span class="im">import</span> ensure_spacy_model</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_nlp():</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ensure_spacy_model(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_csv(<span class="st">"data/covidisreal_OR_wearamask_hashtag.csv"</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">"data/covidhoax_OR_notomasks_hashtag.csv"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">'group'</span>] <span class="op">=</span> <span class="st">'promask'</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>df2[<span class="st">'group'</span>] <span class="op">=</span> <span class="st">'antimask'</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1, df2], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>).head(<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">created_date</th>
<th data-quarto-table-cell-role="th">hashtags</th>
<th data-quarto-table-cell-role="th">num_hashtags</th>
<th data-quarto-table-cell-role="th">tweet_length</th>
<th data-quarto-table-cell-role="th">tweet_text</th>
<th data-quarto-table-cell-role="th">group</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2020-08-31 02:08:31</td>
<td>2020sucks trumpisscar ihateithere wearamask</td>
<td>4</td>
<td>90</td>
<td>#2020sucks #trumpisscar #ihateithere #wearamas...</td>
<td>promask</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2020-08-31 02:07:58</td>
<td>antimasker antimasking DOJ pandemic</td>
<td>4</td>
<td>137</td>
<td>This is probably one of the most ridiculous of...</td>
<td>promask</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2020-08-31 02:07:28</td>
<td>wearamask maskuphoosiers</td>
<td>2</td>
<td>69</td>
<td>Just, like, do it. #wearamask #maskuphoosiers ...</td>
<td>promask</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2020-08-31 02:07:16</td>
<td>NaN</td>
<td>0</td>
<td>140</td>
<td>So one day a guy will be bragging how he didn’...</td>
<td>promask</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5000</td>
<td>2020-08-31 02:03:58</td>
<td>COVID19 covidhoax</td>
<td>2</td>
<td>125</td>
<td>6% Of all #COVID19 Deaths were from just the v...</td>
<td>antimask</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5001</td>
<td>2020-08-31 02:03:35</td>
<td>COVID19</td>
<td>1</td>
<td>140</td>
<td>#COVID19 is a hoax. Fuck masks. If you don’t ...</td>
<td>antimask</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5002</td>
<td>2020-08-31 02:02:55</td>
<td>COVID19 CovidHoax</td>
<td>2</td>
<td>148</td>
<td>@ProfPCDoherty There was no need to shut the b...</td>
<td>antimask</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5003</td>
<td>2020-08-31 02:01:45</td>
<td>CovidHoax</td>
<td>1</td>
<td>140</td>
<td>#CovidHoax is over... Let's OPEN the world and...</td>
<td>antimask</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="dfe9e29f-c58e-48d8-8ab2-d9a0e73b8d3e" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_text(text):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">""</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text.lower().replace(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>, <span class="st">" "</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_tweet(text):</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    nlp <span class="op">=</span> get_nlp()</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nlp(clean_text(text))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8f91067b-c66d-48d8-9395-c01e4e3b299a" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"clean_text"</span>] <span class="op">=</span> df[<span class="st">"tweet_text"</span>].<span class="bu">apply</span>(clean_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d587c92f-07ff-49a2-b77d-607d300bc0aa" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>).head(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">created_date</th>
<th data-quarto-table-cell-role="th">hashtags</th>
<th data-quarto-table-cell-role="th">num_hashtags</th>
<th data-quarto-table-cell-role="th">tweet_length</th>
<th data-quarto-table-cell-role="th">tweet_text</th>
<th data-quarto-table-cell-role="th">group</th>
<th data-quarto-table-cell-role="th">clean_text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2020-08-31 02:08:31</td>
<td>2020sucks trumpisscar ihateithere wearamask</td>
<td>4</td>
<td>90</td>
<td>#2020sucks #trumpisscar #ihateithere #wearamas...</td>
<td>promask</td>
<td>#2020sucks #trumpisscar #ihateithere #wearamas...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2020-08-31 02:07:58</td>
<td>antimasker antimasking DOJ pandemic</td>
<td>4</td>
<td>137</td>
<td>This is probably one of the most ridiculous of...</td>
<td>promask</td>
<td>this is probably one of the most ridiculous of...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2020-08-31 02:07:28</td>
<td>wearamask maskuphoosiers</td>
<td>2</td>
<td>69</td>
<td>Just, like, do it. #wearamask #maskuphoosiers ...</td>
<td>promask</td>
<td>just, like, do it. #wearamask #maskuphoosiers ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5000</td>
<td>2020-08-31 02:03:58</td>
<td>COVID19 covidhoax</td>
<td>2</td>
<td>125</td>
<td>6% Of all #COVID19 Deaths were from just the v...</td>
<td>antimask</td>
<td>6% of all #covid19 deaths were from just the v...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5001</td>
<td>2020-08-31 02:03:35</td>
<td>COVID19</td>
<td>1</td>
<td>140</td>
<td>#COVID19 is a hoax. Fuck masks. If you don’t ...</td>
<td>antimask</td>
<td>#covid19 is a hoax. fuck masks. if you don’t ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5002</td>
<td>2020-08-31 02:02:55</td>
<td>COVID19 CovidHoax</td>
<td>2</td>
<td>148</td>
<td>@ProfPCDoherty There was no need to shut the b...</td>
<td>antimask</td>
<td>@profpcdoherty there was no need to shut the b...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
</section>
<section id="preface---distributional-analysis" class="level2">
<h2 class="anchored" data-anchor-id="preface---distributional-analysis">Preface - Distributional Analysis</h2>
<p>Section A on word association patterns will introduce measures that are not intended to be part of your EDA project. Instead, it sets up how we use statistics to tease out patterns in language. These patterns are the thread that connect linguistic analysis, to traditional NLP, to modern LLMs. We’ll come back to the same statistical principles repeatedly through this course.</p>
<p><strong>Association patterns</strong> make explicit distributional analysis at a very local level. <strong>Distributional analysis</strong> rest on a single, core idea: <em>A word’s meaning (or function) is reflected in how it is distributed across contexts.</em> Two groups may share the use of a set of words, and yet those words take on different meaning in different contexts.</p>
<p>For example, in the promask context: ‘mask’ occurs with words such as protect, safe, others, community, health. In the antimask context, it appears with words such as forced, control, lie, hoax, freedom. Although both groups use the word “mask” frequently, its meaning is shaped by the associative context in which it appears. Neither is right nor wrong – this is an observation about how language is used… which is observable in the data. <strong>Meaning is not just about which words are used, but about the contexts in which they are used.</strong></p>
<p>In section A, we’ll use this idea to observe differences in how language is used between two groups.</p>
</section>
<section id="a---word-association-patterns" class="level2">
<h2 class="anchored" data-anchor-id="a---word-association-patterns">A - Word Association Patterns</h2>
<p>Before we move on to playing with other spaCy pipeline capabilities on this data, let’s talk about the utility of <strong>word associations</strong> to reveal patterns in data. These techniques are used to reveal patterns in language. Very similar statistical methods are used to build word embeddings, which we’ll explore soon. Embeddings are a key tool for LLMs.</p>
<p>What I hope you draw from this is that we have more tools at our disposal for looking at patterns in language data when it comes to squishy questions around the <strong>social use</strong> of language such as attitude, opinion, ideology, power, etc. If statistics excites you, this is an interesting area of study and could be valuable tool in investigative journalism, mental health, social justice, etc.</p>
<p>At the heart of of statistical methods for studying language use is co-occurence and frequencies of words and word patterns.</p>
<p>A basic way to study <strong>co-occurrence patterns</strong> is through <strong>bigrams</strong>, which are adjacent pairs of tokens. Bigrams define what counts as a co-occurrence.</p>
<p>Once we have bigram counts, we can ask whether two tokens appear together more often than we would expect by chance, given their individual frequencies.</p>
<p>The underlying assumption is token independence: if two words are unrelated, the probability of seeing them together should be predictable from their unigram frequencies. Association measures test departures from this assumption. Thus association measures evaluate whether that co-occurence is statistically meaningful.</p>
<p>Statistical such as Pointwise Mutual Information (PMI), t-score, or log-likelihood quantify this likelihood of association by comparing observed bigram frequencies to expected frequencies under an independence assumption.</p>
<p>While this lab is too long to go into depth about any of these inferential techniques, let’s focus on normalizing our frequencies and incorporate sampling. If your data set is large, this is what you will need to do. Below, we’ll reduce the number of documents to 1000. Sampling is a great way to work out ideas before you do a full analysis.</p>
<div id="0163e5f4-4749-4483-a94b-3cc1f067f375" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"token_count"</span>] <span class="op">=</span> df[<span class="st">"clean_text"</span>].<span class="bu">apply</span>(</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> text: <span class="bu">len</span>(</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        [tok <span class="cf">for</span> tok <span class="kw">in</span> nlp(text) <span class="cf">if</span> <span class="kw">not</span> tok.is_space]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
</div>
<div id="68c03d0b-458a-41dc-a29a-2bcb524a5364" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample rows *with* group so alignment is preserved</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>MAX_DOCS <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>df_s <span class="op">=</span> (</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    df[[<span class="st">"clean_text"</span>, <span class="st">"group"</span>, <span class="st">"token_count"</span>]]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    .dropna(subset<span class="op">=</span>[<span class="st">"clean_text"</span>, <span class="st">"group"</span>])</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    .sample(n<span class="op">=</span><span class="bu">min</span>(MAX_DOCS, <span class="bu">len</span>(df)), random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>docs_s <span class="op">=</span> <span class="bu">list</span>(nlp.pipe(df_s[<span class="st">"clean_text"</span>], batch_size<span class="op">=</span><span class="dv">1000</span>))</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>docs_promask <span class="op">=</span> [d <span class="cf">for</span> d, g <span class="kw">in</span> <span class="bu">zip</span>(docs_s, df_s[<span class="st">"group"</span>]) <span class="cf">if</span> g <span class="op">==</span> <span class="st">"promask"</span>]</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>docs_antimask <span class="op">=</span> [d <span class="cf">for</span> d, g <span class="kw">in</span> <span class="bu">zip</span>(docs_s, df_s[<span class="st">"group"</span>]) <span class="cf">if</span> g <span class="op">==</span> <span class="st">"antimask"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
</div>
<p>Below, let’s recall how we normalize frequencies to compare patterns across groups. I played around with removing things we’re less interested in for this analysis such as punctuation and spaces. Freel free to play around with this, as well! When you filter out text like this, you must report that you did so. There will be an effect on your both word counts and statistics.</p>
<div id="67f9eef4" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get word frequencies</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_word_freqs(texts):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> Counter()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        doc <span class="op">=</span> nlp(text)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> tok <span class="kw">in</span> doc:</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> tok.is_punct <span class="kw">and</span> <span class="kw">not</span> tok.is_space:</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>                freqs[tok.text.lower()] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>promask_freqs <span class="op">=</span> get_word_freqs(df[df[<span class="st">'group'</span>]<span class="op">==</span><span class="st">'promask'</span>][<span class="st">'clean_text'</span>])</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>antimask_freqs <span class="op">=</span> get_word_freqs(df[df[<span class="st">'group'</span>]<span class="op">==</span><span class="st">'antimask'</span>][<span class="st">'clean_text'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
</div>
<div id="7f20f8c6" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's compare by frequency by normalizing per 1000 tokens</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get totals first</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>total_promask <span class="op">=</span> <span class="bu">sum</span>(promask_freqs.values())</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>total_antimask <span class="op">=</span> <span class="bu">sum</span>(antimask_freqs.values())</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>norm_promask <span class="op">=</span> {w: (f <span class="op">/</span> total_promask) <span class="op">*</span> <span class="dv">1000</span> <span class="cf">for</span> w, f <span class="kw">in</span> promask_freqs.items()}</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>norm_antimask <span class="op">=</span> {w: (f <span class="op">/</span> total_antimask) <span class="op">*</span> <span class="dv">1000</span> <span class="cf">for</span> w, f <span class="kw">in</span> antimask_freqs.items()}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ccce194c-966b-4f58-b05c-5ce76d1b3d01" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    Counter(norm_promask).most_common(<span class="dv">20</span>),</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"token"</span>, <span class="st">"rate_per_1000"</span>]</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">token</th>
<th data-quarto-table-cell-role="th">rate_per_1000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>wearamask</td>
<td>26.855802</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>the</td>
<td>24.659245</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>to</td>
<td>22.404883</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>a</td>
<td>20.358617</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>and</td>
<td>14.901906</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>i</td>
<td>12.728471</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>you</td>
<td>12.497254</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>of</td>
<td>11.768922</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>in</td>
<td>11.086833</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>is</td>
<td>10.867178</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>mask</td>
<td>10.138846</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>for</td>
<td>9.595487</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>it</td>
<td>8.809350</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>this</td>
<td>8.057897</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>are</td>
<td>7.109909</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>we</td>
<td>6.936496</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>on</td>
<td>5.976948</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>that</td>
<td>5.826657</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>your</td>
<td>5.410467</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>do</td>
<td>5.329541</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="a741ca27-4e28-42d1-b41e-bf6fe861bb64" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    Counter(norm_antimask).most_common(<span class="dv">20</span>),</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"token"</span>, <span class="st">"rate_per_1000"</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">token</th>
<th data-quarto-table-cell-role="th">rate_per_1000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>the</td>
<td>39.600619</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>covidhoax</td>
<td>29.025454</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>to</td>
<td>19.040923</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>is</td>
<td>18.112783</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>a</td>
<td>15.609619</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>of</td>
<td>14.259598</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>and</td>
<td>11.897061</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>you</td>
<td>11.531430</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>this</td>
<td>11.503305</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>in</td>
<td>11.137674</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>are</td>
<td>9.872029</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>it</td>
<td>9.309520</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>i</td>
<td>8.465757</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>that</td>
<td>8.409506</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>for</td>
<td>7.875123</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>they</td>
<td>6.581353</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>all</td>
<td>6.131346</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>not</td>
<td>5.878217</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>we</td>
<td>5.681339</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>have</td>
<td>5.343833</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>The normalized word frequencies above are included to reinforce how corpus size and pre-processing affects comparisons; the <strong>collocation statistics below rely instead on raw unigram and bigram counts</strong>, which are required for computing association measures like PMI.</p>
<p>Frequency tells us which words are common, but it does not tell us which words tend to appear together. Two words can be frequent without being meaningfully related. To capture relationships between words, we need to look at co-occurrence.</p>
<section id="collocations" class="level3">
<h3 class="anchored" data-anchor-id="collocations">Collocations</h3>
<p>While comparing termlists against other term lists is interesting, let’s shift to looking at the co-occurence of words with other words. The simplest way to do this is to look at bigrams.</p>
<p>Bigrams in our context are <strong>pairs of words or tokens</strong>. Here’s an example below. We’ll need to use bigrams and unigrams (single word/token frequencies) for some of the statistics below.</p>
<div id="61549e8b" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(<span class="st">"I love wearing masks"</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>bigrams <span class="op">=</span> [(doc[i].text, doc[i<span class="op">+</span><span class="dv">1</span>].text) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(doc)<span class="op">-</span><span class="dv">1</span>)]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bigrams)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully
[('I', 'love'), ('love', 'wearing'), ('wearing', 'masks')]</code></pre>
</div>
</div>
<p><strong>Collocations</strong> are sequences of words that co-occur unusually frequently and that, over time, start to take on a meaning or a salience that resists the token sequence being broken down into its individual parts.</p>
<p>Often words that start off as collocations become increasingly fixed as lexical items, especially when they are used with great frequency. This process is called <strong>lexicalization</strong>.</p>
<p>For example, as noun-noun collocations such as ‘ice chest’, ‘data base’ or ‘war game’ become increasingly cemented in the vocabulary of English, even native speakers pause to wonder ’Does ice-chest have a hyphen? Is database all one word? <strong>That is a sign of the increasing lexicalization of the collocation.</strong></p>
<p>In some cases, you can introspect about whether a collocation has a non-compositional meaning by trying to substitute it with a single synonym, such as ‘cooler’ for ‘icechest’ or ‘assassin’ for ‘hit man’ (or is that hitman?) Collocations can consist of numerous combinations of parts-of-speech, but most have in common the somewhat idiosyncratic nature of their meaning, which can exhibit differing degrees of compositionality.</p>
<p>This is a challenge for second language learners, and websites such as 7esl devote some effort to helping people master them. For the purposes of natural language processing, when setting out to answer an analytic question with natural language data, it is important to consider whether and to what degree identifying collocations is relevant and necessary. How you treat collocations can affect everything from first order frequency counts to the quality of word embeddings, which are so widely used in contemporary machine learning.</p>
<p><strong>n-grams</strong> (also written <strong>ngrams</strong>), are collcations. We’ll talk about this term many times throughout the course, because n-grams are so central to language modeling in NLP. The <em>n</em> in n-gram is meant to represent a variable of any length. The gram in n-gram is a graphical representation of some chunk of language, which might be characters, morphemes, tokens, or words. Some of the shorter n-grams have special names, such as bigram or trigram, which are 2-grams and 3-grams, respectively.</p>
<p>Collocation measures of words are a kind of <strong>association measure</strong> that calculates the strength of association between words. There are many different association measures, but they all work on the same basic principle: they compare the observed frequency of a pair of words with the expected.</p>
<p>Useful to data scientists are the collocation graphs. Collocation graphs visually map which words commonly appear together in language. By treating words as nodes and their relationships as edges, they help us see patterns of meaning, usage, and discourse structure.</p>
<p><img src="images/collocation-graph.png" class="img-fluid"></p>
<p>For collocation analysis (word associations within a corpus), these are fairly typical statistics that we can use. I won’t go into how these are calculated, since this is just a demonstration.</p>
<p>There are a number of different statistics. To choose one, you have to define the type of collocation that you are interested in. Here is a chart from page 74 in Brezina’s “Statistics in Corpus Linguistics” book.</p>
<p><img src="images/freq-exclusivity-scale.png" class="img-fluid"></p>
<p>This image highlights that some terms occur more frequently together, and some words predominantly occur only with one another.</p>
<p>All of these tests start with the same idea - what gets weighted: surprise vs frequency. They all compare observed co-occurence to expected co-occurence under independence. But they differ in how much they pernalize or reward rare events.</p>
<p>We’ll look at PMI, in particular. It’s the measure up in the top left corner labeled as MI (Mutual Information).</p>
<p>PMI answers a specific question: Are these two words appearing together more often than we would expect, given how often they appear individually?</p>
<p><strong>PMI (Pointwise Mutual Information)</strong> captures how much more likely words co-occur than by chance (strength of association). It measures how <em>surprising</em> the co-occurence of x and y are. It favors rare, but exclusive pairs. For example, a bigram occuring even once can get a very high PMI.</p>
<p><span class="math display">\[
PMI(x,y)=\log \frac{P(x,y)}{P(x)P(y)}
\]</span></p>
<div id="5876d93e-346a-4b4b-8c40-9d55b7ce6f2f" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_filtered_tokens(docs):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        tok.text.lower()</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> doc <span class="kw">in</span> docs</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> tok <span class="kw">in</span> doc</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> tok.is_alpha <span class="kw">and</span> <span class="kw">not</span> tok.is_stop</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>tokens_promask <span class="op">=</span> extract_filtered_tokens(docs_promask)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>tokens_antimask <span class="op">=</span> extract_filtered_tokens(docs_antimask)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ef33ec75" class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_bigrams(tokens):</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Count bigrams from a pre-filtered token sequence.</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Assumes tokens are already lowercased, alphabetic,</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">    and stopwords have been removed.</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Counter(<span class="bu">zip</span>(tokens, tokens[<span class="dv">1</span>:]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f6474a89-cc64-480b-8454-4c281bec9acf" class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>bigrams_promask <span class="op">=</span> count_bigrams(tokens_promask)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>bigrams_antimask <span class="op">=</span> count_bigrams(tokens_antimask)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2e7aae09-9ff1-4941-9c36-38d71ac9c084" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 10 bigrams — promask"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (w1, w2), c <span class="kw">in</span> bigrams_promask.most_common(<span class="dv">10</span>):</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w1<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>w2<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Top 10 bigrams — antimask"</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (w1, w2), c <span class="kw">in</span> bigrams_antimask.most_common(<span class="dv">10</span>):</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w1<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>w2<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 10 bigrams — promask
wear mask: 35
wearing mask: 22
face mask: 14
writingcommunity stayathomesavelives: 13
stayathomesavelives wearamask: 13
mask wearamask: 13
wearing masks: 10
wearamask wearadamnmask: 9
thanks following: 8
wearamask wearamask: 8

Top 10 bigrams — antimask
covidhoax plandemic: 10
plandemic covidhoax: 7
covid covidhoax: 6
covidhoax covidhoax: 6
covidhoax forced: 5
forced quarantine: 5
quarantine camps: 5
camps operating: 5
operating bc: 5
bc canada: 5</code></pre>
</div>
</div>
<div id="32fbd2af" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_unigrams(tokens):</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Count unigrams from a pre-filtered token sequence.</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Must match the token criteria used for bigrams.</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Counter(tokens)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Unigrams derived from the SAME tokens as bigrams</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>unigrams_promask <span class="op">=</span> count_unigrams(tokens_promask)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>unigrams_antimask <span class="op">=</span> count_unigrams(tokens_antimask)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># We can test this!</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span>(bigrams_promask).issubset(</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    {(w1, w2) <span class="cf">for</span> w1 <span class="kw">in</span> unigrams_promask <span class="cf">for</span> w2 <span class="kw">in</span> unigrams_promask}</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>True</code></pre>
</div>
</div>
<div id="0c3dd381" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_pmi(bigram_counts, unigram_counts, min_freq<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculate PMI for bigrams given aligned unigram counts.</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Assumes both were derived from the same token stream.</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">sum</span>(bigram_counts.values())</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (w1, w2), count <span class="kw">in</span> bigram_counts.items():</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> count <span class="op">&gt;=</span> min_freq <span class="kw">and</span> w1 <span class="kw">in</span> unigram_counts <span class="kw">and</span> w2 <span class="kw">in</span> unigram_counts:</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>            pmi <span class="op">=</span> math.log2(</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>                (count <span class="op">*</span> N) <span class="op">/</span> (unigram_counts[w1] <span class="op">*</span> unigram_counts[w2])</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>            results.append(((w1, w2), pmi, count))</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sorted</span>(results, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PMI using the already-aligned counts</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>pmi_promask <span class="op">=</span> calculate_pmi(</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    bigrams_promask,</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    unigrams_promask,</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    min_freq<span class="op">=</span><span class="dv">5</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>pmi_promask[:<span class="dv">20</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[(('wakeup', 'lied'), 9.836839359748716, 5),
 (('trying', 'understand'), 9.421801860469873, 6),
 (('understand', 'graph'), 9.421801860469873, 6),
 (('social', 'distancing'), 9.09987376558251, 5),
 (('writingcommunity', 'stayathomesavelives'), 8.72136214232878, 13),
 (('follow', 'writingcommunity'), 8.043290237216143, 5),
 (('following', 'writingcommunity'), 7.84689302441264, 6),
 (('stay', 'safe'), 7.633899301078441, 8),
 (('thanks', 'following'), 7.438808285775562, 8),
 (('thanks', 'follow'), 7.220167999300222, 5),
 (('wearing', 'masks'), 4.894324854409477, 10),
 (('wear', 'mask'), 4.70265754339091, 35),
 (('face', 'masks'), 4.608020669252835, 6),
 (('wearing', 'mask'), 4.557897189826999, 22),
 (('face', 'mask'), 4.3564819022568715, 14),
 (('stayathomesavelives', 'wearamask'), 4.046762429122948, 13),
 (('people', 'wearing'), 3.926746332101854, 5),
 (('wear', 'masks'), 3.6322682154995127, 6),
 (('wearamask', 'wearadamnmask'), 3.516247712424168, 9),
 (('people', 'wear'), 3.4016552873580963, 5)]</code></pre>
</div>
</div>
<p>Recall PMI is driven by exclusivity… which are the terms that nearly always occur with one another? ‘Wakeup’ might occur infrequently, but when it does it appears next to lied (e.g., “wakeup, you’ve been lied to.” Since we’ve removed stop words – the proximity of these two words is more apparent.</p>
<p>The highest-PMI pairs are not necessarily the most frequent or the most important topics. Instead, they often reveal formulaic or slogan-like language—phrases that occur rarely, but almost always together.</p>
<div id="37900f50-be46-4de3-8cbb-027066834bea" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>pmi_promask <span class="op">=</span> calculate_pmi(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    bigrams_promask,</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    unigrams_promask,</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    min_freq<span class="op">=</span><span class="dv">8</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>pmi_promask[:<span class="dv">20</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[(('writingcommunity', 'stayathomesavelives'), 8.72136214232878, 13),
 (('stay', 'safe'), 7.633899301078441, 8),
 (('thanks', 'following'), 7.438808285775562, 8),
 (('wearing', 'masks'), 4.894324854409477, 10),
 (('wear', 'mask'), 4.70265754339091, 35),
 (('wearing', 'mask'), 4.557897189826999, 22),
 (('face', 'mask'), 4.3564819022568715, 14),
 (('stayathomesavelives', 'wearamask'), 4.046762429122948, 13),
 (('wearamask', 'wearadamnmask'), 3.516247712424168, 9),
 (('mask', 'wearamask'), 0.7814178626019529, 13),
 (('wearamask', 'wearamask'), -1.328277002223977, 8)]</code></pre>
</div>
</div>
<p>You can play with min_freq to see how it changes as you increase and decrease it. Because we’re working with a small sample of texts, we don’t see quite as much as we might on the full corpus.</p>
<p>Lest you think we must rely on sophisticated NLP <em>tools</em> using for studying study language use - here are a couple of examples using sophisticated <em>statistical methods</em> to study language use.</p>
<ol type="1">
<li>Islentyeva (2023) — <a href="https://www.lancaster.ac.uk/fass/journals/cadaad/wp-content/uploads/2023/06/Islentyeva.pdf?utm_source=chatgpt.com">British Media Representations of EU Migrants</a></li>
</ol>
<p>A corpus-assisted analysis of two specialised corpora (500 articles each) across mainstream British newspapers before and after the Brexit referendum.</p>
<p>It traces linguistic patterns and ideological bias in how European migrants were discussed, noting differences between left- and right-leaning outlet</p>
<ol start="2" type="1">
<li>Gabrielatos &amp; Baker et al.&nbsp;(2006/2007) — <a href="https://www.researchgate.net/publication/261708737_Representation_of_refugees_and_asylum_seekers_in_UK_newspapers_Towards_a_corpus-based_comparison_of_the_stance_of_tabloids_and_broadsheets">Tabloids vs.&nbsp;Broadsheets on Immigration</a></li>
</ol>
<p>Work presented at CADAAD 2006 and in later publications explores how refugees, asylum seekers, and immigrants are framed in UK newspapers, with a focus on contrasting broadsheets vs.&nbsp;tabloids.</p>
<p>The project uses collocation and frequency analysis within a corpus framework to quantify differences in stance and lexical choices.</p>
</section>
<section id="word-associations-summary" class="level3">
<h3 class="anchored" data-anchor-id="word-associations-summary">Word Associations Summary</h3>
<ul>
<li><strong>Bigrams operationalize co-occurrence</strong>, giving us a concrete unit for studying how words appear together in text.</li>
<li><strong>Association measures</strong> compare observed vs.&nbsp;expected frequencies under an assumption of independence, allowing us to distinguish meaningful patterns from chance.</li>
<li>PMI emphasizes surprise and exclusivity, often surfacing rare but rhetorically distinctive phrases or slogans.</li>
<li>No single measure is “correct” – interpretation depends on the analytic goal.</li>
</ul>
<p>In a couple of weeks, we’ll see that word embeddings implicitly learn both surprise and frequency signals at once and internalize these patterns across contexts. This allows them to generalize beyond fixed bigrams/trigrams… and as a result, they can recognize meaningful associations even when rare, indirect, or distributed.</p>
</section>
</section>
<section id="b---parts-of-speech-patterns" class="level2">
<h2 class="anchored" data-anchor-id="b---parts-of-speech-patterns">B - Parts-of-Speech Patterns</h2>
<p>So far, we’ve treated text primarily as sequences of tokens, asking which words tend to appear together and how strongly those associations depart from chance. Another way to surface structure in language is to step back from which words are used and look instead at how grammatical resources are distributed. <strong>It’s not only “words” or tokens that have distributional patterns – grammatical categories do, too!</strong></p>
<p>This is where linguistic annotation—specifically part-of-speech (POS) tagging—becomes useful. Rather than measuring association between specific lexical items, POS patterns let us examine higher-level distributional constructs, such as whether a group relies more on nouns versus verbs, descriptive adjectives versus evaluative ones, or personal pronouns versus impersonal constructions. In this section, we return to spaCy’s pipeline annotations to explore how grammatical patterns can complement word-level association analysis.</p>
<p>We won’t use POS for this EDA because it is not reliable on Twitter data. Tweets contain nonstandard spelling, emojis, hashtags, and fragmented syntax, which fall outside the data most POS taggers are trained on.</p>
<p>The spaCy POS tagger was primarily trained on newswire, magazines, blogs and other well formed, and cleaned texts. If your EDA is centered on this sort of text, POS may be useful in your EDA.</p>
<p>POS can be useful for examining: - NOUN density. How much is information-heavy vs opinion-heavy - ADJ frequency. Evaluative language - PRON patterns. Personal involvement</p>
<p>First, we’ll take a peek at how compute a POS distribution. Then we will play around with modal verbs. I hope that exploring patterns via POS gives you ideas about how to use these sorts of annotations.</p>
<div id="ce538744" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_pos_distribution(texts, nlp, allowed_pos<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute normalized POS tag distribution using batched spaCy processing.</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> allowed_pos <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>        allowed_pos <span class="op">=</span> {</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"NOUN"</span>, <span class="st">"PROPN"</span>, <span class="st">"VERB"</span>, <span class="st">"ADJ"</span>, <span class="st">"ADV"</span>,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"PRON"</span>, <span class="st">"DET"</span>, <span class="st">"ADP"</span>, <span class="st">"AUX"</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    pos_counts <span class="op">=</span> Counter()</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc <span class="kw">in</span> nlp.pipe(texts, batch_size<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> tok <span class="kw">in</span> doc:</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> tok.pos_ <span class="kw">in</span> allowed_pos:</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>                pos_counts[tok.pos_] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">sum</span>(pos_counts.values())</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {pos: count <span class="op">/</span> total <span class="cf">for</span> pos, count <span class="kw">in</span> pos_counts.items()}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6ce2ce17" class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>pos_dist_promask <span class="op">=</span> get_pos_distribution(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">'group'</span>] <span class="op">==</span> <span class="st">'promask'</span>][<span class="st">'clean_text'</span>], nlp</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>pos_dist_antimask <span class="op">=</span> get_pos_distribution(</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">'group'</span>] <span class="op">==</span> <span class="st">'antimask'</span>][<span class="st">'clean_text'</span>], nlp</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>pos_dist_promask, pos_dist_antimask</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>({'NOUN': 0.31143695766415874,
  'ADP': 0.08735051718171215,
  'PROPN': 0.11481818531383381,
  'PRON': 0.10053961214575936,
  'AUX': 0.0600751099091247,
  'ADV': 0.04566836283469411,
  'DET': 0.06581730091387995,
  'ADJ': 0.07186710929388995,
  'VERB': 0.14242684474294723},
 {'NOUN': 0.2847861563568064,
  'ADP': 0.08756966468577762,
  'PRON': 0.09951658096499061,
  'AUX': 0.07383686916895034,
  'ADV': 0.05055885703728793,
  'DET': 0.07907134279644056,
  'VERB': 0.13954490870462175,
  'ADJ': 0.08430581642393079,
  'PROPN': 0.10080980386119408})</code></pre>
</div>
</div>
<p>Because POS tagging is noisy on Twitter, small differences should be treated as suggestive patterns, not explanations.</p>
<p>If we’re just looking at proportionality of POS, a few patterns stand out:</p>
<ol type="1">
<li><p><strong>PROPN (proper nouns)</strong> — These are slightly more frequent in promask tweets. This <em>could</em> reflects more use of named entities.</p></li>
<li><p><strong>DET (determiners)</strong> and <strong>AUX (auxiliaries)</strong> — These are slightly more frequent in antimask tweets. We don’t know why, though may correlate with more declarative constructions.</p></li>
<li><p><strong>ADV (adverbs)</strong> and <strong>ADJ (adjectives)</strong> — Little differences across groups. This could suggest evaluative language is present in both groups. Evaluative language uses words and phrases to express judgment, opinion, or attitude (positive, negative, or neutral) about a topic, rather than just stating facts.</p></li>
</ol>
<p>POS tags capture surface grammatical categories, not meaning. On short, informal texts like tweets, POS distributions are especially sensitive to: - emoji and punctuation - hashtags and mentions - fragmented or non-standard syntax</p>
<p>For our analysis of twitter data, it is best treated as contextual, and not explanatory.</p>
<p>Now let’s look at the frequency of modal verbs. <strong>Modal verbs</strong> (typically auxiliary verbs) express modality—obligation, permission, or possibility—and often signal prescriptive or normative language.</p>
<p>We’ll look at several types of modality: - Strong obligation: must, need to - Weaker obligation: should, ought to - Prohibition: can’t, must not, shouldn’t</p>
<p>We could also consider imperative verbs (e.g., “wear!”, “stop!”, “wake up!”) — they’re prescriptive too.</p>
<div id="03579730" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>modals <span class="op">=</span> {</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'strong'</span>: [<span class="st">'must'</span>, <span class="st">'need'</span>, <span class="st">'have'</span>],  <span class="co"># "have to" needs special handling</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'medium'</span>: [<span class="st">'should'</span>, <span class="st">'ought'</span>],</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'weak'</span>: [<span class="st">'can'</span>, <span class="st">'could'</span>, <span class="st">'may'</span>, <span class="st">'might'</span>]</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a0c29237-e620-47dc-84a0-7edf3de31f58" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># build inverse mapping: lemma -&gt; strength</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>modal_to_strength <span class="op">=</span> {</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    modal: strength</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> strength, modal_list <span class="kw">in</span> modals.items()</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> modal <span class="kw">in</span> modal_list</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b5b93c71" class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_modal_counts_from_docs(docs):</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Count modal verbs from pre-parsed spaCy Docs.</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Restricts to AUX tokens to avoid false positives.</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    modal_counts <span class="op">=</span> Counter()</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc <span class="kw">in</span> docs:</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> tok <span class="kw">in</span> doc:</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> tok.pos_ <span class="op">==</span> <span class="st">"AUX"</span>:</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>                strength <span class="op">=</span> modal_to_strength.get(tok.lemma_.lower())</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> strength:</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>                    modal_counts[strength] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> modal_counts</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>modals_promask <span class="op">=</span> get_modal_counts_from_docs(docs_promask)</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>modals_antimask <span class="op">=</span> get_modal_counts_from_docs(docs_antimask)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>modals_promask, modals_antimask</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(Counter({'weak': 83, 'strong': 51, 'medium': 12}),
 Counter({'strong': 35, 'weak': 29, 'medium': 3}))</code></pre>
</div>
</div>
<div id="7a3998f1-74b2-454c-9bd3-7d5931b6a387" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(docs_promask), <span class="bu">len</span>(docs_antimask)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(714, 286)</code></pre>
</div>
</div>
<p>Because the two groups contain different numbers of tweets and tokens, raw counts are not directly comparable. To account for corpus size, we normalize modal counts per 1,000 tokens.</p>
<div id="b22c4d8c" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalized modal rates per 1000 tokens (same sample as modal counts)</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>total_promask_tokens <span class="op">=</span> df_s[df_s[<span class="st">"group"</span>] <span class="op">==</span> <span class="st">"promask"</span>][<span class="st">"token_count"</span>].<span class="bu">sum</span>()</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>total_antimask_tokens <span class="op">=</span> df_s[df_s[<span class="st">"group"</span>] <span class="op">==</span> <span class="st">"antimask"</span>][<span class="st">"token_count"</span>].<span class="bu">sum</span>()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>rate_strong_promask <span class="op">=</span> modals_promask.get(<span class="st">"strong"</span>, <span class="dv">0</span>) <span class="op">/</span> total_promask_tokens <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>rate_strong_antimask <span class="op">=</span> modals_antimask.get(<span class="st">"strong"</span>, <span class="dv">0</span>) <span class="op">/</span> total_antimask_tokens <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>rate_strong_promask, rate_strong_antimask</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(np.float64(3.3320266562132494), np.float64(5.868544600938967))</code></pre>
</div>
</div>
<p>Modal verbs appear in both corpora, which tells us that normative and possibility-oriented language is common across the discourse. When normalized by token count, strong modals (e.g.&nbsp;must, need (to), have (to)) occur more frequently in antimask tweets.</p>
<p>We can only make a cautious interpretation without pulling out KWIC and studying these tweets by eye - possibly, they represent more prescriptive framing. This sort of analysis could go into an EDA, though you can draw no conclusions without carefully examining the data.</p>
</section>
<section id="c---named-entity-recognition" class="level2">
<h2 class="anchored" data-anchor-id="c---named-entity-recognition">C - Named Entity Recognition</h2>
<p>So far, we’ve used token counts, collocations, and POS patterns to surface lexical and grammatical regularities in the corpus. Another common way to structure text analytically is to identify named entities—mentions of people, organizations, locations, and other real-world referents. This is the goal of Named Entity Recognition (NER).</p>
<p>As with POS tagging, spaCy’s NER component was trained primarily on edited, well-formed text, not social media, so we should expect noisy and imperfect results on Twitter data. Nonetheless, examining entity types and co-occurrence patterns is still useful for understanding what kinds of actors and institutions are being referenced and for practicing how entity-based analyses are performed. In this section, we briefly explore NER as another surface-level annotation that complements earlier frequency and association analyses.</p>
<p>Some patterns we might be interested in:</p>
<p>Aggregate across corpus - PERSON mentions (authorities, politicians, scientists) - ORG mentions (CDC, WHO, government agencies) - GPE (locations - local vs.&nbsp;national vs.&nbsp;international framing) - DATE (temporal framing differences)</p>
<p>How well might we be able to detect people mentions?</p>
<p>How well might we be able to find interesting patterns of co-occurence of entities? - Which entities appear together in tweets? - Example: “Fauci” + “lie” vs.&nbsp;“Fauci” + “expert” - Simple co-occurrence matrix for top 10 entities</p>
<p>Later, we will talk about how must evaluate the quality of NER. For now, let’s just practice using it.</p>
<div id="c262fe73" class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll speed this up by disabling a few components since we're only looking at entity types</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_entity_types(texts, nlp):</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    ent_counts <span class="op">=</span> Counter()</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc <span class="kw">in</span> nlp.pipe(</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    texts,</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    disable<span class="op">=</span>[<span class="st">"tagger"</span>, <span class="st">"parser"</span>, <span class="st">"lemmatizer"</span>]</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>        ent_counts.update(ent.label_ <span class="cf">for</span> ent <span class="kw">in</span> doc.ents)</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ent_counts</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>ents_promask <span class="op">=</span> get_entity_types(</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">"group"</span>] <span class="op">==</span> <span class="st">"promask"</span>][<span class="st">"tweet_text"</span>],</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    nlp</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>ents_antimask <span class="op">=</span> get_entity_types(</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">"group"</span>] <span class="op">==</span> <span class="st">"antimask"</span>][<span class="st">"tweet_text"</span>],</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>    nlp</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>ents_promask.most_common(<span class="dv">10</span>), ents_antimask.most_common(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>([('PERSON', 2304),
  ('CARDINAL', 1891),
  ('ORG', 1698),
  ('DATE', 911),
  ('MONEY', 818),
  ('GPE', 671),
  ('NORP', 211),
  ('TIME', 142),
  ('PRODUCT', 112),
  ('ORDINAL', 92)],
 [('PERSON', 943),
  ('ORG', 858),
  ('CARDINAL', 654),
  ('PRODUCT', 528),
  ('MONEY', 296),
  ('GPE', 291),
  ('DATE', 273),
  ('NORP', 155),
  ('PERCENT', 78),
  ('ORDINAL', 35)])</code></pre>
</div>
</div>
<p>We use <a href="https://spacy.io/usage/processing-pipelines#section-pipelines">nlp.pipe()</a> rather than calling nlp(text) in a loop because spaCy is optimized for batch processing. On larger datasets, this can reduce runtime by an order of magnitude.</p>
<div id="d5320de3" class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_entities_by_type(texts, ent_type, nlp):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    ents <span class="op">=</span> Counter()</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc <span class="kw">in</span> nlp.pipe(</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>        texts,</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>        disable<span class="op">=</span>[<span class="st">"tagger"</span>, <span class="st">"parser"</span>, <span class="st">"lemmatizer"</span>]</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ent <span class="kw">in</span> doc.ents:</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> ent.label_ <span class="op">==</span> ent_type:</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>                ents[ent.text] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="da892fb2" class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>get_entities_by_type(</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">'group'</span>] <span class="op">==</span> <span class="st">'promask'</span>][<span class="st">'tweet_text'</span>],</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ORG'</span>,</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    nlp</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>).most_common(<span class="dv">20</span>),</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>get_entities_by_type(</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">'group'</span>] <span class="op">==</span> <span class="st">'antimask'</span>][<span class="st">'tweet_text'</span>],</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ORG'</span>,</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>    nlp</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>).most_common(<span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[('CovidHoax', 87),
 ('CDC', 50),
 ('COVIDIOTS', 19),
 ('BC Canada', 16),
 ('COVIDHOAX', 15),
 ('NHS', 12),
 ('NEVER', 9),
 ('COVID-19', 8),
 ('Trump', 7),
 ('MSM', 7),
 ('BBC', 6),
 ('NFL', 6),
 ('Plandemic', 6),
 ('BS', 5),
 ('RNC', 5),
 ('CovidHoax &amp;', 4),
 ('UN', 4),
 ('BLM', 4),
 ('NJ', 4),
 ('the W H O  wanna', 4)]</code></pre>
</div>
</div>
<section id="interpreting-these-results" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-these-results">Interpreting these results</h3>
<p>The NER analysis provides a coarse, descriptive view of referential structure, rather than a reliable account of who or what is being discussed in detail. At an aggregate level, spaCy’s NER surfaces broad patterns—such as the prominence of PERSON, ORG, GPE, and DATE mention. However, on Twitter data the results are noisy and unstable at the token level. Hashtags, emojis, creative spellings, and slogans seem to be misclassified as entities.</p>
<p>While potentially interesting, this exploratory analysis is not particularly revealing about stance, irony, causality, or implied meaning. Differences should be interpreted as <em>descriptive patterns</em>, not explanations.</p>
<p>We include NER here not because it performs well on Twitter, but because it is a standard NLP technique that illustrates where classical annotation begins to break down. The main lesson here is not what entities are mentioned, but how brittle entity-based analysis becomes in informal, ideological discourse.</p>
</section>
<section id="reflection" class="level3">
<h3 class="anchored" data-anchor-id="reflection">Reflection</h3>
<ol type="1">
<li><p>What aspects of linguistic variety were detectable using word frequency, corpus statistics, and spaCy’s rule-based or statistical methods? What kinds of variation were not well captured?</p></li>
<li><p>Based on examples from our EDA this week and last, what analytical tasks might best suited to:</p></li>
</ol>
<ul>
<li>Corpus statistics (e.g., frequency, dispersion, collocations)?</li>
<li>Classical NLP methods (rules, POS tagging, NER)?</li>
</ul>
<p>Explain why each method is appropriate for those tasks, and give at least one concrete example that you can extrapolate from this notebook.</p>
<div id="6f57e108-d354-49aa-b9f0-26725e03779c" class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>q1_answer <span class="op">=</span> <span class="st">"What aspects of variety were we able to detect with statistical methods or spaCy classical NLP methods? "</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3ed369c0-a73e-432a-9819-924f63f306b0" class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>q2_answer <span class="op">=</span> <span class="st">"What tasks might benefit from corpus statistics methods vs classical NLP methods?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="d---llm-analysis" class="level2">
<h2 class="anchored" data-anchor-id="d---llm-analysis">D - LLM Analysis</h2>
<p>Up to this point, we’ve relied on corpus statistics and spaCy’s linguistic annotations to surface patterns in word choice, grammatical structure, and reference. These methods scale well, are transparent, and make their assumptions explicit—but they also operate largely at the level of surface form. As we’ve seen, they struggle with phenomena that depend on broader context, such as sarcasm, irony, implied stance, emoji usage, and the internal semantics of hashtags.</p>
<p>Large Language Models (LLMs) approach text from a different angle. Rather than counting or labeling isolated units, they model language as a conditional sequence, integrating information across entire utterances and drawing on patterns learned from massive amounts of prior text. This allows them to infer pragmatic meaning, ideological signals, and non-literal usage that classical methods leave opaque. In this section, we explore what LLM-based analysis can reveal about this same dataset—and how its strengths complement, rather than replace, the methods we’ve used so far.</p>
<p>Classical NLP excels at counting and labeling what is explicit; LLMs excel at inferring what is implicit and contextual.</p>
<section id="d.1---hashtags" class="level3">
<h3 class="anchored">D.1 - Hashtags</h3>
<p>Hashtags are interesting and linguistically odd: - No spaces: #CovidIsntReal - Mixed case semantics: #wearAMask vs #WearAMask vs #WEARAMASK - Compound meanings: #DoYourOwnResearch (literal + ideological signal) - Emoji integration: #MaskUp😷 or #NoMasks🙅‍♂️ - Sarcasm markers: #TrustTheScience (could be genuine or mocking)</p>
<p>Could we create custom functions to break hashtags into words? With some effort and degree of error, yes. As it stands, spaCy treats hashtags as proper nouns, doesn’t parse internal structure, and can’t interpret emoji semantics. POS won’t help us much… nor will NER or spaCy dependency parsing. Let’s see what an LLM can tell us.</p>
<div id="f962aa5f" class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example tweets illustrating how hashtags and emoji carry meaning</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="co"># that classical NLP struggles to represent</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(<span class="st">"#DoYourOwnResearch 🐑 #WakeUp"</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>token<span class="sc">.</span>text<span class="sc">:20}</span><span class="ss"> </span><span class="sc">{</span>token<span class="sc">.</span>pos_<span class="sc">:10}</span><span class="ss"> </span><span class="sc">{</span>token<span class="sc">.</span>lemma_<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#                    SYM        #
DoYourOwnResearch    NOUN       doyourownresearch
🐑                    NOUN       🐑
#                    SYM        #
WakeUp               PROPN      WakeUp</code></pre>
</div>
</div>
<div id="93ae7106" class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>tweets <span class="op">=</span> [</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"#DoYourOwnResearch 🐑 #WakeUp Don't let them tell you what to think"</span>,</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️"</span>,</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"#TrustTheScience right into the grave 💀 #CovidHoax"</span>,</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"My freedoms &gt; your fears 🇺🇸 #NoMasks #LiveFree or don't idc"</span></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2b4ea353" class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_analyze_tweet(text, model<span class="op">=</span>DEFAULT_MODEL):</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Analyze tweet for hashtag semantics, ideological signals, and ambiguity"</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> llm_available():</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Summary unavailable</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• LLM disabled or unavailable</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Skipping abstractive summarization</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Proceeding with notebook execution"</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""Analyze this tweet for linguistic and social signals:</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="ss">1. "#DoYourOwnResearch 🐑 #WakeUp Don't let them tell you what to think"</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="ss">2. "Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️"</span></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a><span class="ss">3. "#TrustTheScience right into the grave 💀 #CovidHoax"</span></span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a><span class="ss">4. "My freedoms &gt; your fears 🇺🇸 #NoMasks #LiveFree or don't idc"</span></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a><span class="ss">For each hashtag, convey literal meaning, ideological signal, and whether it's sincere/ironic/ambiguous. Explain reasoning.</span></span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span></span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a>        chat <span class="op">=</span> make_chat(model)</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> chat(prompt)</span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">"HEADLINE: Analysis unavailable</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• LLM call failed</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Safe fallback applied"</span></span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a>llm_analyze_tweet(tweets)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="tweet-analysis" class="level1 cell-output cell-output-display cell-output-markdown">
<h1>Tweet Analysis</h1>
<section id="tweet-1-doyourownresearch-wakeup-dont-let-them-tell-you-what-to-think" class="level2">
<h2 class="anchored" data-anchor-id="tweet-1-doyourownresearch-wakeup-dont-let-them-tell-you-what-to-think">Tweet 1: “#DoYourOwnResearch 🐑 #WakeUp Don’t let them tell you what to think”</h2>
<p><strong>#DoYourOwnResearch</strong> - <em>Literal meaning:</em> Conduct independent investigation - <em>Ideological signal:</em> Anti-establishment, skepticism of mainstream sources/authorities - <em>Tone:</em> Sincere - <em>Reasoning:</em> Commonly associated with conspiracy-adjacent communities; implies mainstream information is unreliable</p>
<p><strong>#WakeUp</strong> - <em>Literal meaning:</em> Become alert/aware - <em>Ideological signal:</em> Suggests others are “asleep” to hidden truths; positions speaker as enlightened - <em>Tone:</em> Sincere - <em>Reasoning:</em> Classic conspiratorial framing; implies special knowledge</p>
<p><strong>🐑 (sheep emoji)</strong> - <em>Signal:</em> Calls others “sheep” for following mainstream guidance - <em>Tone:</em> Sincere contempt/superiority - <em>Reasoning:</em> Dehumanizing language for perceived conformists</p>
<p><strong>Overall Profile:</strong> Anti-establishment, libertarian/populist right, contrarian identity</p>
<hr>
</section>
<section id="tweet-2-proud-to-wearamask-protecting-my-community-inthistogether" class="level2">
<h2 class="anchored" data-anchor-id="tweet-2-proud-to-wearamask-protecting-my-community-inthistogether">Tweet 2: “Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️”</h2>
<p><strong>#WearAMask</strong> - <em>Literal meaning:</em> Advocacy for mask-wearing - <em>Ideological signal:</em> Pro-public health measures, collective responsibility - <em>Tone:</em> Sincere - <em>Reasoning:</em> Positive framing (“proud”), supportive emoji</p>
<p><strong>#InThisTogether</strong> - <em>Literal meaning:</em> Shared experience/collective action - <em>Ideological signal:</em> Communitarian values, social solidarity - <em>Tone:</em> Sincere - <em>Reasoning:</em> Heart emoji reinforces genuine sentiment; emphasizes community over individualism</p>
<p><strong>Overall Profile:</strong> Progressive/liberal, community-oriented, trust in institutions</p>
<hr>
</section>
<section id="tweet-3-trustthescience-right-into-the-grave-covidhoax" class="level2">
<h2 class="anchored" data-anchor-id="tweet-3-trustthescience-right-into-the-grave-covidhoax">Tweet 3: “#TrustTheScience right into the grave 💀 #CovidHoax”</h2>
<p><strong>#TrustTheScience</strong> - <em>Literal meaning:</em> Follow scientific consensus - <em>Ideological signal:</em> Mockery of pro-science messaging - <em>Tone:</em> <strong>Ironic/sarcastic</strong> - <em>Reasoning:</em> Paired with “into the grave” - subverts the typical pro-science hashtag to suggest science is dangerous</p>
<p><strong>#CovidHoax</strong> - <em>Literal meaning:</em> COVID-19 is fabricated/exaggerated - <em>Ideological signal:</em> Conspiracy theorist, pandemic denialist - <em>Tone:</em> Sincere - <em>Reasoning:</em> Direct claim; skull emoji reinforces belief that official narrative is deadly</p>
<p><strong>Overall Profile:</strong> Conspiracy theorist, hard anti-establishment, possibly far-right</p>
<hr>
</section>
<section id="tweet-4-my-freedoms-your-fears-nomasks-livefree-or-dont-idc" class="level2">
<h2 class="anchored" data-anchor-id="tweet-4-my-freedoms-your-fears-nomasks-livefree-or-dont-idc">Tweet 4: “My freedoms &gt; your fears 🇺🇸 #NoMasks #LiveFree or don’t idc”</h2>
<p><strong>“My freedoms &gt; your fears”</strong> - <em>Signal:</em> Libertarian individualism, dismissal of others’ concerns - <em>Tone:</em> Sincere but aggressive - <em>Reasoning:</em> Mathematical notation emphasizes hierarchy of values</p>
<p><strong>#NoMasks</strong> - <em>Literal meaning:</em> Opposition to mask mandates - <em>Ideological signal:</em> Individual liberty over collective measures - <em>Tone:</em> Sincere - <em>Reasoning:</em> Aligns with American flag and freedom rhetoric</p>
<p><strong>#LiveFree</strong> - <em>Literal meaning:</em> Live without restrictions - <em>Ideological signal:</em> Libertarian values; references “Live Free or Die” - <em>Tone:</em> Sincere - <em>Reasoning:</em> American patriotic framing</p>
<p><strong>“or don’t idc” (I don’t care)</strong> - <em>Signal:</em> <strong>Ambiguous</strong> - could be: - Performative indifference (still cares about signaling) - Genuine libertarian “you do you” - Passive-aggressive dismissal - <em>Reasoning:</em> Contradicts the effort of posting; likely performative</p>
<p><strong>Overall Profile:</strong> Libertarian-right, individualist, American nationalism/patriotism</p>
<hr>
</section>
<section id="key-linguistic-patterns" class="level2">
<h2 class="anchored" data-anchor-id="key-linguistic-patterns">Key Linguistic Patterns:</h2>
<p><strong>In-group signaling:</strong> All tweets use hashtags as tribal markers rather than organizational tools</p>
<p><strong>Moral framing:</strong> - Tweets 1, 3, 4: Individual autonomy, anti-coercion - Tweet 2: Collective care, social responsibility</p>
<p><strong>Emotional registers:</strong> - Tweet 1: Superiority/contempt - Tweet 2: Pride/warmth - Tweet 3: Anger/mockery - Tweet 4: Defiance/indifference</p>
<p><strong>Certainty levels:</strong> All express high certainty despite opposing views - characteristic of polarized discourse</p>
<details>
<ul>
<li>id: <code>chatcmpl-fd02e082-3092-487f-a948-86f3fe881f51</code></li>
<li>model: <code>claude-sonnet-4-5-20250929</code></li>
<li>finish_reason: <code>stop</code></li>
<li>usage: <code>Usage(completion_tokens=1131, prompt_tokens=169, total_tokens=1300, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)</code></li>
</ul>
</details>
</section>
</section>
</div>
<p>Hashtags encode compressed semantic and ideological meaning, not just topical labels. While classical NLP treats hashtags as atomic tokens and misses the many ways in which they are used to express feelings, stance, irony, group signaling - LLMs can infer them.</p>
<p>That said, LLM interpretations are plausible analyses, not ground truth. Unlike POS tags or frequency counts, their outputs cannot be directly validated. Claims about stance, irony, or intent should therefore be treated as hypotheses that require external validation (e.g., human annotation, inter-annotator agreement, or task-based evaluation). The value of LLM analysis here lies in sense-making and exploration, not definitive measurement.</p>
<section id="reflection-1" class="level4">
<h4 class="anchored" data-anchor-id="reflection-1">Reflection</h4>
<ol type="1">
<li><p>What signals were invisible to corpus stats and spaCy?</p></li>
<li><p>How do you think the LLM ‘knows’ that 🐑 is being used ironically here? Where does that knowledge come from? (Consider distributional information.)</p></li>
<li><p>The LLM recognizes ‘#DoYourOwnResearch’ as ideologically loaded. How do you think it learn that association? Could we build that classically?</p></li>
</ol>
<div id="45e2f64e-b6aa-4ee9-a701-0762a66bc929" class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>q5_answer <span class="op">=</span> <span class="st">"What information did LLMs infer that SpaCy components couldn't?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d4dfe73e-025a-4371-b9bd-c957fe0216d9" class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>q6_answer <span class="op">=</span> <span class="st">"How did the LLM know that 🐑 indicated irony?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="abefda74-5d1d-455d-b143-023af46c8d19" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>q7_answer <span class="op">=</span> <span class="st">"How did the LLM recognizes an association of #DoYourOwnResearch to ideology?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="d.2-stance-detection" class="level3">
<h3 class="anchored">D.2 Stance Detection</h3>
<p>While, hashtags and emoji can signal ideology, irony, or group identity without explicitly stating a position, stance asks how a speaker positions themselves toward a target. For example, they can indicate whether they support, reject, mock, or distance themselves from an idea.<strong>‘Stance’ indicates a position on a target (e.g., a topic).</strong></p>
<p>Unlike sentiment, which captures positive or negative tone, stance captures a position <strong>toward a specific target</strong>, even when sentiment is ambiguous or ironic.</p>
<p>Stance isn’t always explicit. People signal positions through: - Sarcasm and irony - Rhetorical questions - Tone and affect</p>
<p>Let’s look at tweet pairs that look superficially similar.</p>
<div id="ce83f8ee" class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_analyze_tweet(model<span class="op">=</span>DEFAULT_MODEL):</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Analyze stance and use of language and emoji"</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> llm_available():</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Summary unavailable</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• LLM disabled or unavailable</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Skipping abstractive summarization</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Proceeding with notebook execution"</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""Analyze this tweet for linguistic and social signals:</span></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a><span class="ss">   </span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a><span class="ss">Tweet 1: , "Wow, masks really work 😂"</span></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a><span class="ss">Tweet 2: "Science says masks work. Period."</span></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a><span class="ss">Tweet 3: "Sure, trust the 'experts' 🙄"</span></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a><span class="ss">Tweet 4: "Trust the experts. They know what they're doing."</span></span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a><span class="ss">For each tweet, determine:</span></span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a><span class="ss">1. Explicit stance (pro-mask, anti-mask, neutral)</span></span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a><span class="ss">2. Confidence level (high/medium/low)</span></span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a><span class="ss">3. Key linguistic cues that reveal stance</span></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a><span class="ss">4. Any irony, sarcasm, or non-literal language</span></span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a><span class="ss">5. How emoji/punctuation modifies meaning"""</span></span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>        chat <span class="op">=</span> make_chat(model)</span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> chat(prompt)</span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Analysis unavailable</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• LLM call failed</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Safe fallback applied"</span></span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-40"><a href="#cb65-40" aria-hidden="true" tabindex="-1"></a>llm_analyze_tweet()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="linguistic-and-social-signal-analysis" class="level1 cell-output cell-output-display cell-output-markdown">
<h1>Linguistic and Social Signal Analysis</h1>
<section id="tweet-1-wow-masks-really-work" class="level2">
<h2 class="anchored" data-anchor-id="tweet-1-wow-masks-really-work">Tweet 1: “Wow, masks really work 😂”</h2>
<ol type="1">
<li><strong>Explicit stance:</strong> Anti-mask</li>
<li><strong>Confidence level:</strong> High</li>
<li><strong>Key linguistic cues:</strong>
<ul>
<li>“Wow” - mock surprise/exaggeration</li>
<li>“really” - intensifier used sarcastically</li>
<li>Simple declarative flipped by context</li>
</ul></li>
<li><strong>Irony/Sarcasm:</strong> Heavy sarcasm throughout. The speaker means the opposite of what’s literally stated.</li>
<li><strong>Emoji/Punctuation impact:</strong>
<ul>
<li>😂 (laughing emoji) is crucial—transforms apparent agreement into mockery</li>
<li>Signals the entire statement should be read ironically</li>
</ul></li>
</ol>
<hr>
</section>
<section id="tweet-2-science-says-masks-work.-period." class="level2">
<h2 class="anchored" data-anchor-id="tweet-2-science-says-masks-work.-period.">Tweet 2: “Science says masks work. Period.”</h2>
<ol type="1">
<li><strong>Explicit stance:</strong> Pro-mask</li>
<li><strong>Confidence level:</strong> High</li>
<li><strong>Key linguistic cues:</strong>
<ul>
<li>“Science says” - appeals to authority</li>
<li>“Period” - conversation-ender, brooking no debate</li>
<li>Declarative sentence structure</li>
</ul></li>
<li><strong>Irony/Sarcasm:</strong> None. Direct, literal statement.</li>
<li><strong>Emoji/Punctuation impact:</strong>
<ul>
<li>Period after “Period” creates finality</li>
<li>Emphatic punctuation reinforces certainty</li>
<li>No softening elements</li>
</ul></li>
</ol>
<hr>
</section>
<section id="tweet-3-sure-trust-the-experts" class="level2">
<h2 class="anchored" data-anchor-id="tweet-3-sure-trust-the-experts">Tweet 3: “Sure, trust the ‘experts’ 🙄”</h2>
<ol type="1">
<li><strong>Explicit stance:</strong> Anti-establishment/Anti-mask (implied)</li>
<li><strong>Confidence level:</strong> High</li>
<li><strong>Key linguistic cues:</strong>
<ul>
<li>“Sure” - dismissive agreement (sarcastic)</li>
<li>Scare quotes around ‘experts’ - delegitimizes authority</li>
<li>Imperative verb “trust” used sarcastically</li>
</ul></li>
<li><strong>Irony/Sarcasm:</strong> Strong sarcasm. “Sure” signals insincere agreement.</li>
<li><strong>Emoji/Punctuation impact:</strong>
<ul>
<li>🙄 (eye roll) confirms sarcastic reading</li>
<li>Scare quotes are critical—suggest experts are fraudulent or misguided</li>
<li>Combined effect: complete meaning reversal</li>
</ul></li>
</ol>
<hr>
</section>
<section id="tweet-4-trust-the-experts.-they-know-what-theyre-doing." class="level2">
<h2 class="anchored" data-anchor-id="tweet-4-trust-the-experts.-they-know-what-theyre-doing.">Tweet 4: “Trust the experts. They know what they’re doing.”</h2>
<ol type="1">
<li><strong>Explicit stance:</strong> Pro-establishment/Pro-mask (implied)</li>
<li><strong>Confidence level:</strong> High</li>
<li><strong>Key linguistic cues:</strong>
<ul>
<li>Imperative “Trust” - direct instruction</li>
<li>“They know what they’re doing” - competence assertion</li>
<li>Two reinforcing statements</li>
</ul></li>
<li><strong>Irony/Sarcasm:</strong> None apparent. Sincere statement.</li>
<li><strong>Emoji/Punctuation impact:</strong>
<ul>
<li>Standard punctuation only</li>
<li>Absence of emoji/special punctuation suggests straightforward reading</li>
<li>Could potentially be sarcastic without contextual cues, but default reading is sincere</li>
</ul></li>
</ol>
<hr>
</section>
<section id="key-comparative-observations" class="level2">
<h2 class="anchored" data-anchor-id="key-comparative-observations">Key Comparative Observations:</h2>
<p><strong>Sarcasm Markers:</strong> - Emojis (😂, 🙄) are the strongest sarcasm indicators - Scare quotes signal delegitimization - Words like “Sure,” “Wow,” “really” become sarcastic markers in context</p>
<p><strong>Sincerity Markers:</strong> - “Period” as emphatic closer - Absence of emojis/irony signals - Straightforward syntax</p>
<p><strong>Critical Insight:</strong> Tweets 1 and 3 vs.&nbsp;Tweets 2 and 4 show nearly identical surface content with opposite meanings—demonstrating how digital paralinguistic cues (emoji, quotes, punctuation) are essential for meaning-making in online discourse.</p>
<details>
<ul>
<li>id: <code>chatcmpl-001d2e0e-39fb-44b5-9b5e-1ff742d9bed7</code></li>
<li>model: <code>claude-sonnet-4-5-20250929</code></li>
<li>finish_reason: <code>stop</code></li>
<li>usage: <code>Usage(completion_tokens=839, prompt_tokens=157, total_tokens=996, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)</code></li>
</ul>
</details>
</section>
</section>
</div>
<p>The stance analysis illustrates what LLMs are particularly good at: integrating multiple weak signals—lexical choice, punctuation, emoji, quotation marks, and pragmatic cues—into a coherent interpretation of how a position is being taken. Tweets that appear superficially similar can express sharply different stances.</p>
<p>That said, resuts should be read interpretively and not determinitically. The LLM is not “detecting” stance, but generating plausible explanations based on patterns learned over very large amounts of text. LLMs are great for exploring ideas, generating hypotheses and filling in gaps where surface-level signals break down.</p>
<p>The stance analysis is best understood as interpretive sense-making, not a classification result.</p>
<section id="reflection-2" class="level4">
<h4 class="anchored" data-anchor-id="reflection-2">Reflection</h4>
<ol type="1">
<li><p>The LLM ‘knows’ that 😂 + positive claim often = sarcasm. How did it learn this? Could we build an ML model to detect this or encode it as a rule?</p></li>
<li><p>Are these confidence levels real or simply generated patterns? How could we tell?</p></li>
<li><p>How do we know the LLM is right? For spaCy, we can check POS tags manually. For stance detection, what’s our ground truth?</p></li>
</ol>
<div id="fb6416df-93ae-43b4-b31d-7eded86f124d" class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>q3_answer <span class="op">=</span> <span class="st">"Could we use rules or ML to detect sarcasm?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="15ba30fc-0883-48aa-99d7-46f624cb4d4c" class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>q4_answer <span class="op">=</span> <span class="st">"Are confidence levels given by an LLM real or simply generated?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="30275d94-f9b0-4f6b-9e26-6f1e1b880e3e" class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>q5_answer <span class="op">=</span> <span class="st">"How could we validate whether an LLM is right?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="lab-summary" class="level2">
<h2 class="anchored" data-anchor-id="lab-summary">Lab Summary</h2>
<p>In this lab, you explored how different analytical approaches surface different kinds of structure in text. Using corpus statistics and spaCy’s linguistic annotations, you examined lexical patterns, word associations, grammatical distributions, and referential structure across two contrasting Twitter corpora. You saw how frequency counts, bigrams, and association measures like PMI highlight recurring and slogan-like language, while POS tagging and modal analysis offer a coarse view of grammatical and normative patterns—albeit with clear limitations on informal social media data.</p>
<p>You also observed where classical NLP methods begin to break down. POS tagging and NER, while standard and scalable, proved noisy and brittle in the presence of hashtags, emojis, sarcasm, and fragmented syntax. In contrast, LLM-based analyses demonstrated an ability to integrate multiple weak signals—lexical choice, punctuation, emoji, and pragmatic context—to generate plausible interpretations of stance, irony, and ideological signaling. However, these interpretations remain exploratory and hypothesis-generating rather than directly verifiable.</p>
<p>Taken together, the lab illustrates a core theme of the course: corpus statistics and classical NLP excel at transparent, scalable description of surface patterns, while LLMs excel at contextual sense-making. These tools may be complementary when combined. The goal of the reflection that follows is to help you reason about when to use each method, how they might be combined, and what kinds of linguistic insight each can—and cannot—support.</p>
</section>
<section id="lab-reflection" class="level2">
<h2 class="anchored" data-anchor-id="lab-reflection">Lab Reflection</h2>
<p>In this lab reflection, I’d like you to speculate and use your intuition, even though you don’t have the tools yet to understand LLMs that well yet. We’ll circle back to these questions again.</p>
<ol type="1">
<li><p>Scalability vs.&nbsp;depth trade-off:</p>
<ul>
<li>spaCy: 10,000 tweets, POS tags, in 10 seconds</li>
<li>LLM: 10 tweets, deep analysis, in 30 seconds</li>
<li>“When do you need which?”</li>
</ul></li>
<li><p>How might you combine both traditional NLP methods with LLMs?</p></li>
<li><p>The LLM was trained on internet text that includes political discourse. Could it have learned political biases? How would we detect that?</p></li>
<li><p>What did you find most interesting from this lab?</p></li>
<li><p>What did you find most surprising from this lab?</p></li>
</ol>
<div id="6d269c2d-648f-4bf1-8749-cdabe3547ccc" class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>q6_answer <span class="op">=</span> <span class="st">"For what tasks might we prefer the scalability of spaCy vs depth of an LLM?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="80911c49-d5c7-4a8e-83da-0efc1fdc586e" class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>q7_answer <span class="op">=</span> <span class="st">"How might we combine traditional NLP methods with LLMs?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d447277f-4f11-4672-b93f-3650659a06f7" class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>q8_answer <span class="op">=</span> <span class="st">"Could an LLM learn political biases and how could we tell?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f32bc762-4a5d-4e9b-9ed9-ddf913335066" class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>q9_answer <span class="op">=</span> <span class="st">"What did you find most interesting from this lab?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b60e1b9c-f1d1-427f-a726-8a99138e7f40" class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>q10_answer <span class="op">=</span> <span class="st">"What did you find most surprising from this lab?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0de4365f-11d7-42b2-b0aa-9b4192a7ab45" class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># REVIEW ONLY — does not submit</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.submit <span class="im">import</span> collect_answers, parse_answers, submit_answers</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co"># REVIEW ONLY — does not submit</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>raw <span class="op">=</span> collect_answers(</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    show<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>    namespace<span class="op">=</span><span class="bu">globals</span>(),   </span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>answers <span class="op">=</span> parse_answers(raw)</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Detected </span><span class="sc">{</span><span class="bu">len</span>(answers)<span class="sc">}</span><span class="ss"> answers:"</span>)</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> answers:</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">" "</span>, k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e4598458-a89b-4a81-97ab-3216ac3e4746" class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>ALLOW_SUBMISSION <span class="op">=</span> <span class="va">False</span>   <span class="co"># ← student MUST change this</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> submit_for_credit(student_id):</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ALLOW_SUBMISSION:</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">RuntimeError</span>(</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"⚠️ Submission is disabled.</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"To submit:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  1. Set ALLOW_SUBMISSION = True</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  2. Re-run this cell"</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>    submit_answers(</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>        student_id<span class="op">=</span>student_id,</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>        answers<span class="op">=</span>answers,   <span class="co"># uses reviewed answers</span></span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✅ Submission complete."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1bc8fdf5-dcdd-45eb-bbcc-1aeddd3ba528" class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Don't forget to edit with your name</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>submit_for_credit(<span class="st">"your name"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/su-dataAI/data401-nlp/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>