<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>data401-nlp - Lab 1 - Introduction to the SpaCy Pipeline</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="data401-nlp - Lab 1 - Introduction to the SpaCy Pipeline">
<meta property="og:description" content="Interactive NLP course labs for Jupyter, Colab, and Deepnote">
<meta property="og:site_name" content="data401-nlp">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">data401-nlp</span>
    </a>
  </div>
        <div class="quarto-navbar-tools">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./intro.html">Lab 1 - Introduction to the SpaCy Pipeline</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">README</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_core.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">00_core.html</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Lab 1 - Introduction to the SpaCy Pipeline</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_spacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2 - Leveraging SpaCy for Comparative Textual EDA (Part 1)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda_spacy_part2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 3 Skills: Regular Expressions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zero_frequency_compression_unigrams_bigrams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Zero-Frequency Problem in Text Compression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-sentiment_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 4 - Sparse vectors and Sentiment Analysis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_helpers_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">99_helpers_test.html</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./platform_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Platform Compatibility Tests</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">helpers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/env.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Environment Detection helper (env.py)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLM chat helper (llm.py)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/submit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notebook Submission Helper (submit.py)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./helpers/spacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">spaCy Model Helper (spacy.py)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preface" id="toc-preface" class="nav-link active" data-scroll-target="#preface">Preface</a></li>
  <li><a href="#how-to-use-this-notebook" id="toc-how-to-use-this-notebook" class="nav-link" data-scroll-target="#how-to-use-this-notebook">How to Use This Notebook</a></li>
  <li><a href="#load-libraries-and-models" id="toc-load-libraries-and-models" class="nav-link" data-scroll-target="#load-libraries-and-models">Load Libraries and Models</a>
  <ul>
  <li><a href="#loading-a-spacy-language-model" id="toc-loading-a-spacy-language-model" class="nav-link" data-scroll-target="#loading-a-spacy-language-model">Loading a spaCy Language Model</a></li>
  <li><a href="#setting-up-llm-access" id="toc-setting-up-llm-access" class="nav-link" data-scroll-target="#setting-up-llm-access">Setting Up LLM Access</a></li>
  </ul></li>
  <li><a href="#part-a-exploring-the-spacy-pipeline-tokens-pos-ner-and-parse-trees" id="toc-part-a-exploring-the-spacy-pipeline-tokens-pos-ner-and-parse-trees" class="nav-link" data-scroll-target="#part-a-exploring-the-spacy-pipeline-tokens-pos-ner-and-parse-trees">Part A: Exploring the SpaCy Pipeline (Tokens, POS, NER, and Parse Trees)</a>
  <ul>
  <li><a href="#the-doc-object-your-container-for-processed-text" id="toc-the-doc-object-your-container-for-processed-text" class="nav-link" data-scroll-target="#the-doc-object-your-container-for-processed-text">The Doc Object: Your Container for Processed Text</a></li>
  <li><a href="#tokens-and-their-attributes" id="toc-tokens-and-their-attributes" class="nav-link" data-scroll-target="#tokens-and-their-attributes">Tokens and Their Attributes</a></li>
  <li><a href="#lemmas-and-stopwords" id="toc-lemmas-and-stopwords" class="nav-link" data-scroll-target="#lemmas-and-stopwords">Lemmas and Stopwords</a></li>
  <li><a href="#part-of-speech-tagging" id="toc-part-of-speech-tagging" class="nav-link" data-scroll-target="#part-of-speech-tagging">Part-of-Speech Tagging</a></li>
  <li><a href="#named-entities" id="toc-named-entities" class="nav-link" data-scroll-target="#named-entities">Named Entities</a></li>
  <li><a href="#part-a-summary" id="toc-part-a-summary" class="nav-link" data-scroll-target="#part-a-summary">Part A Summary</a></li>
  </ul></li>
  <li><a href="#part-b-dependency-parsing" id="toc-part-b-dependency-parsing" class="nav-link" data-scroll-target="#part-b-dependency-parsing">Part B: Dependency Parsing</a>
  <ul>
  <li><a href="#part-b-summary" id="toc-part-b-summary" class="nav-link" data-scroll-target="#part-b-summary">Part B Summary</a></li>
  </ul></li>
  <li><a href="#part-c-language-modeling-as-probability-distributions" id="toc-part-c-language-modeling-as-probability-distributions" class="nav-link" data-scroll-target="#part-c-language-modeling-as-probability-distributions">Part C: Language Modeling as Probability Distributions</a>
  <ul>
  <li><a href="#starting-simple-bigram-models" id="toc-starting-simple-bigram-models" class="nav-link" data-scroll-target="#starting-simple-bigram-models">Starting Simple: Bigram Models</a></li>
  <li><a href="#experiments-what-does-ambiguity-look-like-to-an-llm" id="toc-experiments-what-does-ambiguity-look-like-to-an-llm" class="nav-link" data-scroll-target="#experiments-what-does-ambiguity-look-like-to-an-llm">Experiments: What does ambiguity look like to an LLM?</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection">Reflection</a></li>
  <li><a href="#part-c-summary" id="toc-part-c-summary" class="nav-link" data-scroll-target="#part-c-summary">Part C Summary</a></li>
  </ul></li>
  <li><a href="#part-d-sentiment-analysis" id="toc-part-d-sentiment-analysis" class="nav-link" data-scroll-target="#part-d-sentiment-analysis">Part D: Sentiment Analysis</a>
  <ul>
  <li><a href="#classical-approach-vader" id="toc-classical-approach-vader" class="nav-link" data-scroll-target="#classical-approach-vader">Classical Approach: VADER</a></li>
  <li><a href="#llm-approach" id="toc-llm-approach" class="nav-link" data-scroll-target="#llm-approach">LLM Approach</a></li>
  <li><a href="#part-d-summary" id="toc-part-d-summary" class="nav-link" data-scroll-target="#part-d-summary">Part D Summary</a></li>
  </ul></li>
  <li><a href="#part-e-spacy-pipeline-with-llm-summarization" id="toc-part-e-spacy-pipeline-with-llm-summarization" class="nav-link" data-scroll-target="#part-e-spacy-pipeline-with-llm-summarization">Part E: SpaCy Pipeline with LLM Summarization</a>
  <ul>
  <li><a href="#custom-spacy-component" id="toc-custom-spacy-component" class="nav-link" data-scroll-target="#custom-spacy-component">Custom SpaCy component</a></li>
  <li><a href="#reflection-1" id="toc-reflection-1" class="nav-link" data-scroll-target="#reflection-1">Reflection</a></li>
  <li><a href="#part-e-summary" id="toc-part-e-summary" class="nav-link" data-scroll-target="#part-e-summary">Part E Summary</a></li>
  </ul></li>
  <li><a href="#part-f-reflection" id="toc-part-f-reflection" class="nav-link" data-scroll-target="#part-f-reflection">Part F: Reflection</a></li>
  <li><a href="#submit-notebook-for-credit" id="toc-submit-notebook-for-credit" class="nav-link" data-scroll-target="#submit-notebook-for-credit">Submit Notebook for credit</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/su-dataAI/data401-nlp/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lab 1 - Introduction to the SpaCy Pipeline</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="preface" class="level2">
<h2 class="anchored" data-anchor-id="preface">Preface</h2>
<p>Welcome to your first hands-on experience with Natural Language Processing! This notebook takes a different approach from traditional NLP courses. Rather than starting with abstract theory, we will learn NLP concepts by working directly with spaCy, a powerful library used by data scientists and engineers in real-world applications.</p>
<p>Why this approach? Learning NLP can be overwhelming. Textbooks like Jurafsky and Martin’s <em>Speech and Language Processing</em> are comprehensive but dense. By grounding our learning in spaCy, you will build practical skills while gaining conceptual understanding. Every term we introduce connects to something you can see and manipulate in code.</p>
<p><strong>What is spaCy?</strong> <a href="https://spacy.io">SpaCy v.3</a> is an industrial-strength NLP library for Python. Companies use it to build everything from chatbots to document analysis systems. When you learn spaCy, you are learning a tool that employers expect data scientists to know. It processes text quickly, integrates well with other Python libraries, and handles the complex details of language analysis for you.</p>
<p>This notebook provides a whirlwind tour of spaCy’s capabilities. We will work with two fundamental objects: the <strong>Doc</strong> (a processed text document) and <strong>Token</strong> (individual pieces of text like words and punctuation). By the end, you will understand how spaCy breaks text apart, labels it, and identifies relationships between words.</p>
<p>Do not worry if everything does not click immediately. This is an introduction. We will revisit these concepts throughout the course, and each time they will become clearer. The goal today is familiarity, not mastery.</p>
<p>We will also begin exploring how traditional NLP methods relate to Large Language Models (LLMs). Traditional methods (like those in spaCy) are fast, predictable, and transparent. LLMs (like ChatGPT) are flexible and capture nuance but are slower and less explainable. Understanding when to use each is a key skill for modern NLP practitioners.</p>
<p><strong>Related resources</strong> - This is a very thorough overview of SpaCy worth skimming! https://deepnote.com/blog/ultimate-guide-to-the-spacy-library-in-python. - You will also be working your way through the spaCy tutorial here (https://course.spacy.io/en) over the first half of this course.</p>
<p><strong>Learning objectives</strong></p>
<ul>
<li>Introduction to core NLP components and spaCy pipeline</li>
<li>Introduction to tokens and their attributes</li>
<li>Introduction to language models as probability distributions
<ul>
<li>Bigram models</li>
<li>Neural language models</li>
</ul></li>
<li>Thought exercise - Traditional NLP vs LLMs
<ul>
<li>Sentiment analysis</li>
<li>Summarization</li>
</ul></li>
<li>Demonstration of flexible SpaCy pipelines incorporating LLM components</li>
</ul>
</section>
<section id="how-to-use-this-notebook" class="level2">
<h2 class="anchored" data-anchor-id="how-to-use-this-notebook">How to Use This Notebook</h2>
<p><strong>Your goal</strong> is to read the notes and code in this notebook, and answer questions. This is what you will do in each notebook in this class. I used AI copiously to give you a sense of how you might use AI to learn a new library.</p>
<p>If there is code you don’t understand (and that could be most of it!), ask AI to explain it cell-by-cell. Part of your goal is to become fluent in reading code. Make small changes and experiment. If you write code, make tiny, iterative changes and test. Get familiar with the patterns of what must be done and why.</p>
<p>As a student, <strong>you are responsible for answering all questions in the reflection sections and running the last cell in the notebook to submit your answers</strong>. They are ungraded, though we’ll talk about your thoughts and questions in class.</p>
<p>Note: you will see cells marked with <strong>#| eval: false</strong> throughout these notebooks. These are directives that tell the nbdev framework used by this repository not to test during continuous integration. Since the code in these notebooks are not part of the library, most, if not, all will be marked #| eval: false. You can delete them in your own notebooks, if you like.</p>
</section>
<section id="load-libraries-and-models" class="level2">
<h2 class="anchored" data-anchor-id="load-libraries-and-models">Load Libraries and Models</h2>
<p>Before we can work with spaCy, we need to import the necessary libraries. Think of this as gathering your tools before starting a project.</p>
<div id="dbe15e0c-abc5-428f-8037-2bd5be32006d" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If you are colab, un-comment the pip install below.</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This will not be necessary on DeepNote or your local installation</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install data401_nlp</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="93730c4e-ca8a-44c3-9963-1459ac2b0112" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Environment (must run first)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> data401_nlp</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data401_nlp.__version__)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Core libs</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ML libs</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># NLP libs</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Tools libs</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fastcore.tools <span class="im">as</span> fc</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> orjson</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0.7</code></pre>
</div>
</div>
<div id="6049e9b1-b762-40a0-81d1-efedac59933e" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This checks to make sure your SUBMIT_API_KEY is present</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># It can take a moment to load... run again if it fails the first time</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SUBMIT_API_KEY present:"</span>, <span class="bu">bool</span>(os.getenv(<span class="st">"SUBMIT_API_KEY"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Detected environment: dotenv
SUBMIT_API_KEY present: True</code></pre>
</div>
</div>
<section id="loading-a-spacy-language-model" class="level3">
<h3 class="anchored" data-anchor-id="loading-a-spacy-language-model">Loading a spaCy Language Model</h3>
<p>SpaCy does not analyze text on its own. It needs a <strong>language model</strong>—a pre-trained set of rules and patterns for a specific language. We are using <code>en_core_web_sm</code>, a small English model optimized for CPU processing. The “sm” stands for “small,” meaning it downloads quickly and runs fast, though larger models exist for more demanding applications.</p>
<p>When you visit the <a href="https://spacy.io/models/en#en_core_web_sm">model documentation</a>, you will find details about what text it was trained on, what components it includes, and how accurate it is. We will explore most of these components over the coming weeks.</p>
<div id="61ebebf7-34c5-442e-bac2-4b66e78b29a1" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load spacy</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This helper ensures it will automatically download if not present</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.spacy <span class="im">import</span> ensure_spacy_model</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_nlp():</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ensure_spacy_model(<span class="st">"en_core_web_sm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="setting-up-llm-access" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-llm-access">Setting Up LLM Access</h3>
<p>Later in this notebook, we will compare traditional NLP methods with LLM-based approaches. The code below sets up access to an LLM through our helper functions. Do not worry about the details here—just know that this gives us a way to ask questions to an AI model like Claude or GPT.</p>
<p>Your model is currently set to Claude, though you can change it to OpenAI by modifying <code>LLM_MODELS[0]</code> to <code>LLM_MODELS[1]</code>. It is easy to extend the helper to accommodate others and send a <a href="https://github.com/su-dataAI/data401-nlp/pulls">pull request</a> to me, if you use a different model that you’d like added.</p>
<div id="a48d16fa-2dc1-4892-b551-dce535ed7090" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.env <span class="im">import</span> load_env</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.llm <span class="im">import</span> make_chat, LLM_MODELS</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>load_env()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>DEFAULT_MODEL <span class="op">=</span> LLM_MODELS[<span class="dv">0</span>] <span class="co"># Assumes Claude key... adjust if needed.</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Selected model:"</span>, DEFAULT_MODEL)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> make_chat(DEFAULT_MODEL)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Selected model: anthropic/claude-sonnet-4-5</code></pre>
</div>
</div>
<div id="486f8fdd-8064-4a12-b66f-ea7692ca80da" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># You must explicitly opt in, if you want to use and run cells with external LLM calls</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ENABLE_LLM <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="67ccefbf-3423-440e-93f6-a6c9ab679a79" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_status(chat_fn):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ENABLE_LLM:</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"disabled"</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        chat_fn(<span class="st">"ping"</span>, max_tokens<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"ready"</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"misconfigured"</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LLM status:"</span>, llm_status(chat))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>LLM status: disabled</code></pre>
</div>
</div>
<div id="a13a224c-9511-4b3a-9961-eb699653b439" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_and_test_chat(model_name):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ENABLE_LLM:</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span>  <span class="co"># silent no-op</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        chat <span class="op">=</span> make_chat(model_name)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        chat(<span class="st">"ping"</span>, max_tokens<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> chat</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span>  <span class="co"># silent fail</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a989b084-bf52-4bfb-84a9-e4530f6d8096" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_available():</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ENABLE_LLM <span class="kw">and</span> chat <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <a href="https://lisette.answer.ai">listette library</a> wraps the litellm library and makes it possible for us to add models with API keys to this notebook. I’ve included it in helper functions behind the scenes.</p>
<p>You don’t need a subscription or API access, if you don’t have it already. Use these notebooks as “read-only” for those sections. But if you do have a key, do use it!</p>
<ol type="1">
<li><strong>Use Colab or Deepnote’s Secrets feature</strong> (recommended) - store keys in Colab’s built-in secrets manager</li>
<li><strong>Set environment variables</strong> manually in your notebook</li>
<li><strong>Use a <code>.env</code> file</strong> in your local environment</li>
</ol>
</section>
</section>
<section id="part-a-exploring-the-spacy-pipeline-tokens-pos-ner-and-parse-trees" class="level2">
<h2 class="anchored" data-anchor-id="part-a-exploring-the-spacy-pipeline-tokens-pos-ner-and-parse-trees">Part A: Exploring the SpaCy Pipeline (Tokens, POS, NER, and Parse Trees)</h2>
<p>In this section, you will learn how spaCy transforms raw text into structured data. This is the foundation of all NLP work: taking unstructured text and adding labels, categories, and relationships that computers can work with.</p>
<section id="the-doc-object-your-container-for-processed-text" class="level3">
<h3 class="anchored" data-anchor-id="the-doc-object-your-container-for-processed-text">The Doc Object: Your Container for Processed Text</h3>
<p>A <strong>Doc</strong> object is a smart container for data. When you give text to spaCy, it returns a Doc containing your original text plus all the analysis spaCy performs. Every word gets labeled, entities get identified, and grammatical relationships get mapped out—all stored in this single object.</p>
<p>The <strong>nlp</strong> object is what does the work. When you call <code>nlp(text)</code>, spaCy runs your text through a series of processing steps called a <strong>pipeline</strong>. Each step adds different information: one step breaks text into words, another identifies parts of speech, another finds named entities, and so on.</p>
<p>In practice, you create one Doc per document. An Amazon review would be one Doc. A news article would be one Doc. This organization helps when you are processing many documents at once.</p>
<p>The image below captures a high-level overview of the <a href="https://spacy.io/api">spaCy API</a>. Here you can see that text is processed by the <strong>nlp pipeline</strong> which runs the tokenizer. The Doc object itself has Token and Span objects. Let’s look at tokens below. (We’ll hold off on spans till we have a use for them.)</p>
<p><img src="images/spacy-api.png" class="img-fluid"></p>
<div id="6d0f4ac0-a649-43ba-9d29-35ab029f6196" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample text with multiple entities and interesting linguistic features</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> <span class="st">"""Dr. Sarah Chen joined Anthropic in San Francisco on January 15, 2024. She previously worked at Google Brain, where she led a team developing language models that could process over 100,000 tokens per second."""</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Process with spaCy</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We're going to call nlp inside a function so that we don't rely on a global nlp object</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># for demos</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()  </span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(sample_text)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>doc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Dr. Sarah Chen joined Anthropic in San Francisco on January 15, 2024. She previously worked at Google Brain, where she led a team developing language models that could process over 100,000 tokens per second.</code></pre>
</div>
</div>
<div id="463c6516-d727-498d-947a-3a3bcfa62b92" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>[word.text <span class="cf">for</span> word <span class="kw">in</span> doc]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>['Dr.',
 'Sarah',
 'Chen',
 'joined',
 'Anthropic',
 'in',
 'San',
 'Francisco',
 'on',
 'January',
 '15',
 ',',
 '2024',
 '.',
 'She',
 'previously',
 'worked',
 'at',
 'Google',
 'Brain',
 ',',
 'where',
 'she',
 'led',
 'a',
 'team',
 'developing',
 'language',
 'models',
 'that',
 'could',
 'process',
 'over',
 '100,000',
 'tokens',
 'per',
 'second',
 '.']</code></pre>
</div>
</div>
<p>Notice how spaCy split the text into individual pieces. “Dr.” stays together as one piece. “San Francisco” becomes two separate pieces. Punctuation marks like commas and periods each become their own piece. This process of splitting text into pieces is called <strong>tokenization</strong>, and each piece is called a <strong>token</strong>.</p>
</section>
<section id="tokens-and-their-attributes" class="level3">
<h3 class="anchored" data-anchor-id="tokens-and-their-attributes">Tokens and Their Attributes</h3>
<p>A <strong>token</strong> is the basic unit of text in NLP. At its simplest, a token is just a piece of text that has been assigned a number (so computers can work with it). But in spaCy, tokens carry much more: part-of-speech labels, grammatical relationships, and other linguistic information.</p>
<p>We will spend significant time on tokenization in the coming weeks because how you split text dramatically affects NLP performance. <strong>Tokenization</strong> has enormous impact on the performance on NLP tasks.</p>
<p>For now, just understand that tokens are the building blocks we work with.</p>
<p>Each token has many <strong>attributes</strong>—pieces of information attached to it. The <a href="https://spacy.io/api/token#attributes">spaCy token documentation</a> lists all available attributes, or you can use Python’s help function:</p>
<div id="999868cd" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># At this point, it can be helpful to look at API documentation. </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This is one way to do it. Uncomment the line below line.</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># help(doc[0])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5beaaf6f-49b9-4299-8af9-73c2e5bcc78d" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(token.text, token.dep_, token.head.text, token.head.pos_,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>            [child <span class="cf">for</span> child <span class="kw">in</span> token.children])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dr. compound Chen PROPN []
Sarah compound Chen PROPN []
Chen nsubj joined VERB [Dr., Sarah]
joined ROOT joined VERB [Chen, Anthropic, in, on, .]
Anthropic dobj joined VERB []
in prep joined VERB [Francisco]
San compound Francisco PROPN []
Francisco pobj in ADP [San]
on prep joined VERB [January]
January pobj on ADP [15, ,, 2024]
15 nummod January PROPN []
, punct January PROPN []
2024 nummod January PROPN []
. punct joined VERB []
She nsubj worked VERB []
previously advmod worked VERB []
worked ROOT worked VERB [She, previously, at, .]
at prep worked VERB [Brain]
Google compound Brain PROPN []
Brain pobj at ADP [Google, ,, led]
, punct Brain PROPN []
where advmod led VERB []
she nsubj led VERB []
led relcl Brain PROPN [where, she, team]
a det team NOUN []
team dobj led VERB [a, developing]
developing acl team NOUN [models]
language compound models NOUN []
models dobj developing VERB [language, process]
that nsubj process VERB []
could aux process VERB []
process relcl models NOUN [that, could, tokens]
over quantmod 100,000 NUM []
100,000 nummod tokens NOUN [over]
tokens dobj process VERB [100,000, per]
per prep tokens NOUN [second]
second pobj per ADP []
. punct worked VERB []</code></pre>
</div>
</div>
<p>This output is dense! Do not worry about understanding every detail. The key insight is that each token carries information about its grammatical role (dep_), what word it relates to (head), and what words depend on it (children). We will explore these relationships more in the dependency parsing section.</p>
<p>Let us view this information in a cleaner format using a pandas DataFrame, and add a few more commonly used attributes:</p>
<div id="aac8c20d-57bb-4147-8caa-915c166f96e6" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>token_data <span class="op">=</span> []</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    token_data.append({</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Token"</span>: token.text,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Lemma"</span>: token.lemma_,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Lower"</span>: token.lower_,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Shape"</span>: token.shape_,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"POS"</span>: token.pos_,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Tag"</span>: token.tag_,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Dep"</span>: token.dep_,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Is_Stop"</span>: token.is_stop,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Is_Punct"</span>: token.is_punct,</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Is_Digit"</span>: token.is_digit,</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Is_Alpha"</span>: token.is_alpha</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>token_df <span class="op">=</span> pd.DataFrame(token_data)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(token_df.head(<span class="dv">15</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Token     Lemma     Lower Shape   POS Tag      Dep  Is_Stop  Is_Punct  Is_Digit  Is_Alpha
      Dr.       Dr.       dr.   Xx. PROPN NNP compound    False     False     False     False
    Sarah     Sarah     sarah Xxxxx PROPN NNP compound    False     False     False      True
     Chen      Chen      chen  Xxxx PROPN NNP    nsubj    False     False     False      True
   joined      join    joined  xxxx  VERB VBD     ROOT    False     False     False      True
Anthropic Anthropic anthropic Xxxxx PROPN NNP     dobj    False     False     False      True
       in        in        in    xx   ADP  IN     prep     True     False     False      True
      San       San       san   Xxx PROPN NNP compound    False     False     False      True
Francisco Francisco francisco Xxxxx PROPN NNP     pobj    False     False     False      True
       on        on        on    xx   ADP  IN     prep     True     False     False      True
  January   January   january Xxxxx PROPN NNP     pobj    False     False     False      True
       15        15        15    dd   NUM  CD   nummod    False     False      True     False
        ,         ,         ,     , PUNCT   ,    punct    False      True     False     False
     2024      2024      2024  dddd   NUM  CD   nummod    False     False      True     False
        .         .         .     . PUNCT   .    punct    False      True     False     False
      She       she       she   Xxx  PRON PRP    nsubj     True     False     False      True</code></pre>
</div>
</div>
<p>Here are some observations from the first 15 lines of this token analysis: - Notice how ‘joined’ has lemma ‘join’ (verb normalization - ‘Dr.’ is tagged as NNP (proper noun) despite the period” - Stop words like ‘in’, ‘on’, ‘a’ are marked True for Is_Stop”</p>
<p>For now, think of a token as a basic unit that you will focus on in NLP. <strong>A token is simply a piece of text that can be represented as an integer.</strong> The first stage in a spaCy pipeline is tokenization to break up text into the smaller bits that we process. As objects, they have the potential to carry a lot of information. We’re going to briefly look at the sorts of information they carry in this lab. Don’t worry about the details… this is an introduction to terms you will become more familiar with.</p>
<p>Now let’s look at each type of annotation! What are they, and what might we do with them.</p>
</section>
<section id="lemmas-and-stopwords" class="level3">
<h3 class="anchored" data-anchor-id="lemmas-and-stopwords">Lemmas and Stopwords</h3>
<p>Two of the most useful token attributes are <strong>lemmas</strong> and <strong>stopword flags</strong>. Understanding these will help you see why preprocessing matters in NLP.</p>
<p><strong>Lemmas</strong> are the base or dictionary form of a word. For example: - “joined” → “join” - “running” → “run”<br>
- “better” → “good”</p>
<p>This normalization is useful because it lets you treat different forms of the same word as equivalent. For instance, if you’re analyzing sentiment in reviews, you’d want “loved,” “loving,” and “loves” to all be recognized as the same concept.</p>
<p><strong>Stop words</strong> are common words that often don’t carry much meaning on their own, like “the,” “is,” “at,” “in,” “a.” You can see in your token table that words like “in” and “on” are marked as stop words.</p>
<p>They’re often filtered out in tasks like: - Document classification (where “the” appears everywhere and doesn’t help distinguish topics) - Keyword extraction (you want meaningful words, not “and” or “of”)</p>
<p>However, stop words ARE very important for some tasks—like machine translation or question answering, where “not” or “who” can completely change meaning!</p>
<p>Looking at your sample text, can you spot why lemmatization might be helpful for analyzing this text? What if you wanted to count how many times people “work” at different companies across many documents?</p>
</section>
<section id="part-of-speech-tagging" class="level3">
<h3 class="anchored" data-anchor-id="part-of-speech-tagging">Part-of-Speech Tagging</h3>
<p><strong>Part-of-speech (POS) tagging</strong> assigns grammatical categories to each word. Is “book” a noun (I read a book) or a verb (I will book a flight)? POS tags help answer this question based on context.</p>
<p>SpaCy uses two types of POS tags:</p>
<ol type="1">
<li><p><strong>Coarse-grained tags</strong> (<code>token.pos_</code>) - Universal POS tags from the Universal Dependencies project. These are standardized across languages (like NOUN, VERB, ADJ, etc.)</p></li>
<li><p><strong>Fine-grained tags</strong> (<code>token.tag_</code>) - Language-specific tags. For English, these are Penn Treebank tags (like NNP, VBD, JJ, etc.)</p></li>
</ol>
<p>The best references are:</p>
<ul>
<li><a href="https://universaldependencies.org/u/pos/"><strong>Universal POS tags</strong></a></li>
<li><a href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"><strong>Penn Treebank tags</strong></a></li>
<li><a href="https://spacy.io/api/annotation#pos-tagging"><strong>SpaCy’s own documentation</strong></a></li>
</ul>
<p>You can also see what tags are available in your loaded model by checking <code>nlp.get_pipe("tagger").labels</code>.</p>
<p>Here’s a quick reference for the tags appearing in our token data above:</p>
<p><strong>POS Tags (Universal):</strong> - <code>PROPN</code> - Proper noun (Sarah, Chen, Anthropic, San Francisco) - <code>VERB</code> - Verb (joined) - <code>ADP</code> - Adposition/preposition (in, on) - <code>NUM</code> - Number (15, 2024) - <code>PUNCT</code> - Punctuation (., ,) - <code>PRON</code> - Pronoun (She)</p>
<p><strong>Penn Treebank Tags (detailed):</strong> - <code>NNP</code> - Proper noun, singular (Dr., Sarah, Chen) - <code>VBD</code> - Verb, past tense (joined) - <code>IN</code> - Preposition or subordinating conjunction (in, on) - <code>CD</code> - Cardinal number (15, 2024) - <code>PRP</code> - Personal pronoun (She)</p>
<p><strong>Dependency Labels:</strong> - <code>nsubj</code> - Nominal subject (Chen is the subject of “joined”) - <code>dobj</code> - Direct object (Anthropic is what was joined) - <code>compound</code> - Compound modifier (Dr.&nbsp;+ Sarah + Chen) - <code>prep</code> - Prepositional modifier (in, on) - <code>pobj</code> - Object of preposition (Francisco, January) - <code>nummod</code> - Numeric modifier (15 modifies January) - <code>ROOT</code> - Root of the sentence (joined)</p>
<p>SpaCy’s POS tagger uses a neural network model trained on annotated text data. Here’s how it works:</p>
<p><strong>Training:</strong> The model learns patterns from large corpora (like OntoNotes for English) where words are already tagged with their parts of speech. It learns contextual clues—for example, that a word after “the” is likely a noun.</p>
<p><strong>Prediction:</strong> When you process text with <code>nlp(text)</code>, the tagger looks at each token in context (surrounding words, word shape, prefixes/suffixes) and predicts the most likely POS tag using the trained neural network.</p>
<p><strong>Architecture:</strong> Modern SpaCy models (v3+) use transformer-based or CNN-based architectures. The small model you’re using (<code>en_core_web_sm</code>) uses a more compact architecture for speed.</p>
<p>The tagger is one component in the processing pipeline. You can see your pipeline components with:</p>
<div id="2276b425" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>nlp.pipe_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']</code></pre>
</div>
</div>
<p>This shows the six processing steps that run when you call <code>nlp(text)</code>:</p>
<ol type="1">
<li><strong>tok2vec</strong> - Converts tokens into numerical vectors (we will cover this later)</li>
<li><strong>tagger</strong> - Assigns POS tags</li>
<li><strong>parser</strong> - Analyzes grammatical structure (dependency parsing)</li>
<li><strong>attribute_ruler</strong> - Applies rule-based attribute assignments</li>
<li><strong>lemmatizer</strong> - Computes lemmas (base forms of words)</li>
<li><strong>ner</strong> - Named Entity Recognition</li>
</ol>
<p>Notice that tok2vec comes first. It creates vector representations that other components (like the tagger and parser) use as input. This shared representation is one of spaCy’s clever design features—multiple components benefit from the same underlying analysis.</p>
<p>As you will inuit over time, even if we didn’t use spaCy, we would need an nlp pipeline. In general terms, an NLP pipeline is a sequence of processing steps that transform raw text into increasingly structured representations, where each step adds or refines information that later steps can use.</p>
<p>Conceptually:</p>
<ul>
<li>Input starts as unstructured text</li>
<li>Each component performs a specific analysis (e.g., tokenization, tagging, parsing)</li>
<li>The output is a layered annotation of the same text, not a replacement</li>
<li>Later components can depend on the results of earlier ones</li>
</ul>
<p>The key idea is modularity: complex language understanding is built by composing simple, specialized stages rather than solving everything at once. As we will see later, we can add new components to this pipeline… which makes it possible for us to create hybrid NLP solutions using traditional ML with representation and generative models!</p>
<p>Below is a visual depiction of a spaCy pipeline.</p>
<p><img src="images/spacy-pipeline.png" class="img-fluid"></p>
<p>We’ve looked a bit at tokenization, lemmas, and part of speech - let’s move on to NER.</p>
</section>
<section id="named-entities" class="level3">
<h3 class="anchored" data-anchor-id="named-entities">Named Entities</h3>
<p><strong>Named Entity Recognition (NER)</strong> identifies and classifies real-world objects in text: people, organizations, locations, dates, and more. This is one of the most practically useful NLP tasks—imagine automatically extracting all company names from thousands of news articles.</p>
<p>According to the <a href="https://spacy.io/models">SpaCy model reference</a>, the NER component also uses vectors as input. It is configurable to use its own Tok2Vec model, though by default, uses the pipeline Tok2Vec model. SpaCy is extremely configurable and you can turn components on and off, as long as you are paying attention to dependencies.</p>
<p>NER uses all sorts of features as context. For example, it uses punctuation to signal clause boundaries, abbreviations, etc. It also uses lexical features and contextual token features such as neighboring tokens, subword patterns, and other contextual clues. It does not rely on POS tags or dependency parses.</p>
<div id="66f0a2af" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize entities (Colab-friendly)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spacy <span class="im">import</span> displacy</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, HTML</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Render entities</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> displacy.render(doc, style<span class="op">=</span><span class="st">"ent"</span>, jupyter<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>display(HTML(html))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="entities" style="line-height: 2.5; direction: ltr">Dr. 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Sarah Chen
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 joined Anthropic in 
<mark class="entity" style="background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    San Francisco
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">GPE</span>
</mark>
 on 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    January 15, 2024
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
. She previously worked at 
<mark class="entity" style="background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google Brain
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">FAC</span>
</mark>
, where she led a team developing language models that could process over 
<mark class="entity" style="background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    100,000
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">CARDINAL</span>
</mark>
 tokens per 
<mark class="entity" style="background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    second
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORDINAL</span>
</mark>
.</div>
</div>
</div>
<p>POS tags are useful building blocks for many NLP tasks:</p>
<p><strong>1. Information Extraction</strong> - You can filter for specific patterns. For example, finding all noun phrases (sequences of adjectives + nouns) to extract key concepts, or finding verb-object pairs to understand actions.</p>
<p><strong>2. Text Preprocessing</strong> - You might keep only nouns and verbs for topic modeling, or remove everything except proper nouns to find names and places.</p>
<p><strong>3. Disambiguation</strong> - The word “book” could be a noun (read a book) or verb (book a flight). POS tags help distinguish meaning.</p>
<p><strong>4. Feature Engineering</strong> - For classification tasks, POS tag distributions can be features. Academic writing has different POS patterns than casual speech.</p>
<p>Looking at your <code>doc</code>, what if you wanted to extract just the organizations mentioned? You could filter for proper nouns (<code>PROPN</code>), but notice “Google Brain” is tagged as <code>FAC</code> (facility) in the NER output.</p>
<div id="c5e74728-d6e6-4519-a1ff-6c151b0ef87e" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># You can use spacy.explain categories that are unfamiliar.</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>spacy.explain(<span class="st">"FAC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'Buildings, airports, highways, bridges, etc.'</code></pre>
</div>
</div>
<p>Let’s play around with ‘Google Brain’ to look at some other sentences. We want to experiment and see under what sentence contexts it is tagged correctly as an ORG.</p>
<div id="d4f33a31" class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>doc1 <span class="op">=</span> nlp(<span class="st">"She joined Google Brain as an engineer"</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Render entities</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> displacy.render(doc1, style<span class="op">=</span><span class="st">"ent"</span>, jupyter<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>display(HTML(html))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="entities" style="line-height: 2.5; direction: ltr">She joined 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google Brain
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 as an engineer</div>
</div>
</div>
<div id="573f77fb-463f-48b5-8329-6feeb3e9e52e" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>doc2 <span class="op">=</span> nlp(<span class="st">"Google Brain is a research organization"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Render entities</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> displacy.render(doc2, style<span class="op">=</span><span class="st">"ent"</span>, jupyter<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>display(HTML(html))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="entities" style="line-height: 2.5; direction: ltr">
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google Brain
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 is a research organization</div>
</div>
</div>
<div id="615a309a-9134-4efa-81c8-94fcbfc165ed" class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>doc3 <span class="op">=</span> nlp(<span class="st">"She worked at the company Google Brain"</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Render entities</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> displacy.render(doc3, style<span class="op">=</span><span class="st">"ent"</span>, jupyter<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>display(HTML(html))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="entities" style="line-height: 2.5; direction: ltr">She worked at the company 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google Brain
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
</div>
</div>
</div>
</section>
<section id="part-a-summary" class="level3">
<h3 class="anchored" data-anchor-id="part-a-summary">Part A Summary</h3>
<p>In this section, you learned:</p>
<ul>
<li><strong>Doc and Token objects</strong> are spaCy’s fundamental building blocks. A Doc holds processed text; Tokens are individual pieces with attached information.</li>
<li><strong>Tokenization</strong> splits text into pieces. How this happens affects everything downstream.</li>
<li><strong>Token attributes</strong> include lemmas (base forms), POS tags (grammatical categories), and stopword flags.</li>
<li><strong>Named Entity Recognition</strong> identifies real-world objects but depends heavily on context and sometimes makes mistakes.</li>
<li><strong>The spaCy pipeline</strong> runs multiple processing steps in sequence, with each step adding information to the Doc.</li>
</ul>
</section>
</section>
<section id="part-b-dependency-parsing" class="level2">
<h2 class="anchored" data-anchor-id="part-b-dependency-parsing">Part B: Dependency Parsing</h2>
<p>So far, we have looked at individual tokens in isolation. But language is about relationships—subjects perform actions on objects, adjectives modify nouns, prepositions connect phrases. <strong>Dependency parsing</strong> captures these relationships by connecting each word to the word it depends on.</p>
<p>You have been given some <a href="https://socialsci.libretexts.org/Courses/Canada_College/ENGL_LING_200%3A_Introduction_to_Linguistics/05%3A_Phrases-_Syntax/5.03%3A_Phrase_Structure_Rules_X-Bar_Theory_and_Constituency">basic study material on a theory of language structure based on “X-bar” theory</a>, which is the theory behind <strong>constituent parsing</strong>. This kind of parsing has a lot of positives. It can tell you about where noun and verb phrases begin and end because it has rich, hierarchical structure. You can plugin a constituent parser into spaCy, but it’s not the default.</p>
<p>SpaCy chose to implement dependency parsing because it’s faster (linear time), low memory, robust token-centric, and works across many languages (i.e.&nbsp;cross-lingual). Like constituent parsing, it’s also usedful for downstream tasks. Your linguistics book doesn’t talk about dependency parsing, so we’ll draw from Jurafsky and Martin and touch on it in this notebook.</p>
<p>Note, it’s not important to know the details here. Focus on why SpaCy has a dependency parser out of the box – why it might be useful – and that it works at the token level.</p>
<div id="5dd1a85c" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize entities (Colab-friendly)</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spacy <span class="im">import</span> displacy</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, HTML</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>options <span class="op">=</span> {</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distance"</span>: <span class="dv">90</span>,   <span class="co"># arc length</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"compact"</span>: <span class="va">False</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bg"</span>: <span class="st">"#ffffff"</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"color"</span>: <span class="st">"#000000"</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"font"</span>: <span class="st">"Arial"</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Render entities. We need to break out by sentence since this will take a lot of horizontal space, otherwise.</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> displacy.render(</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">list</span>(doc.sents),   <span class="co"># important: avoids cramped multi-sentence trees</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    style<span class="op">=</span><span class="st">"dep"</span>,</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    options<span class="op">=</span>options,</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    jupyter<span class="op">=</span><span class="va">False</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>display(HTML(html))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" lang="en" id="84ab3f580a844df5a9f54dc98b32ef50-0" class="displacy" width="1130" height="272.0" direction="ltr" style="max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr">
<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="50">Dr.</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="50">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="140">Sarah</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="140">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="230">Chen</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="230">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="320">joined</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="320">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="410">Anthropic</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="410">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="500">in</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="500">ADP</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="590">San</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="590">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="680">Francisco</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="680">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="770">on</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="770">ADP</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="860">January</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="860">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="950">15,</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="950">NUM</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1040">2024.</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1040">NUM</tspan>
</text>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-0" stroke-width="2px" d="M70,137.0 C70,47.0 225.0,47.0 225.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-0" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">compound</textpath>
    </text>
    <path class="displacy-arrowhead" d="M70,139.0 L62,127.0 78,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-1" stroke-width="2px" d="M160,137.0 C160,92.0 220.0,92.0 220.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-1" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">compound</textpath>
    </text>
    <path class="displacy-arrowhead" d="M160,139.0 L152,127.0 168,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-2" stroke-width="2px" d="M250,137.0 C250,92.0 310.0,92.0 310.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-2" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M250,139.0 L242,127.0 258,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-3" stroke-width="2px" d="M340,137.0 C340,92.0 400.0,92.0 400.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-3" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">dobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M400.0,139.0 L408.0,127.0 392.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-4" stroke-width="2px" d="M340,137.0 C340,47.0 495.0,47.0 495.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-4" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">prep</textpath>
    </text>
    <path class="displacy-arrowhead" d="M495.0,139.0 L503.0,127.0 487.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-5" stroke-width="2px" d="M610,137.0 C610,92.0 670.0,92.0 670.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-5" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">compound</textpath>
    </text>
    <path class="displacy-arrowhead" d="M610,139.0 L602,127.0 618,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-6" stroke-width="2px" d="M520,137.0 C520,47.0 675.0,47.0 675.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-6" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">pobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M675.0,139.0 L683.0,127.0 667.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-7" stroke-width="2px" d="M340,137.0 C340,2.0 770.0,2.0 770.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-7" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">prep</textpath>
    </text>
    <path class="displacy-arrowhead" d="M770.0,139.0 L778.0,127.0 762.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-8" stroke-width="2px" d="M790,137.0 C790,92.0 850.0,92.0 850.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-8" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">pobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M850.0,139.0 L858.0,127.0 842.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-9" stroke-width="2px" d="M880,137.0 C880,92.0 940.0,92.0 940.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-9" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nummod</textpath>
    </text>
    <path class="displacy-arrowhead" d="M940.0,139.0 L948.0,127.0 932.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-0-10" stroke-width="2px" d="M880,137.0 C880,47.0 1035.0,47.0 1035.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-10" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nummod</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1035.0,139.0 L1043.0,127.0 1027.0,127.0" fill="currentColor"></path>
</g>
</svg>

<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" lang="en" id="84ab3f580a844df5a9f54dc98b32ef50-1" class="displacy" width="2030" height="272.0" direction="ltr" style="max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr">
<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="50">She</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="50">PRON</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="140">previously</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="140">ADV</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="230">worked</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="230">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="320">at</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="320">ADP</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="410">Google</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="410">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="500">Brain,</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="500">PROPN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="590">where</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="590">SCONJ</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="680">she</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="680">PRON</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="770">led</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="770">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="860">a</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="860">DET</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="950">team</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="950">NOUN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1040">developing</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1040">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1130">language</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1130">NOUN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1220">models</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1220">NOUN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1310">that</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1310">PRON</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1400">could</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1400">AUX</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1490">process</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1490">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1580">over</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1580">ADP</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1670">100,000</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1670">NUM</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1760">tokens</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1760">NOUN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1850">per</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1850">ADP</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="182.0">
    <tspan class="displacy-word" fill="currentColor" x="1940">second.</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1940">NOUN</tspan>
</text>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-0" stroke-width="2px" d="M70,137.0 C70,47.0 225.0,47.0 225.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-0" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M70,139.0 L62,127.0 78,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-1" stroke-width="2px" d="M160,137.0 C160,92.0 220.0,92.0 220.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-1" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">advmod</textpath>
    </text>
    <path class="displacy-arrowhead" d="M160,139.0 L152,127.0 168,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-2" stroke-width="2px" d="M250,137.0 C250,92.0 310.0,92.0 310.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-2" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">prep</textpath>
    </text>
    <path class="displacy-arrowhead" d="M310.0,139.0 L318.0,127.0 302.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-3" stroke-width="2px" d="M430,137.0 C430,92.0 490.0,92.0 490.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-3" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">compound</textpath>
    </text>
    <path class="displacy-arrowhead" d="M430,139.0 L422,127.0 438,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-4" stroke-width="2px" d="M340,137.0 C340,47.0 495.0,47.0 495.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-4" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">pobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M495.0,139.0 L503.0,127.0 487.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-5" stroke-width="2px" d="M610,137.0 C610,47.0 765.0,47.0 765.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-5" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">advmod</textpath>
    </text>
    <path class="displacy-arrowhead" d="M610,139.0 L602,127.0 618,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-6" stroke-width="2px" d="M700,137.0 C700,92.0 760.0,92.0 760.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-6" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M700,139.0 L692,127.0 708,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-7" stroke-width="2px" d="M520,137.0 C520,2.0 770.0,2.0 770.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-7" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">relcl</textpath>
    </text>
    <path class="displacy-arrowhead" d="M770.0,139.0 L778.0,127.0 762.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-8" stroke-width="2px" d="M880,137.0 C880,92.0 940.0,92.0 940.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-8" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">det</textpath>
    </text>
    <path class="displacy-arrowhead" d="M880,139.0 L872,127.0 888,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-9" stroke-width="2px" d="M790,137.0 C790,47.0 945.0,47.0 945.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-9" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">dobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M945.0,139.0 L953.0,127.0 937.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-10" stroke-width="2px" d="M970,137.0 C970,92.0 1030.0,92.0 1030.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-10" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">acl</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1030.0,139.0 L1038.0,127.0 1022.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-11" stroke-width="2px" d="M1150,137.0 C1150,92.0 1210.0,92.0 1210.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-11" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">compound</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1150,139.0 L1142,127.0 1158,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-12" stroke-width="2px" d="M1060,137.0 C1060,47.0 1215.0,47.0 1215.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-12" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">dobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1215.0,139.0 L1223.0,127.0 1207.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-13" stroke-width="2px" d="M1330,137.0 C1330,47.0 1485.0,47.0 1485.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-13" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1330,139.0 L1322,127.0 1338,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-14" stroke-width="2px" d="M1420,137.0 C1420,92.0 1480.0,92.0 1480.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-14" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">aux</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1420,139.0 L1412,127.0 1428,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-15" stroke-width="2px" d="M1240,137.0 C1240,2.0 1490.0,2.0 1490.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-15" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">relcl</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1490.0,139.0 L1498.0,127.0 1482.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-16" stroke-width="2px" d="M1600,137.0 C1600,92.0 1660.0,92.0 1660.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-16" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">quantmod</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1600,139.0 L1592,127.0 1608,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-17" stroke-width="2px" d="M1690,137.0 C1690,92.0 1750.0,92.0 1750.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-17" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">nummod</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1690,139.0 L1682,127.0 1698,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-18" stroke-width="2px" d="M1510,137.0 C1510,47.0 1755.0,47.0 1755.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-18" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">dobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1755.0,139.0 L1763.0,127.0 1747.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-19" stroke-width="2px" d="M1780,137.0 C1780,92.0 1840.0,92.0 1840.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-19" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">prep</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1840.0,139.0 L1848.0,127.0 1832.0,127.0" fill="currentColor"></path>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-84ab3f580a844df5a9f54dc98b32ef50-1-20" stroke-width="2px" d="M1870,137.0 C1870,92.0 1930.0,92.0 1930.0,137.0" fill="none" stroke="currentColor"></path>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textpath href="#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-20" class="displacy-label" startoffset="50%" side="left" fill="currentColor" text-anchor="middle">pobj</textpath>
    </text>
    <path class="displacy-arrowhead" d="M1930.0,139.0 L1938.0,127.0 1922.0,127.0" fill="currentColor"></path>
</g>
</svg>
</div>
</div>
<p>Looking at the first sentence’s dependency chart, here’s how to read it:</p>
<p><strong>The arrows show relationships between words</strong>, where: - The arrow points FROM a dependent word TO its head (the word it modifies or relates to) - The label on the arrow tells you the type of relationship</p>
<p><strong>Example from “Dr.&nbsp;Sarah Chen joined Anthropic…”:</strong></p>
<ul>
<li>“Dr.” and “Sarah” both have arrows pointing to “Chen” with label <code>compound</code> - they’re parts of the compound name</li>
<li>“Chen” has an arrow to “joined” labeled <code>nsubj</code> (nominal subject) - Chen is who performed the action</li>
<li>“Anthropic” points to “joined” with <code>dobj</code> (direct object) - Anthropic is what was joined</li>
<li>“in” points to “joined” with <code>prep</code> (prepositional modifier)</li>
<li>“Francisco” points to “in” with <code>pobj</code> (object of preposition)</li>
</ul>
<p><strong>The ROOT</strong> is “joined” - it’s the main verb with no arrow pointing away from it.</p>
<p>Try tracing one relationship yourself. Can you explain what the arrow from “San” to “Francisco” means?</p>
<p>This is what a dependency parse looks like compared to a syntax tree constituent analysis and is from <a href="https://web.stanford.edu/~jurafsky/slp3/19.pdf">Chapter 19 of Jurafsky &amp; Martin</a>. Arguments to relations are heads and dependents. Heads are the organizing word and dependents are like modifiers. These are labeled with grammatical functions like “Nominal subject” or “Direct object.”</p>
<p>For example, (<strong>NSUBJ</strong>) <strong>United</strong> canceled the (<strong>DOBJ</strong>) <strong>flight</strong>.</p>
<p>The example below shows what a dependency parse sentence diagram looks like. Note the direction of the arrows. “flight” and “me” are connected to the root “Book.” They are dependent on “Book.”</p>
<p>Similarly, “morning” is dependent on “flight.” And “the” is dependent on “morning flight.” In fact, every structure is dependent on another – starting with the root.</p>
<p><img src="images/dependency-parse-diagram.png" class="img-fluid"></p>
<p>The Universal Dependencies project is a community effort to align a grammar across more than 100 language with an inventory of <a href="https://universaldependencies.org/u/dep/">37 dependency relations</a>.</p>
<p>Notably, dependency parsing answers questions like: - who did what to whom? - what modifies what? - what organizations below to which phrase?</p>
<p>Unlike consituency parsers which use the <strong>sentence</strong> as the root of the tree, dependency grammars place the main <strong>verb</strong> as the head of a clause (sentence embedded in a larger sentence).</p>
<p>So in our clause “she previously <strong>worked</strong> at Google Brain”, ‘worked’ is the root that everything depends on.</p>
<ul>
<li><strong>she</strong> is “who did it”</li>
<li><strong>previously</strong> is “when”</li>
<li>at <strong>Google Brain</strong> is “where” (oblique argument)</li>
</ul>
<p>SpaCy’s dependency parser works differently from POS tagging. Instead of assigning labels to individual tokens, it predicts <strong>relationships between tokens</strong> (which token is the head of which other token, and what type of dependency).</p>
<p>The parser uses a <strong>transition-based approach</strong>: - It processes the sentence incrementally, making a series of decisions (transitions) - At each step, it can perform actions like “attach this word to that word with label X” - It builds up the parse tree through these sequential decisions</p>
<p>Like NER, it can use beam search to explore multiple parsing paths and find the most probable complete parse tree.</p>
<p>The key difference: POS assigns one label per token independently, while dependency parsing creates a <strong>structure</strong> where every token (except the root) must connect to exactly one head token.</p>
<p>This diagram is from Jurafsky &amp; Martin Chapter 19.2 and is an illustration of <strong>transition-based</strong> parsing. It demonstrates <strong>shift-reduce parsing</strong> where we have a stack on which we build the parse, a buffer of tokens to parse, and a parser which takes actions on the prase via a predictor called an oracle. It can explore multiple paths, when doing so - though, that will slow this process down.</p>
<p><img src="images/dependency-parse.png" class="img-fluid"></p>
<p>The parser walks through the sentence left-to-right, successively shifting items from the buffer onto the stack. At each time point we examine the top two elements on the stack, and the oracle makes a decision about what transition to apply to build the parse.</p>
<p>These are the tree transition operations on the top two elements of the stack:</p>
<ol type="1">
<li><p><strong>LEFTARC</strong>: Assert a head-dependent relation between the word at the top of the stack and the second word; remove the second word from the stack.</p></li>
<li><p><strong>RIGHTARC</strong>: Assert a head-dependent relation between the second word on the stack and the word at the top; remove the top word from the stack.</p></li>
<li><p><strong>SHIFT</strong>: Remove the word from the front of the input buffer and push it onto the stack.</p></li>
</ol>
<p>This is a greedy algorithm - the oracle provides a single choice at each step and the parser proceeds with that choice and no other options are explored. There is no backtracking and a single parse is returned in the end.</p>
<p>Think of it this way, the Oracle is a trained supervised algorithm that makes a decision over two tokens until there are no more rules to apply. It decides if it will shift a word onto the stack, or if it will assert a relationship (left or right) between two tokens. Recall, <strong>every token must connect to exactly one head token.</strong></p>
<p>Below, we will tell SpaCy to give us the top three parses. Generally, we want a beam_width of 1 (one parse), because this is much faster.</p>
<p>A “beam” is a set of top-scoring partial parse trees or hypotheses kept by a beam search algorithm. Beam search maintains a “beam width” of several promising candidates, expanding them and pruning less likely ones at each stage to avoid exponential complexity.</p>
<div id="39a36b27-ca8e-48af-b909-42596450b498" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> get_nlp()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(sample_text)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>parser <span class="op">=</span> nlp.get_pipe(<span class="st">"parser"</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>beams <span class="op">=</span> parser.beam_parse([doc], beam_width<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully</code></pre>
</div>
</div>
<div id="0e5a0e63-23ef-412d-b237-6a1893c1425e" class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>head_scores, label_scores <span class="op">=</span> parser.scored_parses(beams)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of alternatives: </span><span class="sc">{</span><span class="bu">len</span>(beams[<span class="dv">0</span>].histories)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probabilities: </span><span class="sc">{</span>beams[<span class="dv">0</span>]<span class="sc">.</span>probs<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of alternatives: 3
Probabilities: [0.7982435893632595, 0.17826448047596988, 0.023491930160770638]</code></pre>
</div>
</div>
<p>The <code>beams[0].probs</code> shows the probabilities for the top 3 complete dependency parse trees:</p>
<ul>
<li><strong>79.8%</strong> - The parse tree SpaCy chose (most probable)</li>
<li><strong>17.8%</strong> - Second-best alternative parse</li>
<li><strong>2.3%</strong> - Third-best alternative</li>
</ul>
<p>The <code>head_scores</code> and <code>label_scores</code> from <code>scored_parses()</code> give you more detailed information about individual attachment decisions and dependency labels for each token in each parse.</p>
<p>Want to look at what’s actually different between these three parse trees? We could decode the histories to see where they disagree.</p>
<section id="part-b-summary" class="level3">
<h3 class="anchored" data-anchor-id="part-b-summary">Part B Summary</h3>
<p>In this section, you learned:</p>
<ul>
<li><strong>Dependency parsing</strong> captures grammatical relationships between words, showing who did what to whom.</li>
<li><strong>Each token connects to exactly one head</strong>, creating a tree structure with the main verb as root.</li>
<li>SpaCy uses a <strong>transition-based parser</strong> that makes sequential decisions to build the parse.</li>
<li><strong>Beam search</strong> lets us see alternative parses and their probabilities, revealing where the parser is uncertain.</li>
<li>This approach is <strong>fast and works across languages</strong>, which is why spaCy chose it over constituency parsing.</li>
</ul>
</section>
</section>
<section id="part-c-language-modeling-as-probability-distributions" class="level2">
<h2 class="anchored" data-anchor-id="part-c-language-modeling-as-probability-distributions">Part C: Language Modeling as Probability Distributions</h2>
<p>Now we shift from analyzing existing text to understanding how computers predict text. This is the foundation of modern NLP: <strong>language models</strong> assign <em>probabilities to sequences of words</em>. When you use autocomplete on your phone or ChatGPT generates a response, language models are predicting what words should come next.</p>
<section id="starting-simple-bigram-models" class="level3">
<h3 class="anchored" data-anchor-id="starting-simple-bigram-models">Starting Simple: Bigram Models</h3>
<p>The simplest language model considers only the immediately preceding word. Given “the quick brown,” what word is likely to follow? A <strong>bigram model</strong> looks at word pairs and counts how often each pair appeared in training data.</p>
<p>The first thing we are going to do is look at a simple bigram model. A bigram is a pair of consecutive units. These models perform surprisingly well! You can also build trigram models – three consecutive units, and four-gram models. All are simply types of ‘n-gram’ models.</p>
<p>So, for example,</p>
<ul>
<li>unigram - ‘the’</li>
<li>bigram - ‘the man’</li>
<li>trigram - ‘the man with’</li>
<li>4-gram - ‘the man with the’</li>
</ul>
<p>The larger the chunk, the more context. We’ll look at n-grams more in depth later this semester.</p>
<div id="26024430-2d6a-43ff-a838-36a965b063fe" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="st">I saw the man with the telescope yesterday.</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="st">I saw the bird with my binoculars.</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="st">The man with the hat waved at me.</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="st">I watched the show with great interest.</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="st">The telescope with the red lens was expensive.</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="st">I observed the stars with the telescope.</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="st">The bird with colorful feathers flew away.</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="st">She saw him with her own eyes.</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="st">The man with the briefcase left early.</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="st">I spotted the deer with the binoculars.</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6436e1b8" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict, Counter</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9def61c9" class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BigramLM:</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""A simple bigram language model."""</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bigram_counts <span class="op">=</span> defaultdict(Counter)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.unigram_counts <span class="op">=</span> Counter()</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, text):</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Train on a corpus of text."""</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simple tokenization</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> text.lower().replace(<span class="st">'.'</span>, <span class="st">' .'</span>).replace(<span class="st">','</span>, <span class="st">' ,'</span>).split()</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Count unigrams</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.unigram_counts.update(tokens)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Count bigrams</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tokens) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bigram_counts[tokens[i]][tokens[i<span class="op">+</span><span class="dv">1</span>]] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Trained on </span><span class="sc">{</span><span class="bu">len</span>(tokens)<span class="sc">}</span><span class="ss"> tokens, </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.bigram_counts)<span class="sc">}</span><span class="ss"> unique contexts"</span>)</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_next_word_probs(<span class="va">self</span>, context_word, top_k<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get probability distribution over next words given context."""</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>        context_word <span class="op">=</span> context_word.lower()</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> context_word <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.bigram_counts:</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> []</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> <span class="va">self</span>.bigram_counts[context_word]</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="bu">sum</span>(counts.values())</span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> [(word, count<span class="op">/</span>total) <span class="cf">for</span> word, count <span class="kw">in</span> counts.most_common(top_k)]</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> probs</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> score_sequence(<span class="va">self</span>, words):</span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Score a sequence of words (log probability)."""</span></span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>        <span class="im">import</span> math</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> [w.lower() <span class="cf">for</span> w <span class="kw">in</span> words]</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a>        log_prob <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(words) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a>            context <span class="op">=</span> words[i]</span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a>            next_word <span class="op">=</span> words[i<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> context <span class="kw">in</span> <span class="va">self</span>.bigram_counts <span class="kw">and</span> next_word <span class="kw">in</span> <span class="va">self</span>.bigram_counts[context]:</span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a>                prob <span class="op">=</span> <span class="va">self</span>.bigram_counts[context][next_word] <span class="op">/</span> <span class="bu">sum</span>(<span class="va">self</span>.bigram_counts[context].values())</span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a>                log_prob <span class="op">+=</span> math.log(prob)</span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a>                log_prob <span class="op">+=</span> math.log(<span class="fl">1e-6</span>)  <span class="co"># Smoothing for unseen</span></span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> log_prob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="94f46678-abf8-4860-9dd0-720c2aec0248" class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train our bigram model</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>bigram_lm <span class="op">=</span> BigramLM()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>bigram_lm.train(corpus)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trained on 83 tokens, 39 unique contexts</code></pre>
</div>
</div>
<div id="e6b14905-6f2d-408a-b1b9-d5a7c62c6987" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Explore next-word probabilities from our bigram model</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 BIGRAM MODEL: Next-word probabilities"</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>test_contexts <span class="op">=</span> [<span class="st">"the"</span>, <span class="st">"with"</span>, <span class="st">"saw"</span>, <span class="st">"man"</span>]</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> context <span class="kw">in</span> test_contexts:</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> bigram_lm.get_next_word_probs(context, top_k<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">After '</span><span class="sc">{</span>context<span class="sc">}</span><span class="ss">':"</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, prob <span class="kw">in</span> probs:</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"   </span><span class="sc">{</span>word<span class="sc">:15}</span><span class="ss"> </span><span class="sc">{</span>prob<span class="sc">:.3f}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'█'</span> <span class="op">*</span> <span class="bu">int</span>(prob <span class="op">*</span> <span class="dv">20</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
📊 BIGRAM MODEL: Next-word probabilities
==================================================

After 'the':
   man             0.200 ████
   telescope       0.200 ████
   bird            0.133 ██
   hat             0.067 █
   show            0.067 █

After 'with':
   the             0.600 ████████████
   my              0.100 ██
   great           0.100 ██
   colorful        0.100 ██
   her             0.100 ██

After 'saw':
   the             0.667 █████████████
   him             0.333 ██████

After 'man':
   with            1.000 ████████████████████</code></pre>
</div>
</div>
<p>Expected Observation:</p>
<ul>
<li>Limited vocabulary (only words seen in training)</li>
<li>Only looks at ONE previous word (no long-range context)</li>
<li>Sparse: many word pairs never seen → zero probability</li>
</ul>
<p>Play around with different corpora to explore.</p>
<p>Now let’s see how a neural model handles the tax of next-token probabilities.</p>
<div id="c505760d-3615-41e1-a662-d6904b2f2078" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># UNIFIED INTERFACE FOR NEXT-TOKEN PROBABILITIES</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># This has been tested with Claude and ChatGPT</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># It's designed so we can later swap in a remote model </span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co"># without changing downstream experiments.</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Load local model (distilgpt2 - small and fast)</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Loading local language model (distilgpt2)..."</span>)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>local_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"distilgpt2"</span>)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>local_model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(<span class="st">"distilgpt2"</span>)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>local_model.<span class="bu">eval</span>()</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✅ Local model loaded!"</span>)</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_next_token_distribution_local(prompt, k<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Get top-k next token probabilities using local model.</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns: list of (token_string, probability) tuples</span></span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> local_tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> local_model(<span class="op">**</span>inputs)</span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get logits for the last position</span></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>        next_token_logits <span class="op">=</span> outputs.logits[<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert to probabilities</span></span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> F.softmax(next_token_logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get top-k</span></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>        top_probs, top_indices <span class="op">=</span> torch.topk(probs, k)</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> prob, idx <span class="kw">in</span> <span class="bu">zip</span>(top_probs.tolist(), top_indices.tolist()):</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>        token <span class="op">=</span> local_tokenizer.decode([idx])</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>        results.append((token, prob))</span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score_continuation_local(prompt, continuation):</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a><span class="co">    Score a continuation given a prompt using teacher forcing.</span></span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns: (sum_log_prob, avg_log_prob, num_tokens)</span></span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> math</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>    full_text <span class="op">=</span> prompt <span class="op">+</span> continuation</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>    prompt_ids <span class="op">=</span> local_tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>)[<span class="st">"input_ids"</span>]</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>    full_ids <span class="op">=</span> local_tokenizer(full_text, return_tensors<span class="op">=</span><span class="st">"pt"</span>)[<span class="st">"input_ids"</span>]</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>    prompt_len <span class="op">=</span> prompt_ids.shape[<span class="dv">1</span>]</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> local_model(full_ids)</span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> outputs.logits[<span class="dv">0</span>]  <span class="co"># [seq_len, vocab_size]</span></span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Score each token in the continuation</span></span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a>    log_probs <span class="op">=</span> []</span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(prompt_len <span class="op">-</span> <span class="dv">1</span>, full_ids.shape[<span class="dv">1</span>] <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a>        next_token_id <span class="op">=</span> full_ids[<span class="dv">0</span>, i <span class="op">+</span> <span class="dv">1</span>].item()</span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a>        token_logits <span class="op">=</span> logits[i]</span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a>        token_probs <span class="op">=</span> F.softmax(token_logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a>        log_prob <span class="op">=</span> math.log(token_probs[next_token_id].item() <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a>        log_probs.append(log_prob)</span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>    sum_log_prob <span class="op">=</span> <span class="bu">sum</span>(log_probs)</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a>    avg_log_prob <span class="op">=</span> sum_log_prob <span class="op">/</span> <span class="bu">len</span>(log_probs) <span class="cf">if</span> log_probs <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sum_log_prob, avg_log_prob, <span class="bu">len</span>(log_probs)</span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Create unified interface</span></span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_next_token_distribution(prompt, k<span class="op">=</span><span class="dv">10</span>, provider<span class="op">=</span><span class="st">"auto"</span>):</span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a><span class="co">    Unified interface for next-token distributions.</span></span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-78"><a href="#cb45-78" aria-hidden="true" tabindex="-1"></a><span class="co">    </span><span class="al">NOTE</span><span class="co">:</span></span>
<span id="cb45-79"><a href="#cb45-79" aria-hidden="true" tabindex="-1"></a><span class="co">    - Currently defaults to a local model (distilgpt2)</span></span>
<span id="cb45-80"><a href="#cb45-80" aria-hidden="true" tabindex="-1"></a><span class="co">    - Designed so experiments below do not depend on model source</span></span>
<span id="cb45-81"><a href="#cb45-81" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb45-82"><a href="#cb45-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> provider <span class="op">==</span> <span class="st">"auto"</span>:</span>
<span id="cb45-83"><a href="#cb45-83" aria-hidden="true" tabindex="-1"></a>        provider <span class="op">=</span> <span class="st">"local"</span>  <span class="co"># Local is most reliable for logprobs</span></span>
<span id="cb45-84"><a href="#cb45-84" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-85"><a href="#cb45-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> provider <span class="op">==</span> <span class="st">"local"</span>:</span>
<span id="cb45-86"><a href="#cb45-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> get_next_token_distribution_local(prompt, k)</span>
<span id="cb45-87"><a href="#cb45-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb45-88"><a href="#cb45-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fallback to local</span></span>
<span id="cb45-89"><a href="#cb45-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> get_next_token_distribution_local(prompt, k)</span>
<span id="cb45-90"><a href="#cb45-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-91"><a href="#cb45-91" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score_continuation(prompt, continuation, provider<span class="op">=</span><span class="st">"auto"</span>):</span>
<span id="cb45-92"><a href="#cb45-92" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Score a continuation using best available provider."""</span></span>
<span id="cb45-93"><a href="#cb45-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> provider <span class="op">==</span> <span class="st">"auto"</span>:</span>
<span id="cb45-94"><a href="#cb45-94" aria-hidden="true" tabindex="-1"></a>        provider <span class="op">=</span> <span class="st">"local"</span></span>
<span id="cb45-95"><a href="#cb45-95" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-96"><a href="#cb45-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> provider <span class="op">==</span> <span class="st">"local"</span>:</span>
<span id="cb45-97"><a href="#cb45-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> score_continuation_local(prompt, continuation)</span>
<span id="cb45-98"><a href="#cb45-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb45-99"><a href="#cb45-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> score_continuation_local(prompt, continuation)</span>
<span id="cb45-100"><a href="#cb45-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-101"><a href="#cb45-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Unified LM interface ready!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loading local language model (distilgpt2)...
✅ Local model loaded!

✅ Unified LM interface ready!</code></pre>
</div>
</div>
<p>In get_next_token_distribution_local() above:</p>
<ul>
<li>A local causal language model (distilgpt2) is loaded using <a href="https://huggingface.co">Hugging Face</a>.</li>
<li>Given a text prompt, the model produces logits for the next token only.</li>
<li>Logits are converted to a probability distribution via softmax.</li>
<li>The function returns the top-k most likely next tokens with their probabilities.</li>
</ul>
<p>In score_continuation_local() above, we want to see how the score changes when we provide all the <em>correct</em> tokens before (a technique called <strong>teacher forcing</strong>).</p>
<ul>
<li>The prompt and continuation are concatenated into one sequence.</li>
<li>The prompt length is recorded so we know which tokens belong to the continuation.</li>
<li>The full sequence is passed through the model once to obtain logits at every position.</li>
<li>For each continuation token, the model’s probability of the actual next token is read from the logits.</li>
<li>These probabilities are converted to log probabilities and summed.</li>
</ul>
<p>Contrast with bigrams: unlike the bigram model, which conditions only on the immediately preceding word and assigns zero probability to unseen pairs, <strong>the neural model conditions on the entire prior context and assigns graded probabilities even to novel continuations.</strong></p>
<p>Later in the course we’ll talk about language models and how <strong>log probabilities</strong> and <strong>log liklihood</strong> (the scoring function over data) works. These concepts are foundational to machine-learning based AI. Fortunately, at the core, these concept are not difficult for non-statisticians!</p>
<div id="3d49b204-3ace-41e2-bcfc-c8844e4762be" class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the interface</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🧪 Testing next-token distribution..."</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>test_prompt <span class="op">=</span> <span class="st">"The quick brown fox"</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> get_next_token_distribution(test_prompt, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prompt: '</span><span class="sc">{</span>test_prompt<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Top 10 next tokens:"</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token, prob <span class="kw">in</span> results:</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>    bar <span class="op">=</span> <span class="st">'█'</span> <span class="op">*</span> <span class="bu">int</span>(prob <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   '</span><span class="sc">{</span>token<span class="sc">:10}</span><span class="ss">' : </span><span class="sc">{</span>prob<span class="sc">:.4f}</span><span class="ss"> </span><span class="sc">{</span>bar<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
🧪 Testing next-token distribution...
==================================================
Prompt: 'The quick brown fox'

Top 10 next tokens:
   'es        ' : 0.2303 ███████████
   ' is       ' : 0.0549 ██
   ',         ' : 0.0270 █
   '.         ' : 0.0242 █
   ' and      ' : 0.0191 
   ' has      ' : 0.0187 
   ' that     ' : 0.0160 
   ' was      ' : 0.0151 
   'e         ' : 0.0148 
   'y         ' : 0.0104 </code></pre>
</div>
</div>
<p>Why don’t we see ‘jump’ as in thefamous phrase “The quick brown fox jumped over the lazy dog.”</p>
<p><strong>1. Training data bias</strong> - DistilGPT2 was trained on a huge corpus of internet text. While “The quick brown fox jumps over the lazy dog” is a famous pangram (contains all letters), it’s actually quite rare compared to how often the model saw other phrases starting with “The quick brown fox…”</p>
<p><strong>2. Token probabilities are spread out</strong> - Notice we’re only showing the top 10. “jumped” might be ranked 50th or 100th with a very small probability.</p>
<p><strong>3. Tokenization</strong> - “jumped” might be split into multiple tokens (like “jump” + “ed”), making it even less likely to appear as a single next token.</p>
<p>Want to check if “jumped” appears further down the list? We could increase <code>k</code> to see more possibilities, or we could score the specific continuation “jumped over the lazy dog” to see what probability the model assigns to it.</p>
<p>Notice that we can give the entire context to <strong>DistilGPT2</strong>.</p>
<ul>
<li>It’s considering the entire context “The quick brown fox”</li>
<li>It uses sub-tokens, and likely has a lot of “fox” followed by “es” in training data</li>
<li>It can handle words it’s never seen in an exact bigram pair 0 It’s been trained on massive amounts of text, and has much richer knowledge</li>
</ul>
</section>
<section id="experiments-what-does-ambiguity-look-like-to-an-llm" class="level3">
<h3 class="anchored" data-anchor-id="experiments-what-does-ambiguity-look-like-to-an-llm">Experiments: What does ambiguity look like to an LLM?</h3>
<p>The goal of this first experiment is to look at what “ambigious” (multiple possibilities) looks like to the transformer model. Above, we focused on next token probabilities. Now we want to hone in on what happens right at the point where a sentence may diverge into two possible sentence structures. Recall in that we have no possibility for doing this with POS, Named Entities, or Dependency Graphs in SpaCy. They pick the n-best sequence.</p>
<div id="93841128-032f-4237-81ab-4ec64d1fa9da" class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COUPLING EXPERIMENT 1: Distribution at ambiguity point</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Cut point: Right after "with the" - what comes next?</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The cut point for our primary sentence</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>ambiguity_prompt <span class="op">=</span> <span class="st">"I saw the man with the"</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Prompt: '</span><span class="sc">{</span>ambiguity_prompt<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">At this point, the model must 'decide' what comes next."</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"If 'telescope' follows, interpretation leans INSTRUMENT."</span>)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"If a person-attribute word follows (hat, briefcase), it's ATTRIBUTE.</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>dist <span class="op">=</span> get_next_token_distribution(ambiguity_prompt, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 10 next-token predictions:"</span>)</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token, prob <span class="kw">in</span> dist:</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    bar <span class="op">=</span> <span class="st">'█'</span> <span class="op">*</span> <span class="bu">int</span>(prob <span class="op">*</span> <span class="dv">300</span>)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   '</span><span class="sc">{</span>token<span class="sc">:12}</span><span class="ss">' : </span><span class="sc">{</span>prob<span class="sc">:.4f}</span><span class="ss"> </span><span class="sc">{</span>bar<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Prompt: 'I saw the man with the'

At this point, the model must 'decide' what comes next.
If 'telescope' follows, interpretation leans INSTRUMENT.
If a person-attribute word follows (hat, briefcase), it's ATTRIBUTE.

Top 10 next-token predictions:
----------------------------------------
   ' sword      ' : 0.0262 ███████
   ' knife      ' : 0.0224 ██████
   ' black      ' : 0.0209 ██████
   ' gun        ' : 0.0187 █████
   ' mask       ' : 0.0167 █████
   ' head       ' : 0.0156 ████
   ' beard      ' : 0.0136 ████
   ' same       ' : 0.0125 ███
   ' red        ' : 0.0121 ███
   ' right      ' : 0.0099 ██</code></pre>
</div>
</div>
<p>Expected Observation:</p>
<ul>
<li>Distribution should be relatively SPREAD OUT (flat)</li>
<li>Multiple plausible continuations have non-trivial probability</li>
<li>This ‘flatness’ reflects genuine ambiguity!</li>
<li>Unlike spaCy’s single parse, the LM maintains uncertainty.</li>
</ul>
<p>Let’s see what happens when we push the LLM to look at two different structures.</p>
<div id="8e2677f9-a781-4fd4-9048-90a4aa2835b7" class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COUPLING EXPERIMENT 2: Forced-Choice Interpretation Scores</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Base prompt</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>base <span class="op">=</span> <span class="st">"I saw the man with the telescope"</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Continuations that force each interpretation</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>instrument_continuation <span class="op">=</span> <span class="st">" and got a clear view of his face."</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>attribute_continuation <span class="op">=</span> <span class="st">" standing on the corner."</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Base: '</span><span class="sc">{</span>base<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Continuation A (INSTRUMENT): '</span><span class="sc">{</span>instrument_continuation<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Continuation B (ATTRIBUTE):  '</span><span class="sc">{</span>attribute_continuation<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Score both</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>score_a <span class="op">=</span> score_continuation(base, instrument_continuation)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>score_b <span class="op">=</span> score_continuation(base, attribute_continuation)</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Scores (higher = more likely):"</span>)</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   INSTRUMENT: sum=</span><span class="sc">{</span>score_a[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, avg=</span><span class="sc">{</span>score_a[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss"> (</span><span class="sc">{</span>score_a[<span class="dv">2</span>]<span class="sc">}</span><span class="ss"> tokens)"</span>)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   ATTRIBUTE:  sum=</span><span class="sc">{</span>score_b[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, avg=</span><span class="sc">{</span>score_b[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss"> (</span><span class="sc">{</span>score_b[<span class="dv">2</span>]<span class="sc">}</span><span class="ss"> tokens)"</span>)</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>winner <span class="op">=</span> <span class="st">"INSTRUMENT"</span> <span class="cf">if</span> score_a[<span class="dv">1</span>] <span class="op">&gt;</span> score_b[<span class="dv">1</span>] <span class="cf">else</span> <span class="st">"ATTRIBUTE"</span></span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">   Model preference: </span><span class="sc">{</span>winner<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Base: 'I saw the man with the telescope'

Continuation A (INSTRUMENT): ' and got a clear view of his face.'
Continuation B (ATTRIBUTE):  ' standing on the corner.'

--------------------------------------------------
Scores (higher = more likely):
   INSTRUMENT: sum=-23.026, avg=-2.558 (9 tokens)
   ATTRIBUTE:  sum=-17.139, avg=-3.428 (5 tokens)

   Model preference: INSTRUMENT</code></pre>
</div>
</div>
<p>Again, the scoring uses <strong>log probabilities</strong> - here’s what that means:</p>
<p><strong>Log probability</strong>: Instead of multiplying tiny probabilities (which gets numerically unstable), we add their logarithms. Since probabilities are between 0 and 1, log probabilities are <strong>negative numbers</strong>. Less negative = more likely.</p>
<p><strong>The two scores reported</strong>: - <code>sum</code> - Total log probability across all tokens in the continuation - <code>avg</code> - Average log probability per token (sum divided by number of tokens)</p>
<p><strong>Why INSTRUMENT won despite lower sum?</strong> - INSTRUMENT: 9 tokens, sum = -23.026, <strong>avg = -2.558</strong> - ATTRIBUTE: 5 tokens, sum = -17.139, <strong>avg = -3.428</strong></p>
<p>The average is more fair for comparison because longer sequences naturally have more negative sums. The INSTRUMENT continuation has a better average probability per token (-2.558 vs -3.428), meaning each word is more “expected” by the model in that context.</p>
<div id="a4a9dee8-b509-47c4-a40c-7417011015ee" class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COUPLING EXPERIMENT 3: Complete side-by-side analysis</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define cut points and continuations for each sentence</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>experiments <span class="op">=</span> [</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: <span class="st">"Primary (ambiguous)"</span>,</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sentence"</span>: <span class="st">"I saw the man with the telescope."</span>,</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cut_prompt"</span>: <span class="st">"I saw the man with the"</span>,</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instrument_cont"</span>: <span class="st">" telescope and got a clear view."</span>,</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"attribute_cont"</span>: <span class="st">" telescope standing nearby."</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: <span class="st">"Rewrite 1 (attribute likely)"</span>,</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sentence"</span>: <span class="st">"I saw the man with the red hat."</span>,</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cut_prompt"</span>: <span class="st">"I saw the man with the red"</span>,</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instrument_cont"</span>: <span class="st">" hat and got a clear view."</span>,</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"attribute_cont"</span>: <span class="st">" hat standing nearby."</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: <span class="st">"Rewrite 2 (instrument likely)"</span>,</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sentence"</span>: <span class="st">"I saw the bird with the telescope."</span>,</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cut_prompt"</span>: <span class="st">"I saw the bird with the"</span>,</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instrument_cont"</span>: <span class="st">" telescope and got a clear view."</span>,</span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">"attribute_cont"</span>: <span class="st">" telescope perched nearby."</span></span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: <span class="st">"Rewrite 3 (instrument forced)"</span>,</span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sentence"</span>: <span class="st">"I saw the man with my telescope."</span>,</span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cut_prompt"</span>: <span class="st">"I saw the man with my"</span>,</span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instrument_cont"</span>: <span class="st">" telescope and got a clear view."</span>,</span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"attribute_cont"</span>: <span class="st">" telescope standing nearby."</span></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a>results_table <span class="op">=</span> []</span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> exp <span class="kw">in</span> experiments:</span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'─'</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"📝 </span><span class="sc">{</span>exp[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Sentence: </span><span class="sc">{</span>exp[<span class="st">'sentence'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-42"><a href="#cb53-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get spaCy parse</span></span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a>    nlp <span class="op">=</span> get_nlp()</span>
<span id="cb53-44"><a href="#cb53-44" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(exp[<span class="st">'sentence'</span>])</span>
<span id="cb53-45"><a href="#cb53-45" aria-hidden="true" tabindex="-1"></a>    with_token <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> doc <span class="cf">if</span> t.text.lower() <span class="op">==</span> <span class="st">"with"</span>][<span class="dv">0</span>]</span>
<span id="cb53-46"><a href="#cb53-46" aria-hidden="true" tabindex="-1"></a>    spacy_attachment <span class="op">=</span> with_token.head.text</span>
<span id="cb53-47"><a href="#cb53-47" aria-hidden="true" tabindex="-1"></a>    spacy_interp <span class="op">=</span> <span class="st">"INSTRUMENT"</span> <span class="cf">if</span> spacy_attachment <span class="kw">in</span> [<span class="st">"saw"</span>, <span class="st">"see"</span>] <span class="cf">else</span> <span class="st">"ATTRIBUTE"</span></span>
<span id="cb53-48"><a href="#cb53-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-49"><a href="#cb53-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get LM distribution</span></span>
<span id="cb53-50"><a href="#cb53-50" aria-hidden="true" tabindex="-1"></a>    dist <span class="op">=</span> get_next_token_distribution(exp[<span class="st">'cut_prompt'</span>], k<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb53-51"><a href="#cb53-51" aria-hidden="true" tabindex="-1"></a>    top_token <span class="op">=</span> dist[<span class="dv">0</span>][<span class="dv">0</span>].strip() <span class="cf">if</span> dist <span class="cf">else</span> <span class="st">"?"</span></span>
<span id="cb53-52"><a href="#cb53-52" aria-hidden="true" tabindex="-1"></a>    top_prob <span class="op">=</span> dist[<span class="dv">0</span>][<span class="dv">1</span>] <span class="cf">if</span> dist <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb53-53"><a href="#cb53-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-54"><a href="#cb53-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate entropy-like measure (is distribution sharp or flat?)</span></span>
<span id="cb53-55"><a href="#cb53-55" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> [p <span class="cf">for</span> _, p <span class="kw">in</span> dist[:<span class="dv">5</span>]]</span>
<span id="cb53-56"><a href="#cb53-56" aria-hidden="true" tabindex="-1"></a>    max_prob <span class="op">=</span> <span class="bu">max</span>(probs) <span class="cf">if</span> probs <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb53-57"><a href="#cb53-57" aria-hidden="true" tabindex="-1"></a>    sharpness <span class="op">=</span> <span class="st">"SHARP"</span> <span class="cf">if</span> max_prob <span class="op">&gt;</span> <span class="fl">0.3</span> <span class="cf">else</span> <span class="st">"FLAT"</span></span>
<span id="cb53-58"><a href="#cb53-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-59"><a href="#cb53-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Score continuations</span></span>
<span id="cb53-60"><a href="#cb53-60" aria-hidden="true" tabindex="-1"></a>    instr_score <span class="op">=</span> score_continuation(exp[<span class="st">'cut_prompt'</span>], exp[<span class="st">'instrument_cont'</span>])</span>
<span id="cb53-61"><a href="#cb53-61" aria-hidden="true" tabindex="-1"></a>    attr_score <span class="op">=</span> score_continuation(exp[<span class="st">'cut_prompt'</span>], exp[<span class="st">'attribute_cont'</span>])</span>
<span id="cb53-62"><a href="#cb53-62" aria-hidden="true" tabindex="-1"></a>    lm_preference <span class="op">=</span> <span class="st">"INSTRUMENT"</span> <span class="cf">if</span> instr_score[<span class="dv">1</span>] <span class="op">&gt;</span> attr_score[<span class="dv">1</span>] <span class="cf">else</span> <span class="st">"ATTRIBUTE"</span></span>
<span id="cb53-63"><a href="#cb53-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-64"><a href="#cb53-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   spaCy: 'with' → </span><span class="sc">{</span>spacy_attachment<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>spacy_interp<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb53-65"><a href="#cb53-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   LM top-1: '</span><span class="sc">{</span>top_token<span class="sc">}</span><span class="ss">' (</span><span class="sc">{</span>top_prob<span class="sc">:.3f}</span><span class="ss">), dist=</span><span class="sc">{</span>sharpness<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-66"><a href="#cb53-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   LM preference: </span><span class="sc">{</span>lm_preference<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-67"><a href="#cb53-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-68"><a href="#cb53-68" aria-hidden="true" tabindex="-1"></a>    results_table.append({</span>
<span id="cb53-69"><a href="#cb53-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Sentence"</span>: exp[<span class="st">'label'</span>][:<span class="dv">20</span>],</span>
<span id="cb53-70"><a href="#cb53-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">"spaCy Parse"</span>: spacy_interp,</span>
<span id="cb53-71"><a href="#cb53-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Top-1 Token"</span>: top_token[:<span class="dv">10</span>],</span>
<span id="cb53-72"><a href="#cb53-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Distribution"</span>: sharpness,</span>
<span id="cb53-73"><a href="#cb53-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">"LM Preference"</span>: lm_preference</span>
<span id="cb53-74"><a href="#cb53-74" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb53-75"><a href="#cb53-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-76"><a href="#cb53-76" aria-hidden="true" tabindex="-1"></a>summary_df <span class="op">=</span> pd.DataFrame(results_table)</span>
<span id="cb53-77"><a href="#cb53-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary_df.to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
────────────────────────────────────────────────────────────
📝 Primary (ambiguous)
   Sentence: I saw the man with the telescope.
✅ spaCy model 'en_core_web_sm' loaded successfully
   spaCy: 'with' → man (ATTRIBUTE)
   LM top-1: 'sword' (0.026), dist=FLAT
   LM preference: INSTRUMENT

────────────────────────────────────────────────────────────
📝 Rewrite 1 (attribute likely)
   Sentence: I saw the man with the red hat.
✅ spaCy model 'en_core_web_sm' loaded successfully
   spaCy: 'with' → man (ATTRIBUTE)
   LM top-1: '-' (0.069), dist=FLAT
   LM preference: INSTRUMENT

────────────────────────────────────────────────────────────
📝 Rewrite 2 (instrument likely)
   Sentence: I saw the bird with the telescope.
✅ spaCy model 'en_core_web_sm' loaded successfully
   spaCy: 'with' → saw (INSTRUMENT)
   LM top-1: 'eye' (0.027), dist=FLAT
   LM preference: INSTRUMENT

────────────────────────────────────────────────────────────
📝 Rewrite 3 (instrument forced)
   Sentence: I saw the man with my telescope.
✅ spaCy model 'en_core_web_sm' loaded successfully
   spaCy: 'with' → saw (INSTRUMENT)
   LM top-1: 'hands' (0.039), dist=FLAT
   LM preference: INSTRUMENT
            Sentence spaCy Parse Top-1 Token Distribution LM Preference
 Primary (ambiguous)   ATTRIBUTE       sword         FLAT    INSTRUMENT
Rewrite 1 (attribute   ATTRIBUTE           -         FLAT    INSTRUMENT
Rewrite 2 (instrumen  INSTRUMENT         eye         FLAT    INSTRUMENT
Rewrite 3 (instrumen  INSTRUMENT       hands         FLAT    INSTRUMENT</code></pre>
</div>
</div>
<p>Looking at this summary table, there are some interesting observations:</p>
<p><strong>SpaCy’s behavior</strong>: It makes a single parse decision for each sentence. It chose ATTRIBUTE for the ambiguous cases and INSTRUMENT when “my” appears (which is a strong syntactic cue).</p>
<p><strong>The LM’s behavior</strong>: It consistently prefers INSTRUMENT across all sentences when scoring the two continuations. However, notice the “Distribution” column shows FLAT for all - this means at the cut point, the model sees multiple plausible next words with similar probabilities, reflecting genuine uncertainty.</p>
<p><strong>The mismatch</strong>: The LM’s top-1 predictions (sword, hands, eye) don’t match the actual words in the sentences. This shows the model is considering many possibilities, not committing to one interpretation early.</p>
<p>What’s particularly interesting is that even though the distribution is FLAT (uncertain), when we force the model to score complete continuations, it shows a preference. Can you think on why this may be?</p>
<p>What aspect would you like to explore more - why the LM prefers INSTRUMENT, or how we might design better experiments to test these interpretations?</p>
</section>
<section id="reflection" class="level3">
<h3 class="anchored" data-anchor-id="reflection">Reflection</h3>
<p><strong>Questions:</strong></p>
<ol type="1">
<li><p>What does a next-token objective teach a model about syntax and meaning?</p></li>
<li><p>How does probability relate to ambiguity and “preference”?</p></li>
<li><p>Why might the LLM’s preference differ from spaCy’s parse?</p></li>
</ol>
<div id="5dbfadff" class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>q1_answer <span class="op">=</span> <span class="st">"Your answer about what next-token prediction teaches"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f15bb560" class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>q2_answer <span class="op">=</span> <span class="st">"Your answer about how probability relates to ambiguity and preference"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0a6e7d6b-2591-4aad-9c7b-f0a8b2a370bb" class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>q3_answer <span class="op">=</span> <span class="st">"Your answer about differences between LLM and spaCy parser"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-c-summary" class="level3">
<h3 class="anchored" data-anchor-id="part-c-summary">Part C Summary</h3>
<p>In this section, you learned:</p>
<ul>
<li><strong>Language models assign probabilities</strong> to sequences of words, predicting what comes next.</li>
<li><strong>Bigram models</strong> are simple (only one previous word) but suffer from sparsity—many word pairs never appear in training.</li>
<li><strong>Neural language models</strong> generalize better by learning patterns, not just memorizing pairs.</li>
<li><strong>Ambiguity shows up as flat distributions</strong>—when many continuations are plausible, no single prediction dominates.</li>
<li><strong>SpaCy commits to one parse</strong> while language models maintain probability over possibilities.</li>
<li><strong>Log probabilities</strong> let us compare how “expected” different continuations are.</li>
</ul>
</section>
</section>
<section id="part-d-sentiment-analysis" class="level2">
<h2 class="anchored" data-anchor-id="part-d-sentiment-analysis">Part D: Sentiment Analysis</h2>
<p>Now let’s turn to the application of NLP to real-world problems! We’ll look at both sentiment analysis and summarization. In both cases we’ll look at traditional, predictive methods and LLM’s to see how they differ.</p>
<p>Sentiment analysis determines whether text expresses positive, negative, or neutral feelings. This is one of the most common NLP applications—companies analyze customer reviews, social media monitors track brand perception, and researchers study public opinion.</p>
<p>We will compare two approaches: a traditional rule-based method (VADER) and an LLM-based method.</p>
<section id="classical-approach-vader" class="level3">
<h3 class="anchored" data-anchor-id="classical-approach-vader">Classical Approach: VADER</h3>
<p><strong>VADER</strong> (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based sentiment analyzer designed for social media text. It works by looking up words in a sentiment dictionary and applying rules for negation, intensifiers, and punctuation. We may spend time using it because it is easy to use, hack, and understand. Plus, you can use VADER output to help train another model.</p>
<div id="9c337f48-9820-4702-8885-38df00bef85e" class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> nltk.sentiment <span class="im">import</span> SentimentIntensityAnalyzer</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>    vader <span class="op">=</span> SentimentIntensityAnalyzer()</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">LookupError</span>:</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    nltk.download(<span class="st">"vader_lexicon"</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> nltk.sentiment <span class="im">import</span> SentimentIntensityAnalyzer</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    vader <span class="op">=</span> SentimentIntensityAnalyzer()</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize VADER</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>vader <span class="op">=</span> SentimentIntensityAnalyzer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fa84b3ef-5915-447b-946c-7473c644958c" class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sentiment-ambiguous test cases</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>test_utterances <span class="op">=</span> [</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Oh great, another meeting that could have been an email."</span>,  <span class="co"># Sarcasm</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The food was not unpleasant, I suppose."</span>,  <span class="co"># Double negative, hedged</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Why VADER? It’s a rule-based sentiment analyzer that uses:</p>
<ul>
<li>A sentiment lexicon (word → score mappings)</li>
<li>Grammatical rules (negation, intensifiers, etc.)</li>
<li>Punctuation and capitalization heuristics</li>
<li>Fast, deterministic, and interpretable!</li>
</ul>
<div id="02f4be16-c06d-4106-b351-dc293ce59c94" class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># VADER analysis</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>vader_results <span class="op">=</span> []</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> test_utterances:</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> vader.polarity_scores(text)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine label from compound score</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> scores[<span class="st">'compound'</span>] <span class="op">&gt;=</span> <span class="fl">0.05</span>:</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="st">"POSITIVE"</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> scores[<span class="st">'compound'</span>] <span class="op">&lt;=</span> <span class="op">-</span><span class="fl">0.05</span>:</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="st">"NEGATIVE"</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="st">"NEUTRAL"</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>    vader_results.append({</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"text"</span>: text[:<span class="dv">40</span>] <span class="op">+</span> <span class="st">"..."</span>,</span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: label,</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"compound"</span>: scores[<span class="st">'compound'</span>],</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"pos"</span>: scores[<span class="st">'pos'</span>],</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"neg"</span>: scores[<span class="st">'neg'</span>],</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"neu"</span>: scores[<span class="st">'neu'</span>]</span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Text: </span><span class="ch">\"</span><span class="sc">{</span>text<span class="sc">}</span><span class="ch">\"</span><span class="ss">"</span>)</span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Compound: </span><span class="sc">{</span>scores[<span class="st">'compound'</span>]<span class="sc">:.3f}</span><span class="ss"> → </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   (pos=</span><span class="sc">{</span>scores[<span class="st">'pos'</span>]<span class="sc">:.2f}</span><span class="ss">, neg=</span><span class="sc">{</span>scores[<span class="st">'neg'</span>]<span class="sc">:.2f}</span><span class="ss">, neu=</span><span class="sc">{</span>scores[<span class="st">'neu'</span>]<span class="sc">:.2f}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Text: "Oh great, another meeting that could have been an email."
   Compound: 0.625 → POSITIVE
   (pos=0.31, neg=0.00, neu=0.69)

Text: "The food was not unpleasant, I suppose."
   Compound: 0.372 → POSITIVE
   (pos=0.34, neg=0.00, neu=0.66)</code></pre>
</div>
</div>
<p>Look at the results: VADER labeled both sentences as positive! The first sentence is sarcastic—“great” is used ironically. The second has a double negative (“not unpleasant”) which VADER handled okay. This illustrates a key limitation of rule-based systems: they cannot understand context, irony, or nuance.</p>
</section>
<section id="llm-approach" class="level3">
<h3 class="anchored" data-anchor-id="llm-approach">LLM Approach</h3>
<p>LLMs can potentially catch subtleties that rule-based systems miss. If you have API access to an LLM, feel free to play with this to make it work with your API. If not, just read the output and follow along.</p>
<div id="e2feee3a-1ab6-413d-9f7e-b26d1c45c4cd" class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> safe_llm_unavailable_response(reason<span class="op">=</span><span class="st">"LLM unavailable"</span>):</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: <span class="st">"neutral"</span>,</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"confidence"</span>: <span class="fl">0.0</span>,</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rationale"</span>: reason,</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cues"</span>: []</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fbb53cae-e0c5-4477-80ae-c66c0dbbc41d" class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyze_sentiment_llm(text):</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Analyze sentiment using available LLM.</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Always returns (response_text, provider).</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Silently falls back if LLM is unavailable.</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> llm_available():</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>            json.dumps(</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>                safe_llm_unavailable_response(<span class="st">"LLM unavailable"</span>),</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>                ensure_ascii<span class="op">=</span><span class="va">False</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"unavailable"</span></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a><span class="ss">Analyze the sentiment of this text and respond with ONLY valid JSON.</span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a><span class="ss">Text: "</span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a><span class="ss">Respond with this exact JSON format (no other text):</span></span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a><span class="ch">{{</span></span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a><span class="ss">  "label": "positive" | "negative" | "neutral" | "mixed",</span></span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a><span class="ss">  "confidence": 0.0,</span></span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a><span class="ss">  "rationale": "brief explanation",</span></span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a><span class="ss">  "cues": []</span></span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a><span class="ch">}}</span></span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span></span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> chat(prompt)</span>
<span id="cb63-34"><a href="#cb63-34" aria-hidden="true" tabindex="-1"></a>        response_text <span class="op">=</span> response.choices[<span class="dv">0</span>].message.content</span>
<span id="cb63-35"><a href="#cb63-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> response_text, <span class="st">"llm"</span></span>
<span id="cb63-36"><a href="#cb63-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb63-37"><a href="#cb63-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb63-38"><a href="#cb63-38" aria-hidden="true" tabindex="-1"></a>            json.dumps(</span>
<span id="cb63-39"><a href="#cb63-39" aria-hidden="true" tabindex="-1"></a>                safe_llm_unavailable_response(<span class="st">"LLM call failed"</span>),</span>
<span id="cb63-40"><a href="#cb63-40" aria-hidden="true" tabindex="-1"></a>                ensure_ascii<span class="op">=</span><span class="va">False</span></span>
<span id="cb63-41"><a href="#cb63-41" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb63-42"><a href="#cb63-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"error"</span></span>
<span id="cb63-43"><a href="#cb63-43" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5f96289e-f5e1-469a-9f49-53403ebf827f" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse_sentiment_json(response_text):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Safely parse JSON from LLM response."""</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> re</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Try to extract JSON from response</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First try direct parse</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> json.loads(response_text)</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Try to find JSON in the response</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>        json_match <span class="op">=</span> re.search(<span class="vs">r'\{[^}]+\}'</span>, response_text, re.DOTALL)</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> json_match:</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> json.loads(json_match.group())</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return error structure</span></span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"label"</span>: <span class="st">"parse_error"</span>,</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"confidence"</span>: <span class="dv">0</span>,</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rationale"</span>: <span class="ss">f"Could not parse: </span><span class="sc">{</span>response_text[:<span class="dv">100</span>]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cues"</span>: []</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2db2523b-7419-4026-830d-d20679221a0d" class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze each utterance</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>llm_results <span class="op">=</span> []</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> test_utterances:</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Text: </span><span class="ch">\"</span><span class="sc">{</span>text<span class="sc">}</span><span class="ch">\"</span><span class="ss">"</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    response, provider <span class="op">=</span> analyze_sentiment_llm(text)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Provider: </span><span class="sc">{</span>provider<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>    parsed <span class="op">=</span> parse_sentiment_json(response)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    llm_results.append(parsed)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Label: </span><span class="sc">{</span>parsed<span class="sc">.</span>get(<span class="st">'label'</span>, <span class="st">'N/A'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Confidence: </span><span class="sc">{</span>parsed<span class="sc">.</span>get(<span class="st">'confidence'</span>, <span class="st">'N/A'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Rationale: </span><span class="sc">{</span>parsed<span class="sc">.</span>get(<span class="st">'rationale'</span>, <span class="st">'N/A'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Cues: </span><span class="sc">{</span>parsed<span class="sc">.</span>get(<span class="st">'cues'</span>, [])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(llm_results) <span class="op">&lt;</span> <span class="bu">len</span>(test_utterances):</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Some LLM sentiment analyses failed; comparison table may be incomplete."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Text: "Oh great, another meeting that could have been an email."
   Provider: llm
   Label: negative
   Confidence: 0.95
   Rationale: The phrase uses sarcasm ('Oh great') to express frustration about an unnecessary meeting, indicating clear dissatisfaction.
   Cues: ['Oh great', 'could have been an email', 'sarcastic tone', 'frustration with unnecessary meetings']

Text: "The food was not unpleasant, I suppose."
   Provider: llm
   Label: mixed
   Confidence: 0.75
   Rationale: The double negative 'not unpleasant' suggests mild approval, but the hesitant phrase 'I suppose' indicates lukewarm enthusiasm and uncertainty, creating an overall ambivalent tone.
   Cues: ['not unpleasant', 'I suppose', 'double negative', 'hesitant tone', 'lack of enthusiasm']</code></pre>
</div>
</div>
<p>If you’ve run this cell and lost the output, you can use this:</p>
<p>Text: “Oh great, another meeting that could have been an email.” Provider: llm Label: negative Confidence: 0.95 Rationale: The phrase uses sarcasm (‘Oh great’) to express frustration about an unnecessary meeting, indicating clear dissatisfaction. Cues: [‘Oh great’, ‘could have been an email’, ‘sarcastic tone’, ‘frustration with unnecessary meetings’]</p>
<p>Text: “The food was not unpleasant, I suppose.” Provider: llm Label: mixed Confidence: 0.75 Rationale: The double negative ‘not unpleasant’ suggests mild approval, but the hesitant phrase ‘I suppose’ indicates lukewarm enthusiasm and uncertainty, creating an overall ambivalent tone. Cues: [‘not unpleasant’, ‘I suppose’, ‘double negative’, ‘hesitant tone’, ‘lack of enthusiasm’]</p>
<p>#### Comparision of VADER and LLM</p>
<div id="adf9c1cd-5fd0-424d-8056-e2440b265754" class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparison table</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"📊 COMPARISON: VADER vs LLM"</span>)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>comparison_data <span class="op">=</span> []</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(test_utterances):</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>    comparison_data.append({</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Text (truncated)"</span>: text[:<span class="dv">35</span>] <span class="op">+</span> <span class="st">"..."</span>,</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"VADER Label"</span>: vader_results[i][<span class="st">'label'</span>],</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"VADER Score"</span>: <span class="ss">f"</span><span class="sc">{</span>vader_results[i][<span class="st">'compound'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>,</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"LLM Label"</span>: llm_results[i].get(<span class="st">'label'</span>, <span class="st">'N/A'</span>),</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"LLM Conf"</span>: <span class="ss">f"</span><span class="sc">{</span>llm_results[i]<span class="sc">.</span>get(<span class="st">'confidence'</span>, <span class="dv">0</span>)<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>comparison_df <span class="op">=</span> pd.DataFrame(comparison_data)</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comparison_df.to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
📊 COMPARISON: VADER vs LLM
======================================================================
                      Text (truncated) VADER Label VADER Score LLM Label LLM Conf
Oh great, another meeting that coul...    POSITIVE        0.62  negative     0.95
The food was not unpleasant, I supp...    POSITIVE        0.37     mixed     0.65</code></pre>
</div>
</div>
<ul>
<li>Where did VADER fail? Why?</li>
<li>Did the LLM catch sarcasm/nuance that VADER missed?</li>
<li>What ‘cues’ did the LLM identify?</li>
<li>Which would you trust more for: customer reviews? tweets? emails?</li>
</ul>
<p><strong>Submit:</strong> Answer these questions:</p>
<ol type="1">
<li><p>For the sarcastic sentence, how did VADER’s label compare to the LLM’s? What caused any difference?</p></li>
<li><p>What are two scenarios where you’d prefer VADER over an LLM, and two where you’d prefer the LLM?</p></li>
</ol>
<div id="358bda3a" class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>q4_answer <span class="op">=</span> <span class="st">"Your analysis of sarcasm handling"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f2cd5e17" class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>q5_answer <span class="op">=</span>  <span class="st">"Prefer VADER for scenario 1 or scenario 2?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="89a73ac5-9003-4a5b-9e0b-f7ffb61ca6c8" class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>q6_answer <span class="op">=</span> <span class="st">"Prefer LLM for scenario 1 or scenario 2?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-d-summary" class="level3">
<h3 class="anchored" data-anchor-id="part-d-summary">Part D Summary</h3>
<p>In this section, you learned about how to use spaCy for a real-world task.</p>
<ul>
<li><strong>Sentiment analysis</strong> classifies text as positive, negative, or neutral.</li>
<li><strong>VADER</strong> is fast, interpretable, and rule-based, but misses sarcasm, irony, and nuance.</li>
<li><strong>LLMs</strong> can capture subtleties but are slower, more expensive, and less predictable.</li>
<li><strong>Choose your tool based on your needs</strong>: high volume and simple text favors VADER; nuanced analysis favors LLMs.</li>
</ul>
</section>
</section>
<section id="part-e-spacy-pipeline-with-llm-summarization" class="level2">
<h2 class="anchored" data-anchor-id="part-e-spacy-pipeline-with-llm-summarization">Part E: SpaCy Pipeline with LLM Summarization</h2>
<p>One of spaCy’s most powerful features is its modular pipeline architecture. You can add, remove, or customize components to build exactly the NLP system you need. In this section, we will explore how to create custom components and compare different approaches to summarization.</p>
<p>Let us explore how NLP systems can be built as pipelines of components and how this differs from end-to-end LLM approaches. Again, do not worry about the code details—just think through this conceptually.</p>
<div id="c22d336a-9e98-4642-b820-36fb8fdf1073" class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># You've already seen a default spaCy pipeline architecture like this</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, component <span class="kw">in</span> nlp.pipeline:</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">type</span>(component)<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tok2vec: Tok2Vec
tagger: Tagger
parser: DependencyParser
attribute_ruler: AttributeRuler
lemmatizer: EnglishLemmatizer
ner: EntityRecognizer</code></pre>
</div>
</div>
<section id="custom-spacy-component" class="level4">
<h4 class="anchored" data-anchor-id="custom-spacy-component">Custom SpaCy component</h4>
<p>Let’s build an component that flags a sentence for both ORG and DATE.</p>
<p><strong>Custom components</strong> are functions that process a <code>Doc</code> object and return it (possibly modified). They get added to the pipeline and run automatically when you call <code>nlp(text)</code>.</p>
<p>Here’s the basic structure:</p>
<div id="1b76237c" class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="at">@spacy.Language.component</span>(<span class="st">"component_name"</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> custom_component(doc):</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Do something with doc</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You can add custom attributes, modify tokens, etc.</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add it to the pipeline</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>nlp.add_pipe(<span class="st">"component_name"</span>, last<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;function __main__.custom_component(doc)&gt;</code></pre>
</div>
</div>
<p>For this specific task – flagging sentences with both ORG and DATE entities), we want to:</p>
<ol type="1">
<li>Iterate through the doc’s sentences</li>
<li>Check what entity types appear in each sentence</li>
<li>Store a flag somewhere (maybe as a custom attribute on the <strong><code>Span</code></strong> - a slice of a doc object)</li>
</ol>
<div id="5333028c-7e96-470a-b931-dbdd38ed0225" class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a custom spaCy component</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spacy.language <span class="im">import</span> Language</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spacy.tokens <span class="im">import</span> Doc</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a><span class="at">@Language.component</span>(<span class="st">"org_date_flagger"</span>)</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> org_date_flagger(doc):</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Flag sentences that contain both ORG and DATE entities."""</span></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add custom attribute to doc if not exists</span></span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> doc.has_extension(<span class="st">"flagged_sentences"</span>):</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> spacy.tokens <span class="im">import</span> Doc</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>        Doc.set_extension(<span class="st">"flagged_sentences"</span>, default<span class="op">=</span>[])</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a>    flagged <span class="op">=</span> []</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sent <span class="kw">in</span> doc.sents:</span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>        sent_ents <span class="op">=</span> [ent.label_ <span class="cf">for</span> ent <span class="kw">in</span> sent.ents]</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"ORG"</span> <span class="kw">in</span> sent_ents <span class="kw">and</span> <span class="st">"DATE"</span> <span class="kw">in</span> sent_ents:</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a>            flagged.append(sent.text)</span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a>    doc._.flagged_sentences <span class="op">=</span> flagged</span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc</span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Add to pipeline (only if not already there)</span></span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"org_date_flagger"</span> <span class="kw">not</span> <span class="kw">in</span> nlp.pipe_names:</span>
<span id="cb76-24"><a href="#cb76-24" aria-hidden="true" tabindex="-1"></a>    nlp.add_pipe(<span class="st">"org_date_flagger"</span>, last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb76-25"><a href="#cb76-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-26"><a href="#cb76-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Updated pipeline: </span><span class="sc">{</span>nlp<span class="sc">.</span>pipe_names<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Updated pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'component_name', 'org_date_flagger']</code></pre>
</div>
</div>
<p>The <code>doc._</code> syntax is spaCy’s way of accessing <strong>custom extensions</strong> that you’ve added to a Doc object.</p>
<p>Here’s why this design:</p>
<p><strong>Built-in attributes</strong> use direct access: - <code>doc.ents</code> (entities) - <code>doc.text</code> (text) - <code>token.pos_</code> (part of speech)</p>
<p><strong>Custom attributes</strong> use the underscore namespace: - <code>doc._.flagged_sentences</code> (your custom attribute) - <code>token._.custom_score</code> (if you created this)</p>
<p>This separation prevents naming conflicts—your custom <code>flagged_sentences</code> won’t accidentally override something built into spaCy. It also makes it clear when you’re using custom vs.&nbsp;built-in functionality.</p>
<p>The underscore is a special namespace that spaCy reserves for user extensions. You must register extensions with <code>Doc.set_extension()</code> before using them, which is what the code does with the <code>if not doc.has_extension()</code> check.</p>
<div id="f31c8288-601a-4bfe-a936-6ea6ff029e3e" class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the custom component</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>test_text <span class="op">=</span> <span class="st">"""Microsoft announced record earnings on January 24th, 2024.</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="st">The weather was sunny. Apple plans to release new products in March.</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="st">John went to the store."""</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(test_text)</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Test text:"</span>)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_text)</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st"> Sentences containing both ORG and DATE:</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sent <span class="kw">in</span> doc._.flagged_sentences:</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(sent)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Test text:
Microsoft announced record earnings on January 24th, 2024.
The weather was sunny. Apple plans to release new products in March.
John went to the store.


 Sentences containing both ORG and DATE:


Microsoft announced record earnings on January 24th, 2024.

Apple plans to release new products in March.
</code></pre>
</div>
</div>
<div id="f9a704c3-8ab6-4343-a99a-3af141f54968" class="cell">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>article <span class="op">=</span> <span class="st">"In the Blue Ridge, the Christmas season was celebrated for days on end, with gatherings of family and friends, good food, and lots of music. This was especially true in the area known as Round Peak, around Mount Airy, North Carolina, and Galax, Virginia. The tradition was called Breaking up Christmas, and December 25th was just the beginning. Starting on Christmas and continuing for 12 days,people in the mountains would go from house to house viisiting neighbors, dancing and playing music."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9983a300-4199-480a-bfae-fc07a8bbc770" class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical extractive summarizer</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extractive_summarize(text, num_sentences<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Simple extractive summarizer using TF and entity presence."""</span></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    nlp <span class="op">=</span> get_nlp()</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(text)</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get term frequencies (excluding stop words)</span></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>    word_freq <span class="op">=</span> Counter()</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> token.is_stop <span class="kw">and</span> <span class="kw">not</span> token.is_punct <span class="kw">and</span> token.is_alpha:</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>            word_freq[token.lemma_.lower()] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Score each sentence</span></span>
<span id="cb81-17"><a href="#cb81-17" aria-hidden="true" tabindex="-1"></a>    sentence_scores <span class="op">=</span> []</span>
<span id="cb81-18"><a href="#cb81-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sent <span class="kw">in</span> doc.sents:</span>
<span id="cb81-19"><a href="#cb81-19" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb81-20"><a href="#cb81-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># TF score</span></span>
<span id="cb81-21"><a href="#cb81-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> token <span class="kw">in</span> sent:</span>
<span id="cb81-22"><a href="#cb81-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> token.lemma_.lower() <span class="kw">in</span> word_freq:</span>
<span id="cb81-23"><a href="#cb81-23" aria-hidden="true" tabindex="-1"></a>                score <span class="op">+=</span> word_freq[token.lemma_.lower()]</span>
<span id="cb81-24"><a href="#cb81-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb81-25"><a href="#cb81-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bonus for entities</span></span>
<span id="cb81-26"><a href="#cb81-26" aria-hidden="true" tabindex="-1"></a>        entity_bonus <span class="op">=</span> <span class="bu">len</span>([e <span class="cf">for</span> e <span class="kw">in</span> sent.ents]) <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb81-27"><a href="#cb81-27" aria-hidden="true" tabindex="-1"></a>        score <span class="op">+=</span> entity_bonus</span>
<span id="cb81-28"><a href="#cb81-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb81-29"><a href="#cb81-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize by length</span></span>
<span id="cb81-30"><a href="#cb81-30" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> score <span class="op">/</span> (<span class="bu">len</span>(<span class="bu">list</span>(sent)) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb81-31"><a href="#cb81-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb81-32"><a href="#cb81-32" aria-hidden="true" tabindex="-1"></a>        sentence_scores.append((sent.text.strip(), score))</span>
<span id="cb81-33"><a href="#cb81-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb81-34"><a href="#cb81-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort by score and return top sentences</span></span>
<span id="cb81-35"><a href="#cb81-35" aria-hidden="true" tabindex="-1"></a>    sorted_sents <span class="op">=</span> <span class="bu">sorted</span>(sentence_scores, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb81-36"><a href="#cb81-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sorted_sents[:num_sentences]</span>
<span id="cb81-37"><a href="#cb81-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-38"><a href="#cb81-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-39"><a href="#cb81-39" aria-hidden="true" tabindex="-1"></a>extracted <span class="op">=</span> extractive_summarize(article, num_sentences<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb81-40"><a href="#cb81-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Top sentences (by TF + entity score):"</span>)</span>
<span id="cb81-41"><a href="#cb81-41" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (sent, score) <span class="kw">in</span> <span class="bu">enumerate</span>(extracted, <span class="dv">1</span>):</span>
<span id="cb81-42"><a href="#cb81-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. (score: </span><span class="sc">{</span>score<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb81-43"><a href="#cb81-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   </span><span class="sc">{</span>sent<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb81-44"><a href="#cb81-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-45"><a href="#cb81-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Note: Extractive = select existing sentences, transparent scoring"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ spaCy model 'en_core_web_sm' loaded successfully

Top sentences (by TF + entity score):

1. (score: 0.88)
   This was especially true in the area known as Round Peak, around Mount Airy, North Carolina, and Galax, Virginia.

2. (score: 0.82)
   Starting on Christmas and continuing for 12 days,people in the mountains would go from house to house viisiting neighbors, dancing and playing music.

💡 Note: Extractive = select existing sentences, transparent scoring</code></pre>
</div>
</div>
<p>This simple summarizer ranks existing sentences using a simple heuristic score.</p>
<ul>
<li>Compute term frequencies over non-stopword lemmas.</li>
<li>Score each sentence by summing its term frequencies, adding a bonus for named entities, and normalizing by sentence length.</li>
<li>Return the top-scoring sentences as the summary.</li>
</ul>
<p>The method is fast, deterministic, and transparent, but it reflects its assumptions (e.g., entities ≈ importance) rather than true semantic understanding.</p>
<p>Let’s think through why that first sentence scored higher:</p>
<p><strong>The first sentence</strong> has: - Multiple entities: “Round Peak”, “Mount Airy”, “North Carolina”, “Galax”, “Virginia” (5 GPE entities!) - Entity bonus: 5 entities × 2 = +10 to the score - This entity bonus significantly boosted its score</p>
<p><strong>The second sentence</strong> has: - More thematic words (“Christmas”, “mountains”, “house”, “music”) - But fewer named entities - Lower entity bonus</p>
<p>The algorithm assumes entities = importance, which isn’t always true. The first sentence is actually providing geographic context, while the second describes the actual tradition.</p>
<p>This is a classic problem with simple extractive summarizers—they use heuristics (like “entities are important”) that don’t always align with what humans find most relevant.</p>
<p>Can you think of how you might modify the scoring to better capture the main idea of this passage?</p>
<div id="2a7ef10a-399d-4fd3-8bda-eb34ccd93697" class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> llm_summarize(text):</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate abstractive summary using available LLM.</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Silently falls back if LLM is unavailable.</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Always returns plain text.</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> llm_available():</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"HEADLINE: Summary unavailable</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• LLM disabled or unavailable</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Skipping abstractive summarization</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Proceeding with notebook execution"</span></span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a><span class="ss">Summarize this article in exactly:</span></span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- 3 bullet points (key facts)</span></span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- 1 headline (max 10 words)</span></span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-22"><a href="#cb83-22" aria-hidden="true" tabindex="-1"></a><span class="ss">Article:</span></span>
<span id="cb83-23"><a href="#cb83-23" aria-hidden="true" tabindex="-1"></a><span class="sc">{</span>text<span class="sc">}</span></span>
<span id="cb83-24"><a href="#cb83-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-25"><a href="#cb83-25" aria-hidden="true" tabindex="-1"></a><span class="ss">Format exactly as:</span></span>
<span id="cb83-26"><a href="#cb83-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-27"><a href="#cb83-27" aria-hidden="true" tabindex="-1"></a><span class="ss">HEADLINE: &lt;headline&gt;</span></span>
<span id="cb83-28"><a href="#cb83-28" aria-hidden="true" tabindex="-1"></a><span class="ss">• &lt;bullet 1&gt;</span></span>
<span id="cb83-29"><a href="#cb83-29" aria-hidden="true" tabindex="-1"></a><span class="ss">• &lt;bullet 2&gt;</span></span>
<span id="cb83-30"><a href="#cb83-30" aria-hidden="true" tabindex="-1"></a><span class="ss">• &lt;bullet 3&gt;</span></span>
<span id="cb83-31"><a href="#cb83-31" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span></span>
<span id="cb83-32"><a href="#cb83-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-33"><a href="#cb83-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb83-34"><a href="#cb83-34" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> chat(prompt)</span>
<span id="cb83-35"><a href="#cb83-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># handle both raw string and ModelResponse</span></span>
<span id="cb83-36"><a href="#cb83-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(response, <span class="st">"choices"</span>):</span>
<span id="cb83-37"><a href="#cb83-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content</span>
<span id="cb83-38"><a href="#cb83-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">str</span>(response)</span>
<span id="cb83-39"><a href="#cb83-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-40"><a href="#cb83-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb83-41"><a href="#cb83-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb83-42"><a href="#cb83-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"HEADLINE: Summary unavailable</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb83-43"><a href="#cb83-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• LLM call failed</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb83-44"><a href="#cb83-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• No impact on remaining analysis</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb83-45"><a href="#cb83-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">"• Safe fallback applied"</span></span>
<span id="cb83-46"><a href="#cb83-46" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e382246c-48b1-4c2f-9de5-7f11662bf25c" class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>summary_text <span class="op">=</span> llm_summarize(article)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>HEADLINE: Blue Ridge Christmas Celebrated for 12 Days

• Breaking up Christmas was a traditional 12-day celebration in the Blue Ridge region around Mount Airy, NC and Galax, VA
• The festivities began on December 25th and featured family gatherings, food, and extensive music and dancing
• Mountain residents traveled house to house visiting neighbors throughout the entire celebration period</code></pre>
</div>
</div>
<p>If you ran this cell and lost the LLM output, you can use this:</p>
<p>HEADLINE: Blue Ridge Christmas Celebrated for 12 Days</p>
<p>• Breaking up Christmas was a traditional 12-day celebration in the Blue Ridge region around Mount Airy, NC and Galax, VA • The festivities began on December 25th and featured family gatherings, food, and extensive music and dancing • Mountain residents traveled house to house visiting neighbors throughout the entire celebration period</p>
<p>As you may already know, LLMs are <strong>non-deterministic</strong> (can produce different outputs from the same input) and can:</p>
<ul>
<li>Hallucinate facts not in the original</li>
<li>Over-generalize or lose nuance</li>
</ul>
</section>
<section id="reflection-1" class="level4">
<h4 class="anchored" data-anchor-id="reflection-1">Reflection</h4>
<p><strong>Submit:</strong></p>
<ol type="1">
<li><p>What are two advantages of spaCy’s modular pipeline approach?</p></li>
<li><p>When would you choose extractive over abstractive summarization?</p></li>
</ol>
<div id="89bd6f8f" class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>q7_answer <span class="op">=</span> <span class="st">"Your answer about pipeline advantages"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="af5d94da-5c70-405f-81ab-2ebba47cc10b" class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>q8_answer <span class="op">=</span> <span class="st">"Your answer about summarization choice"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-e-summary" class="level3">
<h3 class="anchored" data-anchor-id="part-e-summary">Part E Summary</h3>
<p>In this section, we tackled a different task and showed you the flexibility of spaCy to incorporate custom components:</p>
<ul>
<li><strong>SpaCy pipelines are modular</strong>—you can add custom components that run automatically when processing text.</li>
<li><strong>Custom extensions</strong> (accessed via <code>doc._</code>) let you attach your own data to Doc, Span, or Token objects.</li>
<li><strong>Extractive summarization</strong> selects existing sentences based on scoring heuristics—transparent but limited.</li>
<li><strong>Abstractive summarization</strong> (LLM) generates new text—flexible but can hallucinate or lose nuance.</li>
<li><strong>Choose based on your needs</strong>: extractive for verifiable, traceable summaries; abstractive for readable, condensed versions.</li>
</ul>
</section>
</section>
<section id="part-f-reflection" class="level2">
<h2 class="anchored" data-anchor-id="part-f-reflection">Part F: Reflection</h2>
<p>Let us summarize everything we covered in this notebook. This lab covered a lot of ground in NLP! Here’s what you explored:</p>
<p><strong>Core NLP Components (SpaCy)</strong>: - Tokens and their attributes (lemmas, POS tags, stop words) - Named Entity Recognition (NER) - how models tag entities and why they sometimes get it wrong - Dependency parsing - understanding relationships between words in sentences</p>
<p><strong>Language Models as Probability Distributions</strong>: - Bigram models vs.&nbsp;neural language models (DistilGPT2) - Next-token prediction and what probability distributions reveal about ambiguity - How LMs handle syntactic ambiguity differently than parsers (maintaining uncertainty vs.&nbsp;committing to one parse)</p>
<p><strong>Practical Applications</strong>: - Sentiment analysis: rule-based (VADER) vs.&nbsp;LLM approaches - Summarization: extractive (selecting sentences) vs.&nbsp;abstractive (generating new text) - Building custom SpaCy pipeline components</p>
<p><strong>Key Insight</strong>: Different NLP approaches have different strengths - modular pipelines are transparent and fast, while LLMs capture nuance but are less interpretable.</p>
<p>What part did you find most interesting or want to explore more?</p>
<p><strong>Submit:</strong> 1. What did you find most interesting in this lab? 2. Was there something you found surprising?</p>
<div id="a3d35643" class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>q9_answer <span class="op">=</span> <span class="st">"What you found most interesting in the lab"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f2c61487-8ce4-4be7-b518-8824435a812e" class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>q10_answer <span class="op">=</span> <span class="st">"Whether you found something surprising"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="submit-notebook-for-credit" class="level2">
<h2 class="anchored" data-anchor-id="submit-notebook-for-credit">Submit Notebook for credit</h2>
<p>Instructions: replace “test_student” with your name and run the cell. You will see your answers printed as feedback. If you wish to change your answers… just re-submit.</p>
<p>Feel free to use AI as feedback on your answers after you’ve tried to answer questions yourself. I’ll scan responses to see what might have been confusing in the lab. Lab questions are ungraded and we can talk about your thoughts or questions in class.</p>
<div id="1121b90f-a01c-4111-9611-0cfc45e484f8" class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># REVIEW ONLY — does not submit</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data401_nlp.helpers.submit <span class="im">import</span> collect_answers, parse_answers, submit_answers</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="co"># REVIEW ONLY — does not submit</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>raw <span class="op">=</span> collect_answers(</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>    show<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>    namespace<span class="op">=</span><span class="bu">globals</span>(),   </span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>answers <span class="op">=</span> parse_answers(raw)</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Detected </span><span class="sc">{</span><span class="bu">len</span>(answers)<span class="sc">}</span><span class="ss"> answers:"</span>)</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> answers:</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">" "</span>, k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="de0111f3-62e8-43e5-bce9-4c8a563d7e17" class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>ALLOW_SUBMISSION <span class="op">=</span> <span class="va">False</span>   <span class="co"># ← student MUST change this</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> submit_for_credit(student_id):</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ALLOW_SUBMISSION:</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">RuntimeError</span>(</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"⚠️ Submission is disabled.</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"To submit:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  1. Set ALLOW_SUBMISSION = True</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  2. Re-run this cell"</span></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>    submit_answers(</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>        student_id<span class="op">=</span>student_id,</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>        answers<span class="op">=</span>answers,   <span class="co"># uses reviewed answers</span></span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✅ Submission complete."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="73c4d274" class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Don't forget to edit with your name</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>submit_for_credit(<span class="st">"your name"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: ⚠️ Submission is currently disabled.

To submit:
  1. Review your answers
  2. Set ALLOW_SUBMISSION = True
  3. Re-run this cell</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: ⚠️ Submission is disabled.

To submit:
  1. Set ALLOW_SUBMISSION = True
  2. Re-run this cell</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/su-dataAI/data401-nlp/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>