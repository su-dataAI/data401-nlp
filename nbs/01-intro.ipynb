{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the SpaCy pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preface**\n",
    "\n",
    "This notebook represents a departure from the usual order in which one learns basic concepts in NLP. And, perhaps, in this LLM era, there is no usual progression anymore! \n",
    "\n",
    "Pedagogically, **[Jurafsky and Martin (3rd. ed.)](https://web.stanford.edu/~jurafsky/slp3/)** sets a standard by which many follow. Yet, it's an incredibly lengthy and dense book oriented largely towards graduate students.\n",
    "\n",
    "The challenge is learning NLP using an incremental and human language-centered approach to NLP, while also committing to libraries that students will be expected to know as data scientists in the work environment. \n",
    "\n",
    "\n",
    "**[SpaCy v.3](https://spacy.io)** provides a staggeringly rich ecosystem for NLP development suitable both for data science experimentation and enterprise deployment. It is a defacto industry standard that integrates well with other common tools used by data scientists.\n",
    "\n",
    "This notebook is a whirlwind tour of spaCy. You will gain familiarity with spaCy container objects -- notably, **Doc** (sequence of token objects) and **Token** objects. Tokens themselves contain text annotations as processed by components in the spaCy pipeline. *Don't worry if you don't understand everything that's going on. The hope is that by the end of the class, you will!*\n",
    "\n",
    "This notebook is also designed to tackle linguistic concepts as we encounter them, while starting from the most natural place to learn linguistic processing -- within the spaCy pipeline.\n",
    "\n",
    "Finally, we're going to tackle learning traditional NLP methods alongside LLMs. Traditional methods include predictive AI methods that well complement generative AI techniques. We're going to think about when and how to use both... and sometimes together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related resources:\n",
    "- This is a very thorough overview of SpaCy worth skimming! https://deepnote.com/blog/ultimate-guide-to-the-spacy-library-in-python.\n",
    "- You will also be working your way through the spaCy tutorial here (https://course.spacy.io/en) over the first half of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "\n",
    "- Introduction to core NLP components and spaCy pipeline\n",
    "- Introduction to tokens and their attributes\n",
    "- Introduction to language models as probability distributions\n",
    "    - Bigram models\n",
    "    - Neural language models\n",
    "- Thought exercise: Traditional NLP vs LLMs\n",
    "    - Sentiment analysis\n",
    "    - Summarization\n",
    "- Demonstration of flexible SpaCy pipelines incorporating LLM components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your goal** is to read this notebook and experiment as you like. I used AI copiously to give you a sense of how you might use AI to learn a new library. \n",
    "\n",
    "As a student, **you are responsible for answering all questions in the reflection sections**. But I hope you think of your own questions and do some exploration.\n",
    "\n",
    "I created this notebook in the [Solveit environment](https://solve.it.com), so there is much dialog where I work with AI to learn and expose capabilities in spaCy. Wherever you see this, ðŸ¤–ReplyðŸ¤–, it's Claude inside of Solveit answering questions that I've posed. (In some cases, I've post-edited these responses.) Having such assistance makes it possible to learn and do more than one might, otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "import os\n",
    "import fastcore.tools as fc\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import orjson\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # used by submit helper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spaCy library requires model downloads. We're using the English pipeline optimized for CPU (en_core_web_sm). When you visit this URL (https://spacy.io/models/en#en_core_web_sm), you'll find more information such as training data sources, type of text used for training, size, label schemas, metrics, and components available. We'll play around with most of these components over the next 6 weeks or so, before moving on to transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model en_core_web_sm loaded\n"
     ]
    }
   ],
   "source": [
    "# load spacy\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model en_core_web_sm loaded\")\n",
    "except OSError:\n",
    "    print(\"spaCy model not found. Running download...\")\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model loaded after download!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we're loading some utility libs that will be used for LLM prompting later in the notebook. Your model is currently set to claude, though you can change it to OpenAI by `LLM_MODELS[0]`\n",
    "\n",
    "It is easy to extend the helper to accommodate others and send a [pull request](https://github.com/su-dataAI/data401-nlp/pulls) to me, if you use a different model that you'd like added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data401_nlp.helpers.env import load_env\n",
    "from data401_nlp.helpers.llm import make_chat, LLM_MODELS\n",
    "\n",
    "load_env()\n",
    "chat = make_chat(LLM_MODELS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [listette library](https://lisette.answer.ai) wraps the litellm library and makes it possible for us to add models with API keys to this notebook. I've included it in helper functions behind the scenes.\n",
    "\n",
    "You don't need a subscription or API access, if you don't have it already. Use these notebooks as \"read-only\" for those sections. But if you do have a key, do use it!\n",
    "\n",
    "1. **Use Colab's Secrets feature** (recommended) - store keys in Colab's built-in secrets manager\n",
    "2. **Set environment variables** manually in your notebook\n",
    "3. **Use a `.env` file** (though this requires uploading it each session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Test out a SpaCy pipeline (Tokens, POS, NER, and parse trees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Doc** object is just a container for data. When we add structure to text, we'll be able to access annotations from it. We use the **nlp** object to provide the processing pipeline to create, enrich, and manage Docs. The first thing it does is run tokenization and then pipeline components.\n",
    "\n",
    "We will use one Doc object per text. So for example, a news article from a collection of articles, would be contaied in a Doc object. Or an Amazon review would be contained within its own Doc object. We'll see why this helps later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. Sarah Chen joined Anthropic in San Francisco on January 15, 2024. She previously worked at Google Brain, where she led a team developing language models that could process over 100,000 tokens per second."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample text with multiple entities and interesting linguistic features\n",
    "sample_text = \"\"\"Dr. Sarah Chen joined Anthropic in San Francisco on January 15, 2024. She previously worked at Google Brain, where she led a team developing language models that could process over 100,000 tokens per second.\"\"\"\n",
    "\n",
    "# Process with spaCy\n",
    "doc = nlp(sample_text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.',\n",
       " 'Sarah',\n",
       " 'Chen',\n",
       " 'joined',\n",
       " 'Anthropic',\n",
       " 'in',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'on',\n",
       " 'January',\n",
       " '15',\n",
       " ',',\n",
       " '2024',\n",
       " '.',\n",
       " 'She',\n",
       " 'previously',\n",
       " 'worked',\n",
       " 'at',\n",
       " 'Google',\n",
       " 'Brain',\n",
       " ',',\n",
       " 'where',\n",
       " 'she',\n",
       " 'led',\n",
       " 'a',\n",
       " 'team',\n",
       " 'developing',\n",
       " 'language',\n",
       " 'models',\n",
       " 'that',\n",
       " 'could',\n",
       " 'process',\n",
       " 'over',\n",
       " '100,000',\n",
       " 'tokens',\n",
       " 'per',\n",
       " 'second',\n",
       " '.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word.text for word in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens and their Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll spend a lot of time on **tokens** in the next couple weeks. **Tokenization** has enormous impact on the performance on NLP tasks.\n",
    "\n",
    "Using the doc object, we can look at annotations on tokens. There are a very large number listed here: [spaCy token attributes](https://spacy.io/api/token#attributes) or use the help function, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Token object:\n",
      "\n",
      "class Token(builtins.object)\n",
      " |  An individual token â€“ i.e. a word, punctuation symbol, whitespace,\n",
      " |  etc.\n",
      " |\n",
      " |  DOCS: https://spacy.io/api/token\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __bytes__(self)\n",
      " |      Token.__bytes__(self)\n",
      " |\n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |\n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __len__(...)\n",
      " |      Token.__len__(self)\n",
      " |\n",
      " |      The number of unicode characters in the token, i.e. `token.text`.\n",
      " |\n",
      " |      RETURNS (int): The number of unicode characters in the token.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#len\n",
      " |\n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |\n",
      " |  __reduce__(self)\n",
      " |      Token.__reduce__(self)\n",
      " |\n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  __unicode__(self)\n",
      " |      Token.__unicode__(self)\n",
      " |\n",
      " |  check_flag(self, flag_id)\n",
      " |      Token.check_flag(self, attr_id_t flag_id) -> bool\n",
      " |\n",
      " |      Check the value of a boolean flag.\n",
      " |\n",
      " |      flag_id (int): The ID of the flag attribute.\n",
      " |      RETURNS (bool): Whether the flag is set.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#check_flag\n",
      " |\n",
      " |  has_dep(self)\n",
      " |      Token.has_dep(self)\n",
      " |\n",
      " |      Check whether the token has annotated dep information.\n",
      " |      Returns False when the dep label is unset/missing.\n",
      " |\n",
      " |      RETURNS (bool): Whether the dep label is valid or not.\n",
      " |\n",
      " |  has_head(self)\n",
      " |      Token.has_head(self)\n",
      " |\n",
      " |      Check whether the token has annotated head information.\n",
      " |      Return False when the head annotation is unset/missing.\n",
      " |\n",
      " |      RETURNS (bool): Whether the head annotation is valid or not.\n",
      " |\n",
      " |  has_morph(self)\n",
      " |      Token.has_morph(self)\n",
      " |\n",
      " |      Check whether the token has annotated morph information.\n",
      " |      Return False when the morph annotation is unset/missing.\n",
      " |\n",
      " |      RETURNS (bool): Whether the morph annotation is set.\n",
      " |\n",
      " |  is_ancestor(self, descendant)\n",
      " |      Token.is_ancestor(self, descendant)\n",
      " |\n",
      " |      Check whether this token is a parent, grandparent, etc. of another\n",
      " |      in the dependency tree.\n",
      " |\n",
      " |      descendant (Token): Another token.\n",
      " |      RETURNS (bool): Whether this token is the ancestor of the descendant.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#is_ancestor\n",
      " |\n",
      " |  nbor(self, i=1)\n",
      " |      Token.nbor(self, int i=1)\n",
      " |\n",
      " |      Get a neighboring token.\n",
      " |\n",
      " |      i (int): The relative position of the token to get. Defaults to 1.\n",
      " |      RETURNS (Token): The token at position `self.doc[self.i+i]`.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#nbor\n",
      " |\n",
      " |  set_morph(self, features)\n",
      " |      Token.set_morph(self, features)\n",
      " |\n",
      " |  similarity(self, other)\n",
      " |      Token.similarity(self, other)\n",
      " |\n",
      " |      Make a semantic similarity estimate. The default estimate is cosine\n",
      " |      similarity using an average of word vectors.\n",
      " |\n",
      " |      other (object): The object to compare with. By default, accepts `Doc`,\n",
      " |          `Span`, `Token` and `Lexeme` objects.\n",
      " |      RETURNS (float): A scalar similarity score. Higher is more similar.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#similarity\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  get_extension(name)\n",
      " |      Token.get_extension(cls, name)\n",
      " |\n",
      " |      Look up a previously registered extension by name.\n",
      " |\n",
      " |      name (str): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#get_extension\n",
      " |\n",
      " |  has_extension(name)\n",
      " |      Token.has_extension(cls, name)\n",
      " |\n",
      " |      Check whether an extension has been registered.\n",
      " |\n",
      " |      name (str): Name of the extension.\n",
      " |      RETURNS (bool): Whether the extension has been registered.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#has_extension\n",
      " |\n",
      " |  iob_strings()\n",
      " |      Token.iob_strings(cls)\n",
      " |\n",
      " |  remove_extension(name)\n",
      " |      Token.remove_extension(cls, name)\n",
      " |\n",
      " |      Remove a previously registered extension.\n",
      " |\n",
      " |      name (str): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n",
      " |          removed extension.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#remove_extension\n",
      " |\n",
      " |  set_extension(name, **kwargs)\n",
      " |      Token.set_extension(cls, name, **kwargs)\n",
      " |\n",
      " |      Define a custom attribute which becomes available as `Token._`.\n",
      " |\n",
      " |      name (str): Name of the attribute to set.\n",
      " |      default: Optional default value of the attribute.\n",
      " |      getter (callable): Optional getter function.\n",
      " |      setter (callable): Optional setter function.\n",
      " |      method (callable): Optional method for method extension.\n",
      " |      force (bool): Force overwriting existing attribute.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#set_extension\n",
      " |      USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  __new__(*args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  ancestors\n",
      " |      A sequence of this token's syntactic ancestors.\n",
      " |\n",
      " |      YIELDS (Token): A sequence of ancestor tokens such that\n",
      " |          `ancestor.is_ancestor(self)`.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#ancestors\n",
      " |\n",
      " |  children\n",
      " |      A sequence of the token's immediate syntactic children.\n",
      " |\n",
      " |      YIELDS (Token): A child token such that `child.head==self`.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#children\n",
      " |\n",
      " |  cluster\n",
      " |      RETURNS (int): Brown cluster ID.\n",
      " |\n",
      " |  conjuncts\n",
      " |      A sequence of coordinated tokens, including the token itself.\n",
      " |\n",
      " |      RETURNS (tuple): The coordinated tokens.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#conjuncts\n",
      " |\n",
      " |  dep\n",
      " |      RETURNS (uint64): ID of syntactic dependency label.\n",
      " |\n",
      " |  dep_\n",
      " |      RETURNS (str): The syntactic dependency label.\n",
      " |\n",
      " |  doc\n",
      " |\n",
      " |  ent_id\n",
      " |      RETURNS (uint64): ID of the entity the token is an instance of,\n",
      " |      if any.\n",
      " |\n",
      " |  ent_id_\n",
      " |      RETURNS (str): ID of the entity the token is an instance of,\n",
      " |      if any.\n",
      " |\n",
      " |  ent_iob\n",
      " |      IOB code of named entity tag. `1=\"I\", 2=\"O\", 3=\"B\"`. 0 means no tag\n",
      " |      is assigned.\n",
      " |\n",
      " |      RETURNS (uint64): IOB code of named entity tag.\n",
      " |\n",
      " |  ent_iob_\n",
      " |      IOB code of named entity tag. \"B\" means the token begins an entity,\n",
      " |      \"I\" means it is inside an entity, \"O\" means it is outside an entity,\n",
      " |      and \"\" means no entity tag is set. \"B\" with an empty ent_type\n",
      " |      means that the token is blocked from further processing by NER.\n",
      " |\n",
      " |      RETURNS (str): IOB code of named entity tag.\n",
      " |\n",
      " |  ent_kb_id\n",
      " |      RETURNS (uint64): Named entity KB ID.\n",
      " |\n",
      " |  ent_kb_id_\n",
      " |      RETURNS (str): Named entity KB ID.\n",
      " |\n",
      " |  ent_type\n",
      " |      RETURNS (uint64): Named entity type.\n",
      " |\n",
      " |  ent_type_\n",
      " |      RETURNS (str): Named entity type.\n",
      " |\n",
      " |  has_vector\n",
      " |      A boolean value indicating whether a word vector is associated with\n",
      " |      the object.\n",
      " |\n",
      " |      RETURNS (bool): Whether a word vector is associated with the object.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#has_vector\n",
      " |\n",
      " |  head\n",
      " |      The syntactic parent, or \"governor\", of this token.\n",
      " |      If token.has_head() is `False`, this method will return itself.\n",
      " |\n",
      " |      RETURNS (Token): The token predicted by the parser to be the head of\n",
      " |          the current token.\n",
      " |\n",
      " |  i\n",
      " |\n",
      " |  idx\n",
      " |      RETURNS (int): The character offset of the token within the parent\n",
      " |      document.\n",
      " |\n",
      " |  is_alpha\n",
      " |      RETURNS (bool): Whether the token consists of alpha characters.\n",
      " |      Equivalent to `token.text.isalpha()`.\n",
      " |\n",
      " |  is_ascii\n",
      " |      RETURNS (bool): Whether the token consists of ASCII characters.\n",
      " |      Equivalent to `[any(ord(c) >= 128 for c in token.text)]`.\n",
      " |\n",
      " |  is_bracket\n",
      " |      RETURNS (bool): Whether the token is a bracket.\n",
      " |\n",
      " |  is_currency\n",
      " |      RETURNS (bool): Whether the token is a currency symbol.\n",
      " |\n",
      " |  is_digit\n",
      " |      RETURNS (bool): Whether the token consists of digits. Equivalent to\n",
      " |      `token.text.isdigit()`.\n",
      " |\n",
      " |  is_left_punct\n",
      " |      RETURNS (bool): Whether the token is a left punctuation mark.\n",
      " |\n",
      " |  is_lower\n",
      " |      RETURNS (bool): Whether the token is in lowercase. Equivalent to\n",
      " |      `token.text.islower()`.\n",
      " |\n",
      " |  is_oov\n",
      " |      RETURNS (bool): Whether the token is out-of-vocabulary.\n",
      " |\n",
      " |  is_punct\n",
      " |      RETURNS (bool): Whether the token is punctuation.\n",
      " |\n",
      " |  is_quote\n",
      " |      RETURNS (bool): Whether the token is a quotation mark.\n",
      " |\n",
      " |  is_right_punct\n",
      " |      RETURNS (bool): Whether the token is a right punctuation mark.\n",
      " |\n",
      " |  is_sent_end\n",
      " |      A boolean value indicating whether the token ends a sentence.\n",
      " |      `None` if unknown. Defaults to `True` for the last token in the `Doc`.\n",
      " |\n",
      " |      RETURNS (bool / None): Whether the token ends a sentence.\n",
      " |          None if unknown.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#is_sent_end\n",
      " |\n",
      " |  is_sent_start\n",
      " |      A boolean value indicating whether the token starts a sentence.\n",
      " |      `None` if unknown. Defaults to `True` for the first token in the `Doc`.\n",
      " |\n",
      " |      RETURNS (bool / None): Whether the token starts a sentence.\n",
      " |          None if unknown.\n",
      " |\n",
      " |  is_space\n",
      " |      RETURNS (bool): Whether the token consists of whitespace characters.\n",
      " |      Equivalent to `token.text.isspace()`.\n",
      " |\n",
      " |  is_stop\n",
      " |      RETURNS (bool): Whether the token is a stop word, i.e. part of a\n",
      " |      \"stop list\" defined by the language data.\n",
      " |\n",
      " |  is_title\n",
      " |      RETURNS (bool): Whether the token is in titlecase. Equivalent to\n",
      " |      `token.text.istitle()`.\n",
      " |\n",
      " |  is_upper\n",
      " |      RETURNS (bool): Whether the token is in uppercase. Equivalent to\n",
      " |      `token.text.isupper()`\n",
      " |\n",
      " |  lang\n",
      " |      RETURNS (uint64): ID of the language of the parent document's\n",
      " |      vocabulary.\n",
      " |\n",
      " |  lang_\n",
      " |      RETURNS (str): Language of the parent document's vocabulary,\n",
      " |      e.g. 'en'.\n",
      " |\n",
      " |  left_edge\n",
      " |      Token.left_edge: int\n",
      " |\n",
      " |      The leftmost token of this token's syntactic descendents.\n",
      " |\n",
      " |      RETURNS (Token): The first token such that `self.is_ancestor(token)`.\n",
      " |\n",
      " |  lefts\n",
      " |      The leftward immediate children of the word, in the syntactic\n",
      " |      dependency parse.\n",
      " |\n",
      " |      YIELDS (Token): A left-child of the token.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#lefts\n",
      " |\n",
      " |  lemma\n",
      " |      RETURNS (uint64): ID of the base form of the word, with no\n",
      " |      inflectional suffixes.\n",
      " |\n",
      " |  lemma_\n",
      " |      RETURNS (str): The token lemma, i.e. the base form of the word,\n",
      " |      with no inflectional suffixes.\n",
      " |\n",
      " |  lex\n",
      " |      RETURNS (Lexeme): The underlying lexeme.\n",
      " |\n",
      " |  lex_id\n",
      " |      RETURNS (int): Sequential ID of the token's lexical type.\n",
      " |\n",
      " |  like_email\n",
      " |      RETURNS (bool): Whether the token resembles an email address.\n",
      " |\n",
      " |  like_num\n",
      " |      RETURNS (bool): Whether the token resembles a number, e.g. \"10.9\",\n",
      " |      \"10\", \"ten\", etc.\n",
      " |\n",
      " |  like_url\n",
      " |      RETURNS (bool): Whether the token resembles a URL.\n",
      " |\n",
      " |  lower\n",
      " |      RETURNS (uint64): ID of the lowercase token text.\n",
      " |\n",
      " |  lower_\n",
      " |      RETURNS (str): The lowercase token text. Equivalent to\n",
      " |      `Token.text.lower()`.\n",
      " |\n",
      " |  morph\n",
      " |\n",
      " |  n_lefts\n",
      " |      The number of leftward immediate children of the word, in the\n",
      " |      syntactic dependency parse.\n",
      " |\n",
      " |      RETURNS (int): The number of leftward immediate children of the\n",
      " |          word, in the syntactic dependency parse.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#n_lefts\n",
      " |\n",
      " |  n_rights\n",
      " |      The number of rightward immediate children of the word, in the\n",
      " |      syntactic dependency parse.\n",
      " |\n",
      " |      RETURNS (int): The number of rightward immediate children of the\n",
      " |          word, in the syntactic dependency parse.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#n_rights\n",
      " |\n",
      " |  norm\n",
      " |      RETURNS (uint64): ID of the token's norm, i.e. a normalised form of\n",
      " |      the token text. Usually set in the language's tokenizer exceptions\n",
      " |      or norm exceptions.\n",
      " |\n",
      " |  norm_\n",
      " |      RETURNS (str): The token's norm, i.e. a normalised form of the\n",
      " |      token text. Usually set in the language's tokenizer exceptions or\n",
      " |      norm exceptions.\n",
      " |\n",
      " |  orth\n",
      " |      RETURNS (uint64): ID of the verbatim text content.\n",
      " |\n",
      " |  orth_\n",
      " |      RETURNS (str): Verbatim text content (identical to\n",
      " |      `Token.text`). Exists mostly for consistency with the other\n",
      " |      attributes.\n",
      " |\n",
      " |  pos\n",
      " |      RETURNS (uint64): ID of coarse-grained part-of-speech tag.\n",
      " |\n",
      " |  pos_\n",
      " |      RETURNS (str): Coarse-grained part-of-speech tag.\n",
      " |\n",
      " |  prefix\n",
      " |      RETURNS (uint64): ID of a length-N substring from the start of the\n",
      " |      token. Defaults to `N=1`.\n",
      " |\n",
      " |  prefix_\n",
      " |      RETURNS (str): A length-N substring from the start of the token.\n",
      " |      Defaults to `N=1`.\n",
      " |\n",
      " |  prob\n",
      " |      RETURNS (float): Smoothed log probability estimate of token type.\n",
      " |\n",
      " |  rank\n",
      " |      RETURNS (int): Sequential ID of the token's lexical type, used to\n",
      " |      index into tables, e.g. for word vectors.\n",
      " |\n",
      " |  right_edge\n",
      " |      Token.right_edge: int\n",
      " |\n",
      " |      The rightmost token of this token's syntactic descendents.\n",
      " |\n",
      " |      RETURNS (Token): The last token such that `self.is_ancestor(token)`.\n",
      " |\n",
      " |  rights\n",
      " |      The rightward immediate children of the word, in the syntactic\n",
      " |      dependency parse.\n",
      " |\n",
      " |      YIELDS (Token): A right-child of the token.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#rights\n",
      " |\n",
      " |  sent\n",
      " |      RETURNS (Span): The sentence span that the token is a part of.\n",
      " |\n",
      " |  sent_start\n",
      " |      Deprecated: use Token.is_sent_start instead.\n",
      " |\n",
      " |  sentiment\n",
      " |      RETURNS (float): A scalar value indicating the positivity or\n",
      " |      negativity of the token.\n",
      " |\n",
      " |  shape\n",
      " |      RETURNS (uint64): ID of the token's shape, a transform of the\n",
      " |      token's string, to show orthographic features (e.g. \"Xxxx\", \"dd\").\n",
      " |\n",
      " |  shape_\n",
      " |      RETURNS (str): Transform of the token's string, to show\n",
      " |      orthographic features. For example, \"Xxxx\" or \"dd\".\n",
      " |\n",
      " |  subtree\n",
      " |      A sequence containing the token and all the token's syntactic\n",
      " |      descendants.\n",
      " |\n",
      " |      YIELDS (Token): A descendent token such that\n",
      " |          `self.is_ancestor(descendent) or token == self`.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#subtree\n",
      " |\n",
      " |  suffix\n",
      " |      RETURNS (uint64): ID of a length-N substring from the end of the\n",
      " |      token. Defaults to `N=3`.\n",
      " |\n",
      " |  suffix_\n",
      " |      RETURNS (str): A length-N substring from the end of the token.\n",
      " |      Defaults to `N=3`.\n",
      " |\n",
      " |  tag\n",
      " |      RETURNS (uint64): ID of fine-grained part-of-speech tag.\n",
      " |\n",
      " |  tag_\n",
      " |      RETURNS (str): Fine-grained part-of-speech tag.\n",
      " |\n",
      " |  tensor\n",
      " |\n",
      " |  text\n",
      " |      RETURNS (str): The original verbatim text of the token.\n",
      " |\n",
      " |  text_with_ws\n",
      " |      RETURNS (str): The text content of the span (with trailing\n",
      " |      whitespace).\n",
      " |\n",
      " |  vector\n",
      " |      A real-valued meaning representation.\n",
      " |\n",
      " |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n",
      " |          representing the token's semantics.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#vector\n",
      " |\n",
      " |  vector_norm\n",
      " |      The L2 norm of the token's vector representation.\n",
      " |\n",
      " |      RETURNS (float): The L2 norm of the vector representation.\n",
      " |\n",
      " |      DOCS: https://spacy.io/api/token#vector_norm\n",
      " |\n",
      " |  vocab\n",
      " |\n",
      " |  whitespace_\n",
      " |      RETURNS (str): The trailing whitespace character, if present.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. compound Chen PROPN []\n",
      "Sarah compound Chen PROPN []\n",
      "Chen nsubj joined VERB [Dr., Sarah]\n",
      "joined ROOT joined VERB [Chen, Anthropic, in, on, .]\n",
      "Anthropic dobj joined VERB []\n",
      "in prep joined VERB [Francisco]\n",
      "San compound Francisco PROPN []\n",
      "Francisco pobj in ADP [San]\n",
      "on prep joined VERB [January]\n",
      "January pobj on ADP [15, ,, 2024]\n",
      "15 nummod January PROPN []\n",
      ", punct January PROPN []\n",
      "2024 nummod January PROPN []\n",
      ". punct joined VERB []\n",
      "She nsubj worked VERB []\n",
      "previously advmod worked VERB []\n",
      "worked ROOT worked VERB [She, previously, at, .]\n",
      "at prep worked VERB [Brain]\n",
      "Google compound Brain PROPN []\n",
      "Brain pobj at ADP [Google, ,, led]\n",
      ", punct Brain PROPN []\n",
      "where advmod led VERB []\n",
      "she nsubj led VERB []\n",
      "led relcl Brain PROPN [where, she, team]\n",
      "a det team NOUN []\n",
      "team dobj led VERB [a, developing]\n",
      "developing acl team NOUN [models]\n",
      "language compound models NOUN []\n",
      "models dobj developing VERB [language, process]\n",
      "that nsubj process VERB []\n",
      "could aux process VERB []\n",
      "process relcl models NOUN [that, could, tokens]\n",
      "over quantmod 100,000 NUM []\n",
      "100,000 nummod tokens NOUN [over]\n",
      "tokens dobj process VERB [100,000, per]\n",
      "per prep tokens NOUN [second]\n",
      "second pobj per ADP []\n",
      ". punct worked VERB []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š TOKEN ANALYSIS (first 15 tokens)\n",
      "======================================================================\n",
      "    Token     Lemma   POS Tag      Dep  Is_Stop\n",
      "      Dr.       Dr. PROPN NNP compound    False\n",
      "    Sarah     Sarah PROPN NNP compound    False\n",
      "     Chen      Chen PROPN NNP    nsubj    False\n",
      "   joined      join  VERB VBD     ROOT    False\n",
      "Anthropic Anthropic PROPN NNP     dobj    False\n",
      "       in        in   ADP  IN     prep     True\n",
      "      San       San PROPN NNP compound    False\n",
      "Francisco Francisco PROPN NNP     pobj    False\n",
      "       on        on   ADP  IN     prep     True\n",
      "  January   January PROPN NNP     pobj    False\n",
      "       15        15   NUM  CD   nummod    False\n",
      "        ,         , PUNCT   ,    punct    False\n",
      "     2024      2024   NUM  CD   nummod    False\n",
      "        .         . PUNCT   .    punct    False\n",
      "      She       she  PRON PRP    nsubj     True\n",
      "\n",
      "\n",
      "ðŸ’¡ Expected Observation:\n",
      "   - Notice how 'joined' has lemma 'join' (verb normalization)\n",
      "   - 'Dr.' is tagged as NNP (proper noun) despite the period\n",
      "   - Stop words like 'in', 'on', 'a' are marked True for Is_Stop\n"
     ]
    }
   ],
   "source": [
    "# Claude helped me create a table of tokens with their attributes\n",
    "# It's just a prettier version than the above\n",
    "\n",
    "token_data = []\n",
    "for token in doc:\n",
    "    token_data.append({\n",
    "        \"Token\": token.text,\n",
    "        \"Lemma\": token.lemma_,\n",
    "        \"POS\": token.pos_,\n",
    "        \"Tag\": token.tag_,\n",
    "        \"Dep\": token.dep_,\n",
    "        \"Is_Stop\": token.is_stop\n",
    "    })\n",
    "\n",
    "token_df = pd.DataFrame(token_data)\n",
    "print(\"\\nðŸ“Š TOKEN ANALYSIS (first 15 tokens)\")\n",
    "print(\"=\"*70)\n",
    "print(token_df.head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nðŸ’¡ Expected Observation:\")\n",
    "print(\"   - Notice how 'joined' has lemma 'join' (verb normalization)\")\n",
    "print(\"   - 'Dr.' is tagged as NNP (proper noun) despite the period\")\n",
    "print(\"   - Stop words like 'in', 'on', 'a' are marked True for Is_Stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While **Part-of-Speech (POS)**, **syntactic (constituent) categories (Tag)**, and **Dependency relations (Dep)** are important concepts. We won't go into in any depth on this right now. This lab gives you an introduction to these concepts because of the importance of token level annotations in SpaCy.\n",
    "\n",
    "For now, think of a token as a basic unit that you will focus on in NLP. **A token is simply a piece of text that can be represented as an integer.** The first stage in a spaCy pipeline is tokenization to break up text into the smaller bits that we process. As objects, they have the potential to carry a lot of information. We're going to briefly look at the sorts of information they carry in this lab. Don't worry about the details... this is an introduction to terms you will become more familiar with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmas and stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me what lemmas and stop words are and how they might be used in NLP tasks?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain these two important concepts:\n",
    "\n",
    "**Lemmas** are the base or dictionary form of a word. For example:\n",
    "- \"joined\" â†’ \"join\"\n",
    "- \"running\" â†’ \"run\"  \n",
    "- \"better\" â†’ \"good\"\n",
    "\n",
    "This normalization is useful because it lets you treat different forms of the same word as equivalent. For instance, if you're analyzing sentiment in reviews, you'd want \"loved,\" \"loving,\" and \"loves\" to all be recognized as the same concept.\n",
    "\n",
    "**Stop words** are common words that often don't carry much meaning on their own, like \"the,\" \"is,\" \"at,\" \"in,\" \"a.\" You can see in your token table that words like \"in\" and \"on\" are marked as stop words.\n",
    "\n",
    "They're often filtered out in tasks like:\n",
    "- Document classification (where \"the\" appears everywhere and doesn't help distinguish topics)\n",
    "- Keyword extraction (you want meaningful words, not \"and\" or \"of\")\n",
    "\n",
    "However, stop words ARE important for some tasksâ€”like machine translation or question answering, where \"not\" or \"who\" can completely change meaning!\n",
    "\n",
    "Looking at your sample text, can you spot why lemmatization might be helpful for analyzing this text? What if you wanted to count how many times people \"work\" at different companies across many documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you know about POS tags used by SpaCy? Is there a good reference?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "SpaCy uses two types of POS tags:\n",
    "\n",
    "1. **Coarse-grained tags** (`token.pos_`) - Universal POS tags from the Universal Dependencies project. These are standardized across languages (like NOUN, VERB, ADJ, etc.)\n",
    "\n",
    "2. **Fine-grained tags** (`token.tag_`) - Language-specific tags. For English, these are Penn Treebank tags (like NNP, VBD, JJ, etc.)\n",
    "\n",
    "The best references are:\n",
    "\n",
    "- [**Universal POS tags**](https://universaldependencies.org/u/pos/)\n",
    "- [**Penn Treebank tags**](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
    "- [**SpaCy's own documentation**](https://spacy.io/api/annotation#pos-tagging)\n",
    "\n",
    "You can also see what tags are available in your loaded model by checking `nlp.get_pipe(\"tagger\").labels`.\n",
    "\n",
    "Would you like to explore the tags in your current doc, or see what your model supports?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give me a reference table for those that I am seeing.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's a quick reference for the tags appearing in your token data:\n",
    "\n",
    "**POS Tags (Universal):**\n",
    "- `PROPN` - Proper noun (Sarah, Chen, Anthropic, San Francisco)\n",
    "- `VERB` - Verb (joined)\n",
    "- `ADP` - Adposition/preposition (in, on)\n",
    "- `NUM` - Number (15, 2024)\n",
    "- `PUNCT` - Punctuation (., ,)\n",
    "- `PRON` - Pronoun (She)\n",
    "\n",
    "**Penn Treebank Tags (detailed):**\n",
    "- `NNP` - Proper noun, singular (Dr., Sarah, Chen)\n",
    "- `VBD` - Verb, past tense (joined)\n",
    "- `IN` - Preposition or subordinating conjunction (in, on)\n",
    "- `CD` - Cardinal number (15, 2024)\n",
    "- `PRP` - Personal pronoun (She)\n",
    "\n",
    "**Dependency Labels:**\n",
    "- `nsubj` - Nominal subject (Chen is the subject of \"joined\")\n",
    "- `dobj` - Direct object (Anthropic is what was joined)\n",
    "- `compound` - Compound modifier (Dr. + Sarah + Chen)\n",
    "- `prep` - Prepositional modifier (in, on)\n",
    "- `pobj` - Object of preposition (Francisco, January)\n",
    "- `nummod` - Numeric modifier (15 modifies January)\n",
    "- `ROOT` - Root of the sentence (joined)\n",
    "\n",
    "Would you like to see these applied to your data, or explore any specific tag type in more detail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me how SpaCy's POS tagger works?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "SpaCy's POS tagger uses a neural network model trained on annotated text data. Here's how it works:\n",
    "\n",
    "**Training:** The model learns patterns from large corpora (like OntoNotes for English) where words are already tagged with their parts of speech. It learns contextual cluesâ€”for example, that a word after \"the\" is likely a noun.\n",
    "\n",
    "**Prediction:** When you process text with `nlp(text)`, the tagger looks at each token in context (surrounding words, word shape, prefixes/suffixes) and predicts the most likely POS tag using the trained neural network.\n",
    "\n",
    "**Architecture:** Modern SpaCy models (v3+) use transformer-based or CNN-based architectures. The small model you're using (`en_core_web_sm`) uses a more compact architecture for speed.\n",
    "\n",
    "The tagger is one component in the processing pipeline. You can see your pipeline components with:\n",
    "\n",
    "```python\n",
    "nlp.pipe_names\n",
    "```\n",
    "\n",
    "Want to try that to see what other components are running when you call `nlp(text)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using spaCy version 3 which includes transformer models. Tok2vec is a model that turns tokens to vectors. We'll get to what that means later, but its useful to know that the (POS) tagger is a classifier that takes a vector as input and predicts a POS label. \n",
    "\n",
    "What's really neat about the \"token-to-vector\" model is that it's outputs can be used between multiple components such as the (POS) Tagger and Dependency Parser.\n",
    "\n",
    "We'll look at dependency parsing more below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [SpaCy model reference](https://spacy.io/models), the Named Entity Recognition (NER) component also uses vectors as input. It is configurable to use its own Tok2Vec model, though by default, uses the pipeline Tok2Vec model. SpaCy is extremely configurable and you can turn components on and off, as long as you are paying attention to dependencies.\n",
    "\n",
    "NER uses all sorts of features as context. For example, it uses punctuation to signal clause boundaries, abbreviations, etc. It also uses lexical features and contextual token features such as neighboring tokens, subword patterns, and other contextual clues. It does not rely on POS tags or dependency parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sarah Chen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " joined Anthropic in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    January 15, 2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". She previously worked at \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ", where she led a team developing language models that could process over \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    100,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " tokens per \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize entities (Colab-friendly)\n",
    "from spacy import displacy\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Render entities\n",
    "html = displacy.render(doc, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we use POS tags in NLP tasks?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "POS tags are useful building blocks for many NLP tasks:\n",
    "\n",
    "**1. Information Extraction** - You can filter for specific patterns. For example, finding all noun phrases (sequences of adjectives + nouns) to extract key concepts, or finding verb-object pairs to understand actions.\n",
    "\n",
    "**2. Text Preprocessing** - You might keep only nouns and verbs for topic modeling, or remove everything except proper nouns to find names and places.\n",
    "\n",
    "**3. Disambiguation** - The word \"book\" could be a noun (read a book) or verb (book a flight). POS tags help distinguish meaning.\n",
    "\n",
    "**4. Feature Engineering** - For classification tasks, POS tag distributions can be features. Academic writing has different POS patterns than casual speech.\n",
    "\n",
    "Looking at your `doc`, what if you wanted to extract just the organizations mentioned? You could filter for proper nouns (`PROPN`), but notice \"Google Brain\" is tagged as `FAC` (facility) in the NER output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buildings, airports, highways, bridges, etc.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"FAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around with 'Google Brain' to look at some other sentences. We want to experiment and see under what sentence contexts it is tagged correctly as an ORG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">She worked at the company \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc1 = nlp(\"She joined Google Brain as an engineer\")\n",
    "doc2 = nlp(\"Google Brain is a research organization\")\n",
    "doc3 = nlp(\"She worked at the company Google Brain\")\n",
    "\n",
    "# Render entities\n",
    "html = displacy.render(doc1, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))\n",
    "html = displacy.render(doc2, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))\n",
    "html = displacy.render(doc3, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been given some [basic study material on a theory of language structure based on \"X-bar\" theory](https://socialsci.libretexts.org/Courses/Canada_College/ENGL_LING_200%3A_Introduction_to_Linguistics/05%3A_Phrases-_Syntax/5.03%3A_Phrase_Structure_Rules_X-Bar_Theory_and_Constituency), which is a kind of **constituent parsing**. This kind of parsing has a lot of positives. It can tell you about where noun and verb phrases begin and end because it has rich, hierarchical structure. You can plugin a constituent parser into spaCy, but it's not the default.\n",
    "\n",
    "SpaCy chose to implement dependency parsing because it's faster (linear time), low memory, robust token-centric, and works across many languages (i.e. cross-lingual). Like constituent parsing, it's also usedful for downstream tasks. Your linguistics book doesn't talk about dependency parsing, so we'll draw from Jurafsky and Martin and touch on it in this notebook.\n",
    "\n",
    "Note, it's not important to know the details here. Focus on why SpaCy has a dependency parser out of the box -- why it might be useful -- and that it works at the token level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e6eb53f2a7364b589a2bb148f6c1ebca-0\" class=\"displacy\" width=\"1130\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dr.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Sarah</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Chen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">joined</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Anthropic</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">San</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">Francisco</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">January</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">15,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">2024.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 225.0,47.0 225.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,139.0 L408.0,127.0 392.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-4\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,139.0 L503.0,127.0 487.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-6\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,139.0 L683.0,127.0 667.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-7\" stroke-width=\"2px\" d=\"M340,137.0 C340,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-8\" stroke-width=\"2px\" d=\"M790,137.0 C790,92.0 850.0,92.0 850.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M850.0,139.0 L858.0,127.0 842.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-9\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M940.0,139.0 L948.0,127.0 932.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-10\" stroke-width=\"2px\" d=\"M880,137.0 C880,47.0 1035.0,47.0 1035.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1035.0,139.0 L1043.0,127.0 1027.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e6eb53f2a7364b589a2bb148f6c1ebca-1\" class=\"displacy\" width=\"2030\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">previously</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">worked</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Google</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Brain,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">where</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">she</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">led</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">team</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">developing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">models</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">could</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">process</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1580\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1580\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1670\">100,000</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1670\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1760\">tokens</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1760\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">per</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1940\">second.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1940\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 225.0,47.0 225.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310.0,139.0 L318.0,127.0 302.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-4\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,139.0 L503.0,127.0 487.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,47.0 765.0,47.0 765.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-6\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,139.0 L692,127.0 708,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-7\" stroke-width=\"2px\" d=\"M520,137.0 C520,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-10\" stroke-width=\"2px\" d=\"M970,137.0 C970,92.0 1030.0,92.0 1030.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030.0,139.0 L1038.0,127.0 1022.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-11\" stroke-width=\"2px\" d=\"M1150,137.0 C1150,92.0 1210.0,92.0 1210.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,139.0 L1142,127.0 1158,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-12\" stroke-width=\"2px\" d=\"M1060,137.0 C1060,47.0 1215.0,47.0 1215.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1215.0,139.0 L1223.0,127.0 1207.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-13\" stroke-width=\"2px\" d=\"M1330,137.0 C1330,47.0 1485.0,47.0 1485.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1330,139.0 L1322,127.0 1338,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-14\" stroke-width=\"2px\" d=\"M1420,137.0 C1420,92.0 1480.0,92.0 1480.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1420,139.0 L1412,127.0 1428,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-15\" stroke-width=\"2px\" d=\"M1240,137.0 C1240,2.0 1490.0,2.0 1490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1490.0,139.0 L1498.0,127.0 1482.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-16\" stroke-width=\"2px\" d=\"M1600,137.0 C1600,92.0 1660.0,92.0 1660.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600,139.0 L1592,127.0 1608,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-17\" stroke-width=\"2px\" d=\"M1690,137.0 C1690,92.0 1750.0,92.0 1750.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1690,139.0 L1682,127.0 1698,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-18\" stroke-width=\"2px\" d=\"M1510,137.0 C1510,47.0 1755.0,47.0 1755.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1755.0,139.0 L1763.0,127.0 1747.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-19\" stroke-width=\"2px\" d=\"M1780,137.0 C1780,92.0 1840.0,92.0 1840.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1840.0,139.0 L1848.0,127.0 1832.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-20\" stroke-width=\"2px\" d=\"M1870,137.0 C1870,92.0 1930.0,92.0 1930.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e6eb53f2a7364b589a2bb148f6c1ebca-1-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1930.0,139.0 L1938.0,127.0 1922.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize entities (Colab-friendly)\n",
    "from spacy import displacy\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "options = {\n",
    "    \"distance\": 90,   # arc length\n",
    "    \"compact\": False,\n",
    "    \"bg\": \"#ffffff\",\n",
    "    \"color\": \"#000000\",\n",
    "    \"font\": \"Arial\"\n",
    "}\n",
    "\n",
    "# Render entities. We need to break out by sentence since this will take a lot of horizontal space, otherwise.\n",
    "html = displacy.render(\n",
    "    list(doc.sents),   # important: avoids cramped multi-sentence trees\n",
    "    style=\"dep\",\n",
    "    options=options,\n",
    "    jupyter=False\n",
    ")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me how to read this dependency chart. Maybe use the first sentence as an example.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at the first sentence's dependency chart, here's how to read it:\n",
    "\n",
    "**The arrows show relationships between words**, where:\n",
    "- The arrow points FROM a dependent word TO its head (the word it modifies or relates to)\n",
    "- The label on the arrow tells you the type of relationship\n",
    "\n",
    "**Example from \"Dr. Sarah Chen joined Anthropic...\":**\n",
    "\n",
    "- \"Dr.\" and \"Sarah\" both have arrows pointing to \"Chen\" with label `compound` - they're parts of the compound name\n",
    "- \"Chen\" has an arrow to \"joined\" labeled `nsubj` (nominal subject) - Chen is who performed the action\n",
    "- \"Anthropic\" points to \"joined\" with `dobj` (direct object) - Anthropic is what was joined\n",
    "- \"in\" points to \"joined\" with `prep` (prepositional modifier)\n",
    "- \"Francisco\" points to \"in\" with `pobj` (object of preposition)\n",
    "\n",
    "**The ROOT** is \"joined\" - it's the main verb with no arrow pointing away from it.\n",
    "\n",
    "Try tracing one relationship yourself. Can you explain what the arrow from \"San\" to \"Francisco\" means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a dependency parse looks like compared to a syntax tree constituent analysis and is from [Chapter 19 of Jurafsky & Martin](https://web.stanford.edu/~jurafsky/slp3/19.pdf). Arguments to relations are heads and dependents. Heads are the organizing word and dependents are like modifiers. These are labeled with grammatical functions like \"Nominal subject\" or \"Direct object.\" \n",
    "\n",
    "For example, (**NSUBJ**) **United** canceled the (**DOBJ**) **flight**.\n",
    "\n",
    "The Universal Dependencies project is a community effort to align a grammar across more than 100 language with an inventory of 37 dependency relations. \n",
    "\n",
    "![pasted_image_7d560d89-c8fe-4a24-b742-16a8368e7184.png](attachment:7d560d89-c8fe-4a24-b742-16a8368e7184)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, dependency parsing answers questions like:\n",
    "- who did what to whom?\n",
    "- what modifies what?\n",
    "- what organizations below to which phrase?\n",
    "\n",
    "Unlike consituency parsers which use the **sentence** as the root of the tree, dependency grammars place the main **verb** as the head of a clause (sentence embedded in a larger sentence). \n",
    "\n",
    "So in our clause \"she previously **worked** at Google Brain\", 'worked' is the root that everything depends on.\n",
    "\n",
    "- **she** is \"who did it\"\n",
    "- **previously** is \"when\"\n",
    "- at **Google Brain** is \"where\" (oblique argument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me about the dependency parser in spaCy. Is it also based on a sequence of span probabilities like POS\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "SpaCy's dependency parser works differently from POS tagging. Instead of assigning labels to individual tokens, it predicts **relationships between tokens** (which token is the head of which other token, and what type of dependency).\n",
    "\n",
    "The parser uses a **transition-based approach**:\n",
    "- It processes the sentence incrementally, making a series of decisions (transitions)\n",
    "- At each step, it can perform actions like \"attach this word to that word with label X\"\n",
    "- It builds up the parse tree through these sequential decisions\n",
    "\n",
    "Like NER, it can use beam search to explore multiple parsing paths and find the most probable complete parse tree.\n",
    "\n",
    "The key difference: POS assigns one label per token independently, while dependency parsing creates a **structure** where every token (except the root) must connect to exactly one head token.\n",
    "\n",
    "Would you like to explore how the parser handles ambiguous sentences, or see what transitions it makes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diagram is from Jurafsky & Martin Chapter 19.2 and is an illustration of **transition-based** parsing. It demonstrates **shift-reduce parsing** where we have a stack on which we build the parse, a buffer of tokens to parse, and a parser which takes actions on the prase via a predictor called an oracle. It can explore multiple paths, when doing so - though, that will slow this process down.\n",
    "\n",
    "![pasted_image_b62affb2-2519-4fe4-82cf-f40dcffa03e3.png](attachment:b62affb2-2519-4fe4-82cf-f40dcffa03e3)\n",
    "\n",
    "The parser walks through the sentence left-to-right, successively shifting items\n",
    "from the buffer onto the stack. At each time point we examine the top two elements\n",
    "on the stack, and the oracle makes a decision about what transition to apply to build the parse. \n",
    "\n",
    "These are the tree transition operations on the top two elements of the stack:\n",
    "\n",
    "1. **LEFTARC**: Assert a head-dependent relation between the word at the top of\n",
    "the stack and the second word; remove the second word from the stack.\n",
    "\n",
    "2. **RIGHTARC**: Assert a head-dependent relation between the second word on\n",
    "the stack and the word at the top; remove the top word from the stack.\n",
    "\n",
    "3. **SHIFT**: Remove the word from the front of the input buffer and push it onto\n",
    "the stack.\n",
    "\n",
    "This is a greedy algorithm - the oracle provides a single choice at each step and the parser proceeds with that choice and no other options are explored. There is no backtracking and a single parse is returned in the end.\n",
    "\n",
    "Think of it this way, the Oracle is a trained supervised algorithm that makes a decision over two tokens until there are no more rules to apply. It decides if it will shift a word onto the stack, or if it will assert a relationship (left or right) between two tokens. Recall, **every token must connect to exactly one head token.** \n",
    "\n",
    "Lets walk through an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example from J&M Chapter 19.\n",
    "\n",
    "![pasted_image_acf6b95c-51de-43b2-bdee-7a74d9bdd17a.png](attachment:acf6b95c-51de-43b2-bdee-7a74d9bdd17a)\n",
    "\n",
    "You can see that every stage the algorithm is looking for one head token and one dependent token until there are none left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below, we will tell SpaCy to give us the top three parses. Generally, we want a beam_width of 1 (one parse), because this is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = nlp.get_pipe(\"parser\")\n",
    "beams = parser.beam_parse([doc], beam_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alternatives: 3\n",
      "Probabilities: [0.7982435893632595, 0.17826448047596988, 0.023491930160770638]\n"
     ]
    }
   ],
   "source": [
    "head_scores, label_scores = parser.scored_parses(beams)\n",
    "print(f\"Number of alternatives: {len(beams[0].histories)}\")\n",
    "print(f\"Probabilities: {beams[0].probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell me what these scores mean?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The `beams[0].probs` shows the probabilities for the top 3 complete dependency parse trees:\n",
    "\n",
    "- **79.8%** - The parse tree SpaCy chose (most probable)\n",
    "- **17.8%** - Second-best alternative parse\n",
    "- **2.3%** - Third-best alternative\n",
    "\n",
    "The `head_scores` and `label_scores` from `scored_parses()` give you more detailed information about individual attachment decisions and dependency labels for each token in each parse.\n",
    "\n",
    "Want to look at what's actually different between these three parse trees? We could decode the histories to see where they disagree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Language Modeling as Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we're going to do is look at a simple bigram model. A bigram is a pair of consecutive units. These models perform surprisingly well! You can also build trigram models -- three consecutive units, and four-gram models. All are simply types of 'n-gram' models.\n",
    "\n",
    "So, for example, \n",
    "\n",
    "- unigram - 'the'\n",
    "- bigram - 'the man'\n",
    "- trigram - 'the man with'\n",
    "- 4-gram - 'the man with the'\n",
    "\n",
    "The larger the chunk, the more context. We'll look at n-grams more in depth later this semester.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small corpus for our bigram model\n",
    "corpus = \"\"\"\n",
    "I saw the man with the telescope yesterday.\n",
    "I saw the bird with my binoculars.\n",
    "The man with the hat waved at me.\n",
    "I watched the show with great interest.\n",
    "The telescope with the red lens was expensive.\n",
    "I observed the stars with the telescope.\n",
    "The bird with colorful feathers flew away.\n",
    "She saw him with her own eyes.\n",
    "The man with the briefcase left early.\n",
    "I spotted the deer with the binoculars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM:\n",
    "    \"\"\"A simple bigram language model.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.bigram_counts = defaultdict(Counter)\n",
    "        self.unigram_counts = Counter()\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"Train on a corpus of text.\"\"\"\n",
    "        # Simple tokenization\n",
    "        tokens = text.lower().replace('.', ' .').replace(',', ' ,').split()\n",
    "        \n",
    "        # Count unigrams\n",
    "        self.unigram_counts.update(tokens)\n",
    "        \n",
    "        # Count bigrams\n",
    "        for i in range(len(tokens) - 1):\n",
    "            self.bigram_counts[tokens[i]][tokens[i+1]] += 1\n",
    "            \n",
    "        print(f\"Trained on {len(tokens)} tokens, {len(self.bigram_counts)} unique contexts\")\n",
    "    \n",
    "    def get_next_word_probs(self, context_word, top_k=5):\n",
    "        \"\"\"Get probability distribution over next words given context.\"\"\"\n",
    "        context_word = context_word.lower()\n",
    "        if context_word not in self.bigram_counts:\n",
    "            return []\n",
    "        \n",
    "        counts = self.bigram_counts[context_word]\n",
    "        total = sum(counts.values())\n",
    "        \n",
    "        probs = [(word, count/total) for word, count in counts.most_common(top_k)]\n",
    "        return probs\n",
    "    \n",
    "    def score_sequence(self, words):\n",
    "        \"\"\"Score a sequence of words (log probability).\"\"\"\n",
    "        import math\n",
    "        words = [w.lower() for w in words]\n",
    "        log_prob = 0\n",
    "        for i in range(len(words) - 1):\n",
    "            context = words[i]\n",
    "            next_word = words[i+1]\n",
    "            if context in self.bigram_counts and next_word in self.bigram_counts[context]:\n",
    "                prob = self.bigram_counts[context][next_word] / sum(self.bigram_counts[context].values())\n",
    "                log_prob += math.log(prob)\n",
    "            else:\n",
    "                log_prob += math.log(1e-6)  # Smoothing for unseen\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on 83 tokens, 39 unique contexts\n"
     ]
    }
   ],
   "source": [
    "# Train our bigram model\n",
    "bigram_lm = BigramLM()\n",
    "bigram_lm.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š BIGRAM MODEL: Next-word probabilities\n",
      "==================================================\n",
      "\n",
      "After 'the':\n",
      "   man             0.200 â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   telescope       0.200 â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   bird            0.133 â–ˆâ–ˆ\n",
      "   hat             0.067 â–ˆ\n",
      "   show            0.067 â–ˆ\n",
      "\n",
      "After 'with':\n",
      "   the             0.600 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   my              0.100 â–ˆâ–ˆ\n",
      "   great           0.100 â–ˆâ–ˆ\n",
      "   colorful        0.100 â–ˆâ–ˆ\n",
      "   her             0.100 â–ˆâ–ˆ\n",
      "\n",
      "After 'saw':\n",
      "   the             0.667 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   him             0.333 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "After 'man':\n",
      "   with            1.000 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ðŸ’¡ Expected Observation:\n",
      "   - Limited vocabulary (only words seen in training)\n",
      "   - Only looks at ONE previous word (no long-range context)\n",
      "   - Sparse: many word pairs never seen â†’ zero probability\n"
     ]
    }
   ],
   "source": [
    "# Explore next-word probabilities from our bigram model\n",
    "print(\"\\nðŸ“Š BIGRAM MODEL: Next-word probabilities\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_contexts = [\"the\", \"with\", \"saw\", \"man\"]\n",
    "\n",
    "for context in test_contexts:\n",
    "    probs = bigram_lm.get_next_word_probs(context, top_k=5)\n",
    "    print(f\"\\nAfter '{context}':\")\n",
    "    for word, prob in probs:\n",
    "        print(f\"   {word:15} {prob:.3f} {'â–ˆ' * int(prob * 20)}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Expected Observation:\")\n",
    "print(\"   - Limited vocabulary (only words seen in training)\")\n",
    "print(\"   - Only looks at ONE previous word (no long-range context)\")\n",
    "print(\"   - Sparse: many word pairs never seen â†’ zero probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think probabilities would look like with these contexts?\n",
    "test_contexts = [\"the\", \"quick\", \"brown\", \"fox\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how a neural model handles the tax of next-token probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local language model (distilgpt2)...\n",
      "âœ… Local model loaded!\n",
      "\n",
      "âœ… Unified LM interface ready!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# ============================================================\n",
    "# UNIFIED INTERFACE FOR NEXT-TOKEN PROBABILITIES\n",
    "# ============================================================\n",
    "# This works with:\n",
    "#   1. LOCAL model (always available, no API key needed)\n",
    "#   2. OpenAI GPT (if OPENAI_API_KEY present)\n",
    "#   3. Anthropic Claude (if ANTHROPIC_API_KEY present)\n",
    "# ============================================================\n",
    "\n",
    "# This interface is designed so we can later swap in a remote model \n",
    "# without changing downstream experiments.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load local model (distilgpt2 - small and fast)\n",
    "print(\"Loading local language model (distilgpt2)...\")\n",
    "local_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "local_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "local_model.eval()\n",
    "print(\"âœ… Local model loaded!\")\n",
    "\n",
    "def get_next_token_distribution_local(prompt, k=10):\n",
    "    \"\"\"\n",
    "    Get top-k next token probabilities using local model.\n",
    "    Returns: list of (token_string, probability) tuples\n",
    "    \"\"\"\n",
    "    inputs = local_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = local_model(**inputs)\n",
    "        # Get logits for the last position\n",
    "        next_token_logits = outputs.logits[0, -1, :]\n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        # Get top-k\n",
    "        top_probs, top_indices = torch.topk(probs, k)\n",
    "        \n",
    "    results = []\n",
    "    for prob, idx in zip(top_probs.tolist(), top_indices.tolist()):\n",
    "        token = local_tokenizer.decode([idx])\n",
    "        results.append((token, prob))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def score_continuation_local(prompt, continuation):\n",
    "    \"\"\"\n",
    "    Score a continuation given a prompt using teacher forcing.\n",
    "    Returns: (sum_log_prob, avg_log_prob, num_tokens)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    full_text = prompt + continuation\n",
    "    prompt_ids = local_tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    full_ids = local_tokenizer(full_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    \n",
    "    prompt_len = prompt_ids.shape[1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = local_model(full_ids)\n",
    "        logits = outputs.logits[0]  # [seq_len, vocab_size]\n",
    "        \n",
    "    # Score each token in the continuation\n",
    "    log_probs = []\n",
    "    for i in range(prompt_len - 1, full_ids.shape[1] - 1):\n",
    "        next_token_id = full_ids[0, i + 1].item()\n",
    "        token_logits = logits[i]\n",
    "        token_probs = F.softmax(token_logits, dim=-1)\n",
    "        log_prob = math.log(token_probs[next_token_id].item() + 1e-10)\n",
    "        log_probs.append(log_prob)\n",
    "    \n",
    "    sum_log_prob = sum(log_probs)\n",
    "    avg_log_prob = sum_log_prob / len(log_probs) if log_probs else 0\n",
    "    \n",
    "    return sum_log_prob, avg_log_prob, len(log_probs)\n",
    "\n",
    "# Create unified interface\n",
    "def get_next_token_distribution(prompt, k=10, provider=\"auto\"):\n",
    "    \"\"\"\n",
    "    Unified interface for next-token distributions.\n",
    "\n",
    "    NOTE:\n",
    "    - Currently defaults to a local model (distilgpt2)\n",
    "    - Designed so experiments below do not depend on model source\n",
    "    \"\"\"\n",
    "    if provider == \"auto\":\n",
    "        provider = \"local\"  # Local is most reliable for logprobs\n",
    "    \n",
    "    if provider == \"local\":\n",
    "        return get_next_token_distribution_local(prompt, k)\n",
    "    else:\n",
    "        # Fallback to local\n",
    "        return get_next_token_distribution_local(prompt, k)\n",
    "\n",
    "def score_continuation(prompt, continuation, provider=\"auto\"):\n",
    "    \"\"\"Score a continuation using best available provider.\"\"\"\n",
    "    if provider == \"auto\":\n",
    "        provider = \"local\"\n",
    "    \n",
    "    if provider == \"local\":\n",
    "        return score_continuation_local(prompt, continuation)\n",
    "    else:\n",
    "        return score_continuation_local(prompt, continuation)\n",
    "\n",
    "print(\"\\nâœ… Unified LM interface ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Testing next-token distribution...\n",
      "==================================================\n",
      "Prompt: 'The quick brown fox'\n",
      "\n",
      "Top 10 next tokens:\n",
      "   'es        ' : 0.2303 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' is       ' : 0.0549 â–ˆâ–ˆ\n",
      "   ',         ' : 0.0270 â–ˆ\n",
      "   '.         ' : 0.0242 â–ˆ\n",
      "   ' and      ' : 0.0191 \n",
      "   ' has      ' : 0.0187 \n",
      "   ' that     ' : 0.0160 \n",
      "   ' was      ' : 0.0151 \n",
      "   'e         ' : 0.0148 \n",
      "   'y         ' : 0.0104 \n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Test the interface\n",
    "print(\"\\nðŸ§ª Testing next-token distribution...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_prompt = \"The quick brown fox\"\n",
    "results = get_next_token_distribution(test_prompt, k=10)\n",
    "\n",
    "print(f\"Prompt: '{test_prompt}'\")\n",
    "print(f\"\\nTop 10 next tokens:\")\n",
    "for token, prob in results:\n",
    "    bar = 'â–ˆ' * int(prob * 50)\n",
    "    print(f\"   '{token:10}' : {prob:.4f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why don't we see 'jump'? The famous phrase is \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great observation! There are a few reasons \"jump\" or \"jumped\" isn't showing up:\n",
    "\n",
    "**1. Training data bias** - DistilGPT2 was trained on a huge corpus of internet text. While \"The quick brown fox jumps over the lazy dog\" is a famous pangram (contains all letters), it's actually quite rare compared to how often the model saw other phrases starting with \"The quick brown fox...\"\n",
    "\n",
    "**2. Token probabilities are spread out** - Notice we're only showing the top 10. \"jumped\" might be ranked 50th or 100th with a very small probability.\n",
    "\n",
    "**3. Tokenization** - \"jumped\" might be split into multiple tokens (like \"jump\" + \"ed\"), making it even less likely to appear as a single next token.\n",
    "\n",
    "Want to check if \"jumped\" appears further down the list? We could increase `k` to see more possibilities, or we could score the specific continuation \"jumped over the lazy dog\" to see what probability the model assigns to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can give the entire context to **DistilGPT2**.\n",
    "\n",
    "- It's considering the entire context \"The quick brown fox\"\n",
    "- It uses sub-tokens, and likely has a lot of \"fox\" followed by \"es\" in training data\n",
    "- It can handle words it's never seen in an exact bigram pair\n",
    "0 It's been trained on massive amounts of text, and has much richer knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments: What does ambiguity look like to an LLM?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first experiment is to look at what \"ambigious\" (multiple possibilities) looks like to the transformer model. Above, we focused on next token probabilities. Now we want to hone in on what happens right at the point where a sentence may diverge into two possible sentence structures. Recall in that we have no possibility for doing this with POS, Named Entities, or Dependency Graphs in SpaCy. They pick the n-best sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”¬ COUPLING EXPERIMENT 1: Distribution at Ambiguity Point\n",
      "======================================================================\n",
      "\n",
      "Prompt: 'I saw the man with the'\n",
      "\n",
      "At this point, the model must 'decide' what comes next.\n",
      "If 'telescope' follows, interpretation leans INSTRUMENT.\n",
      "If a person-attribute word follows (hat, briefcase), it's ATTRIBUTE.\n",
      "\n",
      "Top 10 next-token predictions:\n",
      "----------------------------------------\n",
      "   ' sword      ' : 0.0262 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' knife      ' : 0.0224 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' black      ' : 0.0209 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' gun        ' : 0.0187 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' mask       ' : 0.0167 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' head       ' : 0.0156 â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' beard      ' : 0.0136 â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   ' same       ' : 0.0125 â–ˆâ–ˆâ–ˆ\n",
      "   ' red        ' : 0.0121 â–ˆâ–ˆâ–ˆ\n",
      "   ' right      ' : 0.0099 â–ˆâ–ˆ\n",
      "\n",
      "ðŸ’¡ Expected Observation:\n",
      "   - Distribution should be relatively SPREAD OUT (flat)\n",
      "   - Multiple plausible continuations have non-trivial probability\n",
      "   - This 'flatness' reflects genuine ambiguity!\n",
      "   - Unlike spaCy's single parse, the LM maintains uncertainty.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# COUPLING EXPERIMENT 1: Distribution at ambiguity point\n",
    "# Cut point: Right after \"with the\" - what comes next?\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”¬ COUPLING EXPERIMENT 1: Distribution at Ambiguity Point\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# The cut point for our primary sentence\n",
    "ambiguity_prompt = \"I saw the man with the\"\n",
    "\n",
    "print(f\"\\nPrompt: '{ambiguity_prompt}'\")\n",
    "print(\"\\nAt this point, the model must 'decide' what comes next.\")\n",
    "print(\"If 'telescope' follows, interpretation leans INSTRUMENT.\")\n",
    "print(\"If a person-attribute word follows (hat, briefcase), it's ATTRIBUTE.\\n\")\n",
    "\n",
    "dist = get_next_token_distribution(ambiguity_prompt, k=10)\n",
    "\n",
    "print(\"Top 10 next-token predictions:\")\n",
    "print(\"-\" * 40)\n",
    "for token, prob in dist:\n",
    "    bar = 'â–ˆ' * int(prob * 300)\n",
    "    print(f\"   '{token:12}' : {prob:.4f} {bar}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Expected Observation:\")\n",
    "print(\"   - Distribution should be relatively SPREAD OUT (flat)\")\n",
    "print(\"   - Multiple plausible continuations have non-trivial probability\")\n",
    "print(\"   - This 'flatness' reflects genuine ambiguity!\")\n",
    "print(\"   - Unlike spaCy's single parse, the LM maintains uncertainty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we push the LLM to look at two different structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”¬ COUPLING EXPERIMENT 2: Forced-Choice Interpretation Scores\n",
      "======================================================================\n",
      "\n",
      "Base: 'I saw the man with the telescope'\n",
      "\n",
      "Continuation A (INSTRUMENT): ' and got a clear view of his face.'\n",
      "Continuation B (ATTRIBUTE):  ' standing on the corner.'\n",
      "\n",
      "--------------------------------------------------\n",
      "Scores (higher = more likely):\n",
      "   INSTRUMENT: sum=-23.026, avg=-2.558 (9 tokens)\n",
      "   ATTRIBUTE:  sum=-17.139, avg=-3.428 (5 tokens)\n",
      "\n",
      "   ðŸ† Model preference: INSTRUMENT\n",
      "\n",
      "ðŸ’¡ Expected Observation:\n",
      "   - The model shows a PROBABILISTIC preference, not a hard choice\n",
      "   - Both continuations have finite probability (neither is 'impossible')\n",
      "   - This is fundamentally different from spaCy's single parse!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”¬ COUPLING EXPERIMENT 2: Forced-Choice Interpretation Scores\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Base prompt\n",
    "base = \"I saw the man with the telescope\"\n",
    "\n",
    "# Continuations that force each interpretation\n",
    "instrument_continuation = \" and got a clear view of his face.\"\n",
    "attribute_continuation = \" standing on the corner.\"\n",
    "\n",
    "print(f\"\\nBase: '{base}'\")\n",
    "print(f\"\\nContinuation A (INSTRUMENT): '{instrument_continuation}'\")\n",
    "print(f\"Continuation B (ATTRIBUTE):  '{attribute_continuation}'\")\n",
    "\n",
    "# Score both\n",
    "score_a = score_continuation(base, instrument_continuation)\n",
    "score_b = score_continuation(base, attribute_continuation)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"Scores (higher = more likely):\")\n",
    "print(f\"   INSTRUMENT: sum={score_a[0]:.3f}, avg={score_a[1]:.3f} ({score_a[2]} tokens)\")\n",
    "print(f\"   ATTRIBUTE:  sum={score_b[0]:.3f}, avg={score_b[1]:.3f} ({score_b[2]} tokens)\")\n",
    "\n",
    "winner = \"INSTRUMENT\" if score_a[1] > score_b[1] else \"ATTRIBUTE\"\n",
    "print(f\"\\n   ðŸ† Model preference: {winner}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Expected Observation:\")\n",
    "print(\"   - The model shows a PROBABILISTIC preference, not a hard choice\")\n",
    "print(\"   - Both continuations have finite probability (neither is 'impossible')\")\n",
    "print(\"   - This is fundamentally different from spaCy's single parse!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the scoring.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The scoring uses **log probabilities** - here's what that means:\n",
    "\n",
    "**Log probability**: Instead of multiplying tiny probabilities (which gets numerically unstable), we add their logarithms. Since probabilities are between 0 and 1, log probabilities are **negative numbers**. Less negative = more likely.\n",
    "\n",
    "**The two scores reported**:\n",
    "- `sum` - Total log probability across all tokens in the continuation\n",
    "- `avg` - Average log probability per token (sum divided by number of tokens)\n",
    "\n",
    "**Why INSTRUMENT won despite lower sum?**\n",
    "- INSTRUMENT: 9 tokens, sum = -23.026, **avg = -2.558**\n",
    "- ATTRIBUTE: 5 tokens, sum = -17.139, **avg = -3.428**\n",
    "\n",
    "The average is more fair for comparison because longer sequences naturally have more negative sums. The INSTRUMENT continuation has a better average probability per token (-2.558 vs -3.428), meaning each word is more \"expected\" by the model in that context.\n",
    "\n",
    "Does that make sense? Want to try scoring some different continuations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be looking more closely at log probabilities later because they are an essential tool in language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ”¬ COUPLING EXPERIMENT 3: Rewrite-to-Probability Side-by-Side\n",
      "======================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“ Primary (ambiguous)\n",
      "   Sentence: I saw the man with the telescope.\n",
      "   spaCy: 'with' â†’ man (ATTRIBUTE)\n",
      "   LM top-1: 'sword' (0.026), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“ Rewrite 1 (attribute likely)\n",
      "   Sentence: I saw the man with the red hat.\n",
      "   spaCy: 'with' â†’ man (ATTRIBUTE)\n",
      "   LM top-1: '-' (0.069), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“ Rewrite 2 (instrument likely)\n",
      "   Sentence: I saw the bird with the telescope.\n",
      "   spaCy: 'with' â†’ saw (INSTRUMENT)\n",
      "   LM top-1: 'eye' (0.027), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“ Rewrite 3 (instrument forced)\n",
      "   Sentence: I saw the man with my telescope.\n",
      "   spaCy: 'with' â†’ saw (INSTRUMENT)\n",
      "   LM top-1: 'hands' (0.039), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š SUMMARY TABLE\n",
      "======================================================================\n",
      "            Sentence spaCy Parse Top-1 Token Distribution LM Preference\n",
      " Primary (ambiguous)   ATTRIBUTE       sword         FLAT    INSTRUMENT\n",
      "Rewrite 1 (attribute   ATTRIBUTE           -         FLAT    INSTRUMENT\n",
      "Rewrite 2 (instrumen  INSTRUMENT         eye         FLAT    INSTRUMENT\n",
      "Rewrite 3 (instrumen  INSTRUMENT       hands         FLAT    INSTRUMENT\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# COUPLING EXPERIMENT 3: Complete side-by-side analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”¬ COUPLING EXPERIMENT 3: Rewrite-to-Probability Side-by-Side\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define cut points and continuations for each sentence\n",
    "experiments = [\n",
    "    {\n",
    "        \"label\": \"Primary (ambiguous)\",\n",
    "        \"sentence\": \"I saw the man with the telescope.\",\n",
    "        \"cut_prompt\": \"I saw the man with the\",\n",
    "        \"instrument_cont\": \" telescope and got a clear view.\",\n",
    "        \"attribute_cont\": \" telescope standing nearby.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Rewrite 1 (attribute likely)\",\n",
    "        \"sentence\": \"I saw the man with the red hat.\",\n",
    "        \"cut_prompt\": \"I saw the man with the red\",\n",
    "        \"instrument_cont\": \" hat and got a clear view.\",\n",
    "        \"attribute_cont\": \" hat standing nearby.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Rewrite 2 (instrument likely)\",\n",
    "        \"sentence\": \"I saw the bird with the telescope.\",\n",
    "        \"cut_prompt\": \"I saw the bird with the\",\n",
    "        \"instrument_cont\": \" telescope and got a clear view.\",\n",
    "        \"attribute_cont\": \" telescope perched nearby.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Rewrite 3 (instrument forced)\",\n",
    "        \"sentence\": \"I saw the man with my telescope.\",\n",
    "        \"cut_prompt\": \"I saw the man with my\",\n",
    "        \"instrument_cont\": \" telescope and got a clear view.\",\n",
    "        \"attribute_cont\": \" telescope standing nearby.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results_table = []\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"\\n{'â”€'*60}\")\n",
    "    print(f\"ðŸ“ {exp['label']}\")\n",
    "    print(f\"   Sentence: {exp['sentence']}\")\n",
    "    \n",
    "    # Get spaCy parse\n",
    "    doc = nlp(exp['sentence'])\n",
    "    with_token = [t for t in doc if t.text.lower() == \"with\"][0]\n",
    "    spacy_attachment = with_token.head.text\n",
    "    spacy_interp = \"INSTRUMENT\" if spacy_attachment in [\"saw\", \"see\"] else \"ATTRIBUTE\"\n",
    "    \n",
    "    # Get LM distribution\n",
    "    dist = get_next_token_distribution(exp['cut_prompt'], k=5)\n",
    "    top_token = dist[0][0].strip() if dist else \"?\"\n",
    "    top_prob = dist[0][1] if dist else 0\n",
    "    \n",
    "    # Calculate entropy-like measure (is distribution sharp or flat?)\n",
    "    probs = [p for _, p in dist[:5]]\n",
    "    max_prob = max(probs) if probs else 0\n",
    "    sharpness = \"SHARP\" if max_prob > 0.3 else \"FLAT\"\n",
    "    \n",
    "    # Score continuations\n",
    "    instr_score = score_continuation(exp['cut_prompt'], exp['instrument_cont'])\n",
    "    attr_score = score_continuation(exp['cut_prompt'], exp['attribute_cont'])\n",
    "    lm_preference = \"INSTRUMENT\" if instr_score[1] > attr_score[1] else \"ATTRIBUTE\"\n",
    "    \n",
    "    print(f\"   spaCy: 'with' â†’ {spacy_attachment} ({spacy_interp})\")\n",
    "    print(f\"   LM top-1: '{top_token}' ({top_prob:.3f}), dist={sharpness}\")\n",
    "    print(f\"   LM preference: {lm_preference}\")\n",
    "    \n",
    "    results_table.append({\n",
    "        \"Sentence\": exp['label'][:20],\n",
    "        \"spaCy Parse\": spacy_interp,\n",
    "        \"Top-1 Token\": top_token[:10],\n",
    "        \"Distribution\": sharpness,\n",
    "        \"LM Preference\": lm_preference\n",
    "    })\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "summary_df = pd.DataFrame(results_table)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Looking at this summary table, there are some interesting observations:\n",
    "\n",
    "**SpaCy's behavior**: It makes a single parse decision for each sentence. It chose ATTRIBUTE for the ambiguous cases and INSTRUMENT when \"my\" appears (which is a strong syntactic cue).\n",
    "\n",
    "**The LM's behavior**: It consistently prefers INSTRUMENT across all sentences when scoring the two continuations. However, notice the \"Distribution\" column shows FLAT for all - this means at the cut point, the model sees multiple plausible next words with similar probabilities, reflecting genuine uncertainty.\n",
    "\n",
    "**The mismatch**: The LM's top-1 predictions (sword, hands, eye) don't match the actual words in the sentences. This shows the model is considering many possibilities, not committing to one interpretation early.\n",
    "\n",
    "What's particularly interesting is that even though the distribution is FLAT (uncertain), when we force the model to score complete continuations, it shows a preference. Can you think on why this may be?\n",
    "\n",
    "What aspect would you like to explore more - why the LM prefers INSTRUMENT, or how we might design better experiments to test these interpretations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What does a next-token objective teach a model about syntax and meaning?\n",
    "\n",
    "2. How does probability relate to ambiguity and \"preference\"?\n",
    "\n",
    "3. Why might the LLM's preference differ from spaCy's parse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q1_answer = \"Your answer about what next-token prediction teaches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_answer = \"Your answer about how probability relates to ambiguity and preference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_answer = \"Your answer about differences between LLM and spaCy parser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we're going to look at two approaches to sentiment analysis. VADER is a well-known and popular, rule-based model for short texts, like social media. We may spend time using it because it's easy use, hack, and understand. Plus, you can use VADER output to help train another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical approach using Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸŽ­ SENTIMENT ANALYSIS: Classical (VADER) vs LLM\n",
      "======================================================================\n",
      "\n",
      "Why VADER? It's a rule-based sentiment analyzer that uses:\n",
      "  â€¢ A sentiment lexicon (word â†’ score mappings)\n",
      "  â€¢ Grammatical rules (negation, intensifiers, etc.)\n",
      "  â€¢ Punctuation and capitalization heuristics\n",
      "  â€¢ Fast, deterministic, and interpretable!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Initialize VADER\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Sentiment-ambiguous test cases\n",
    "test_utterances = [\n",
    "    \"Oh great, another meeting that could have been an email.\",  # Sarcasm\n",
    "    \"The food was not unpleasant, I suppose.\",  # Double negative, hedged\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ­ SENTIMENT ANALYSIS: Classical (VADER) vs LLM\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWhy VADER? It's a rule-based sentiment analyzer that uses:\")\n",
    "print(\"  â€¢ A sentiment lexicon (word â†’ score mappings)\")\n",
    "print(\"  â€¢ Grammatical rules (negation, intensifiers, etc.)\")\n",
    "print(\"  â€¢ Punctuation and capitalization heuristics\")\n",
    "print(\"  â€¢ Fast, deterministic, and interpretable!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š VADER (Classical) Results\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Text: \"Oh great, another meeting that could have been an email.\"\n",
      "   Compound: 0.625 â†’ POSITIVE\n",
      "   (pos=0.31, neg=0.00, neu=0.69)\n",
      "\n",
      "Text: \"The food was not unpleasant, I suppose.\"\n",
      "   Compound: 0.372 â†’ POSITIVE\n",
      "   (pos=0.34, neg=0.00, neu=0.66)\n",
      "\n",
      "ðŸ’¡ Expected Observation:\n",
      "   - VADER may miss sarcasm (text 1 has positive word 'great')\n",
      "   - Double negatives can confuse rule-based systems\n"
     ]
    }
   ],
   "source": [
    "# VADER analysis\n",
    "print(\"\\n\" + \"â”€\"*60)\n",
    "print(\"ðŸ“Š VADER (Classical) Results\")\n",
    "print(\"â”€\"*60)\n",
    "\n",
    "vader_results = []\n",
    "for text in test_utterances:\n",
    "    scores = vader.polarity_scores(text)\n",
    "    \n",
    "    # Determine label from compound score\n",
    "    if scores['compound'] >= 0.05:\n",
    "        label = \"POSITIVE\"\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        label = \"NEGATIVE\"\n",
    "    else:\n",
    "        label = \"NEUTRAL\"\n",
    "    \n",
    "    vader_results.append({\n",
    "        \"text\": text[:40] + \"...\",\n",
    "        \"label\": label,\n",
    "        \"compound\": scores['compound'],\n",
    "        \"pos\": scores['pos'],\n",
    "        \"neg\": scores['neg'],\n",
    "        \"neu\": scores['neu']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nText: \\\"{text}\\\"\")\n",
    "    print(f\"   Compound: {scores['compound']:.3f} â†’ {label}\")\n",
    "    print(f\"   (pos={scores['pos']:.2f}, neg={scores['neg']:.2f}, neu={scores['neu']:.2f})\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Expected Observation:\")\n",
    "print(\"   - VADER may miss sarcasm (text 1 has positive word 'great')\")\n",
    "print(\"   - Double negatives can confuse rule-based systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have API access to an LLM, feel free to play with this to make it work with your API. If not, just read the output and follow along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ¤– LLM Sentiment Analysis\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Text: \"Oh great, another meeting that could have been an email.\"\n",
      "   Provider: anthropic/claude-sonnet-4-5\n",
      "   Label: parse_error\n",
      "   Confidence: 0\n",
      "   Rationale: Could not parse: ModelResponse(id='chatcmpl-8ceec6d1-7f5c-4cb0-ae3a-b2ffd58b6a91', created=1767972770, model='claude-\n",
      "   Cues: []\n",
      "\n",
      "Text: \"The food was not unpleasant, I suppose.\"\n",
      "   Provider: anthropic/claude-sonnet-4-5\n",
      "   Label: parse_error\n",
      "   Confidence: 0\n",
      "   Rationale: Could not parse: ModelResponse(id='chatcmpl-d393ea23-8506-472d-804b-714b0cf43fea', created=1767972777, model='claude-\n",
      "   Cues: []\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# LLM Sentiment Analysis\n",
    "print(\"\\n\" + \"â”€\"*60)\n",
    "print(\"ðŸ¤– LLM Sentiment Analysis\")\n",
    "print(\"â”€\"*60)\n",
    "\n",
    "def analyze_sentiment_llm(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment using available LLM with strict JSON output.\n",
    "    Returns (response_text, model_name)\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the sentiment of this text and respond with ONLY valid JSON.\n",
    "\n",
    "    Text: \"{text}\"\n",
    "\n",
    "    Respond with this exact JSON format (no other text):\n",
    "    {{\n",
    "        \"label\": \"positive\" | \"negative\" | \"neutral\" | \"mixed\",\n",
    "        \"confidence\": 0.0-1.0,\n",
    "        \"rationale\": \"brief explanation\",\n",
    "        \"cues\": [\"cue1\", \"cue2\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    chat = make_chat(LLM_MODELS[0])\n",
    "    response = chat(prompt)\n",
    "    response_text = str(chat(prompt))\n",
    "    return response_text, LLM_MODELS[0]   # â† explicit, deterministic\n",
    "\n",
    "\n",
    "def parse_sentiment_json(response_text):\n",
    "    \"\"\"Safely parse JSON from LLM response.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Try to extract JSON from response\n",
    "    try:\n",
    "        # First try direct parse\n",
    "        return json.loads(response_text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to find JSON in the response\n",
    "    try:\n",
    "        json_match = re.search(r'\\{[^}]+\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Return error structure\n",
    "    return {\n",
    "        \"label\": \"parse_error\",\n",
    "        \"confidence\": 0,\n",
    "        \"rationale\": f\"Could not parse: {response_text[:100]}\",\n",
    "        \"cues\": []\n",
    "    }\n",
    "\n",
    "# Analyze each utterance\n",
    "llm_results = []\n",
    "\n",
    "for text in test_utterances:\n",
    "    print(f\"\\nText: \\\"{text}\\\"\")\n",
    "    response, provider = analyze_sentiment_llm(text)\n",
    "    print(f\"   Provider: {provider}\")\n",
    "    \n",
    "    parsed = parse_sentiment_json(response)\n",
    "    llm_results.append(parsed)\n",
    "    \n",
    "    print(f\"   Label: {parsed.get('label', 'N/A')}\")\n",
    "    print(f\"   Confidence: {parsed.get('confidence', 'N/A')}\")\n",
    "    print(f\"   Rationale: {parsed.get('rationale', 'N/A')}\")\n",
    "    print(f\"   Cues: {parsed.get('cues', [])}\")\n",
    "if len(llm_results) < len(test_utterances):\n",
    "    print(\"âš ï¸ Some LLM sentiment analyses failed; comparison table may be incomplete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparision of VADER and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š COMPARISON: VADER vs LLM\n",
      "======================================================================\n",
      "                      Text (truncated) VADER Label VADER Score   LLM Label LLM Conf\n",
      "Oh great, another meeting that coul...    POSITIVE        0.62 parse_error     0.00\n",
      "The food was not unpleasant, I supp...    POSITIVE        0.37 parse_error     0.00\n",
      "\n",
      "ðŸ’¡ Discussion Points:\n",
      "   - Where did VADER fail? Why?\n",
      "   - Did the LLM catch sarcasm/nuance that VADER missed?\n",
      "   - What 'cues' did the LLM identify?\n",
      "   - Which would you trust more for: customer reviews? tweets? emails?\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š COMPARISON: VADER vs LLM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = []\n",
    "for i, text in enumerate(test_utterances):\n",
    "    comparison_data.append({\n",
    "        \"Text (truncated)\": text[:35] + \"...\",\n",
    "        \"VADER Label\": vader_results[i]['label'],\n",
    "        \"VADER Score\": f\"{vader_results[i]['compound']:.2f}\",\n",
    "        \"LLM Label\": llm_results[i].get('label', 'N/A'),\n",
    "        \"LLM Conf\": f\"{llm_results[i].get('confidence', 0):.2f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ’¡ Discussion Points:\")\n",
    "print(\"   - Where did VADER fail? Why?\")\n",
    "print(\"   - Did the LLM catch sarcasm/nuance that VADER missed?\")\n",
    "print(\"   - What 'cues' did the LLM identify?\")\n",
    "print(\"   - Which would you trust more for: customer reviews? tweets? emails?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit:** Answer these questions:\n",
    "\n",
    "1. For the sarcastic sentence, how did VADER's label compare to the LLM's? What caused any difference?\n",
    "\n",
    "2. What are two scenarios where you'd prefer VADER over an LLM, and two where you'd prefer the LLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_answer = \"Your analysis of sarcasm handling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_answer =  \"Prefer VADER for scenario 1 or scenario 2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_answer = \"Prefer LLM for scenario 1 or scenario 2?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E - spaCy pipline with LLM Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how NLP systems can be built as pipelines of components and how this differs from end-to-end LLM approaches. Again, don't worry about the code, just think through this conceptually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok2vec: Tok2Vec\n",
      "tagger: Tagger\n",
      "parser: DependencyParser\n",
      "attribute_ruler: AttributeRuler\n",
      "lemmatizer: EnglishLemmatizer\n",
      "ner: EntityRecognizer\n"
     ]
    }
   ],
   "source": [
    "# You've already seen a default spaCy pipeline architecture like this\n",
    "\n",
    "for name, component in nlp.pipeline:\n",
    "    print(f\"{name}: {type(component).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom SpaCy component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how to create and add a custom component in spaCy. Let's build an component that flags a sentence for both ORG and DATE.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Let me explain how custom spaCy components work.\n",
    "\n",
    "**Custom components** are functions that process a `Doc` object and return it (possibly modified). They get added to the pipeline and run automatically when you call `nlp(text)`.\n",
    "\n",
    "Here's the basic structure:\n",
    "\n",
    "```python\n",
    "@spacy.Language.component(\"component_name\")\n",
    "def custom_component(doc):\n",
    "    # Do something with doc\n",
    "    # You can add custom attributes, modify tokens, etc.\n",
    "    return doc\n",
    "\n",
    "# Add it to the pipeline\n",
    "nlp.add_pipe(\"component_name\", last=True)\n",
    "```\n",
    "\n",
    "For your specific task (flagging sentences with both ORG and DATE entities), you'd want to:\n",
    "\n",
    "1. Iterate through the doc's sentences\n",
    "2. Check what entity types appear in each sentence\n",
    "3. Store a flag somewhere (maybe as a custom attribute on the `Span`)\n",
    "\n",
    "Would you like to try writing this component yourself, or would you like me to show you how to do it step by step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'org_date_flagger']\n"
     ]
    }
   ],
   "source": [
    "# Create a custom spaCy component\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "@Language.component(\"org_date_flagger\")\n",
    "def org_date_flagger(doc):\n",
    "    \"\"\"Flag sentences that contain both ORG and DATE entities.\"\"\"\n",
    "    # Add custom attribute to doc if not exists\n",
    "    if not doc.has_extension(\"flagged_sentences\"):\n",
    "        from spacy.tokens import Doc\n",
    "        Doc.set_extension(\"flagged_sentences\", default=[])\n",
    "    \n",
    "    flagged = []\n",
    "    for sent in doc.sents:\n",
    "        sent_ents = [ent.label_ for ent in sent.ents]\n",
    "        if \"ORG\" in sent_ents and \"DATE\" in sent_ents:\n",
    "            flagged.append(sent.text)\n",
    "    \n",
    "    doc._.flagged_sentences = flagged\n",
    "    return doc\n",
    "\n",
    "# Add to pipeline (only if not already there)\n",
    "if \"org_date_flagger\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"org_date_flagger\", last=True)\n",
    "\n",
    "print(f\"\\nUpdated pipeline: {nlp.pipe_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why should we use this particular syntax? doc._.flagged_sentences \n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The `doc._` syntax is spaCy's way of accessing **custom extensions** that you've added to a Doc object.\n",
    "\n",
    "Here's why this design:\n",
    "\n",
    "**Built-in attributes** use direct access:\n",
    "- `doc.ents` (entities)\n",
    "- `doc.text` (text)\n",
    "- `token.pos_` (part of speech)\n",
    "\n",
    "**Custom attributes** use the underscore namespace:\n",
    "- `doc._.flagged_sentences` (your custom attribute)\n",
    "- `token._.custom_score` (if you created this)\n",
    "\n",
    "This separation prevents naming conflictsâ€”your custom `flagged_sentences` won't accidentally override something built into spaCy. It also makes it clear when you're using custom vs. built-in functionality.\n",
    "\n",
    "The underscore is a special namespace that spaCy reserves for user extensions. You must register extensions with `Doc.set_extension()` before using them, which is what the code does with the `if not doc.has_extension()` check.\n",
    "\n",
    "Does this design pattern make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test text:\n",
      "Microsoft announced record earnings on January 24th, 2024.\n",
      "The weather was sunny. Apple plans to release new products in March.\n",
      "John went to the store.\n",
      "\n",
      "\n",
      " Sentences containing both ORG and DATE:\n",
      "\n",
      "\n",
      "Microsoft announced record earnings on January 24th, 2024.\n",
      "\n",
      "Apple plans to release new products in March.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the custom component\n",
    "test_text = \"\"\"Microsoft announced record earnings on January 24th, 2024.\n",
    "The weather was sunny. Apple plans to release new products in March.\n",
    "John went to the store.\"\"\"\n",
    "\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"\\nTest text:\")\n",
    "print(test_text)\n",
    "print(\"\\n\\n Sentences containing both ORG and DATE:\\n\\n\")\n",
    "for sent in doc._.flagged_sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“‹ EXTRACTIVE SUMMARY (Classical)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Top sentences (by TF + entity score):\n",
      "\n",
      "1. (score: 0.88)\n",
      "   This was especially true in the area known as Round Peak, around Mount Airy, North Carolina, and Galax, Virginia.\n",
      "\n",
      "2. (score: 0.82)\n",
      "   Starting on Christmas and continuing for 12 days,people in the mountains would go from house to house viisiting neighbors, dancing and playing music.\n",
      "\n",
      "ðŸ’¡ Note: Extractive = select existing sentences, transparent scoring\n"
     ]
    }
   ],
   "source": [
    "# Classical extractive summarizer\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "article = \"In the Blue Ridge, the Christmas season was celebrated for days on end, with gatherings of family and friends, good food, and lots of music. This was especially true in the area known as Round Peak, around Mount Airy, North Carolina, and Galax, Virginia. The tradition was called Breaking up Christmas, and December 25th was just the beginning. Starting on Christmas and continuing for 12 days,people in the mountains would go from house to house viisiting neighbors, dancing and playing music.\"\n",
    "\n",
    "def extractive_summarize(text, num_sentences=2):\n",
    "    \"\"\"Simple extractive summarizer using TF and entity presence.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Get term frequencies (excluding stop words)\n",
    "    word_freq = Counter()\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha:\n",
    "            word_freq[token.lemma_.lower()] += 1\n",
    "    \n",
    "    # Score each sentence\n",
    "    sentence_scores = []\n",
    "    for sent in doc.sents:\n",
    "        score = 0\n",
    "        # TF score\n",
    "        for token in sent:\n",
    "            if token.lemma_.lower() in word_freq:\n",
    "                score += word_freq[token.lemma_.lower()]\n",
    "        \n",
    "        # Bonus for entities\n",
    "        entity_bonus = len([e for e in sent.ents]) * 2\n",
    "        score += entity_bonus\n",
    "        \n",
    "        # Normalize by length\n",
    "        score = score / (len(list(sent)) + 1)\n",
    "        \n",
    "        sentence_scores.append((sent.text.strip(), score))\n",
    "    \n",
    "    # Sort by score and return top sentences\n",
    "    sorted_sents = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_sents[:num_sentences]\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*60)\n",
    "print(\"ðŸ“‹ EXTRACTIVE SUMMARY (Classical)\")\n",
    "print(\"â”€\"*60)\n",
    "\n",
    "extracted = extractive_summarize(article, num_sentences=2)\n",
    "print(\"\\nTop sentences (by TF + entity score):\")\n",
    "for i, (sent, score) in enumerate(extracted, 1):\n",
    "    print(f\"\\n{i}. (score: {score:.2f})\")\n",
    "    print(f\"   {sent}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: Extractive = select existing sentences, transparent scoring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why the first sentence may have been scored higher. This seems counter-intuitive.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good observation! Let's think through why that first sentence scored higher:\n",
    "\n",
    "**The first sentence** has:\n",
    "- Multiple entities: \"Round Peak\", \"Mount Airy\", \"North Carolina\", \"Galax\", \"Virginia\" (5 GPE entities!)\n",
    "- Entity bonus: 5 entities Ã— 2 = +10 to the score\n",
    "- This entity bonus significantly boosted its score\n",
    "\n",
    "**The second sentence** has:\n",
    "- More thematic words (\"Christmas\", \"mountains\", \"house\", \"music\")\n",
    "- But fewer named entities\n",
    "- Lower entity bonus\n",
    "\n",
    "The algorithm assumes entities = importance, which isn't always true. The first sentence is actually providing geographic context, while the second describes the actual tradition.\n",
    "\n",
    "This is a classic problem with simple extractive summarizersâ€”they use heuristics (like \"entities are important\") that don't always align with what humans find most relevant.\n",
    "\n",
    "Can you think of how you might modify the scoring to better capture the main idea of this passage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ¨ ABSTRACTIVE SUMMARY (LLM)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ModelResponse(id='chatcmpl-921fa7f4-9731-4744-9901-67600c185f44', created=1767973051, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='HEADLINE: Blue Ridge Christmas Tradition Lasted Twelve Days\\n\\nâ€¢ Breaking up Christmas was a Blue Ridge tradition celebrated around Mount Airy, NC and Galax, VA\\nâ€¢ The celebration began December 25th and continued for 12 consecutive days\\nâ€¢ People visited neighbors house to house, gathering for music, dancing, food and fellowship', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=75, prompt_tokens=187, total_tokens=262, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))\n",
      "\n",
      "âš ï¸  Warning: LLM summaries can:\n",
      "   - Hallucinate facts not in the original\n",
      "   - Over-generalize or lose nuance\n",
      "   - Be non-deterministic\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# LLM abstractive summarization\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*60)\n",
    "print(\"âœ¨ ABSTRACTIVE SUMMARY (LLM)\")\n",
    "print(\"â”€\"*60)\n",
    "\n",
    "chat = make_chat(LLM_MODELS[0])\n",
    "\n",
    "def llm_summarize(text):\n",
    "    \"\"\"\n",
    "    Generate abstractive summary using available LLM.\n",
    "    Returns plain text.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Summarize this article in exactly:\n",
    "\n",
    "- 3 bullet points (key facts)\n",
    "- 1 headline (max 10 words)\n",
    "\n",
    "Article:\n",
    "{text}\n",
    "\n",
    "Format your response as:\n",
    "\n",
    "HEADLINE: <headline>\n",
    "\n",
    "â€¢ <bullet 1>\n",
    "â€¢ <bullet 2>\n",
    "â€¢ <bullet 3>\n",
    "\"\"\"\n",
    "    return chat(prompt)\n",
    "\n",
    "summary_text = llm_summarize(article)\n",
    "print(summary_text)\n",
    "\n",
    "print(\"\\nâš ï¸  Warning: LLM summaries can:\")\n",
    "print(\"   - Hallucinate facts not in the original\")\n",
    "print(\"   - Over-generalize or lose nuance\")\n",
    "print(\"   - Be non-deterministic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "**Submit:** \n",
    "\n",
    "1. What are two advantages of spaCy's modular pipeline approach?\n",
    "\n",
    "2. When would you choose extractive over abstractive summarization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q7_answer = \"Your answer about pipeline advantages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q8_answer = \"Your answer about summarization choice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F - Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize what was learned.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "This lab covered a lot of ground in NLP! Here's what you explored:\n",
    "\n",
    "**Core NLP Components (SpaCy)**:\n",
    "- Tokens and their attributes (lemmas, POS tags, stop words)\n",
    "- Named Entity Recognition (NER) - how models tag entities and why they sometimes get it wrong\n",
    "- Dependency parsing - understanding relationships between words in sentences\n",
    "\n",
    "**Language Models as Probability Distributions**:\n",
    "- Bigram models vs. neural language models (DistilGPT2)\n",
    "- Next-token prediction and what probability distributions reveal about ambiguity\n",
    "- How LMs handle syntactic ambiguity differently than parsers (maintaining uncertainty vs. committing to one parse)\n",
    "\n",
    "**Practical Applications**:\n",
    "- Sentiment analysis: rule-based (VADER) vs. LLM approaches\n",
    "- Summarization: extractive (selecting sentences) vs. abstractive (generating new text)\n",
    "- Building custom SpaCy pipeline components\n",
    "\n",
    "**Key Insight**: Different NLP approaches have different strengths - modular pipelines are transparent and fast, while LLMs capture nuance but are less interpretable.\n",
    "\n",
    "What part did you find most interesting or want to explore more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit:**\n",
    "1. What did you find most interesting in this lab?\n",
    "2. Was there something you found surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q9_answer = \"What you found most interesting in the lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_answer = \"Whether you found something surprising\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Notebook for credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: replace \"test_student\" with your name and run the cell. You will see your answers printed as feedback. If you wish to change your answers... just re-submit. \n",
    "\n",
    "Feel free to use AI as feedback on your answers after you've tried to answer questions yourself. I'll scan responses to see what might have been confusing in the lab. Lab questions are ungraded and we can talk about your thoughts or questions in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from data401_nlp.helpers.submit import submit_answers\n",
    "\n",
    "submit_answers(\n",
    "    student_id=\"test_student\",\n",
    "    path=\"1-intro.ipynb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data401_nlp",
   "language": "python",
   "name": "data401_nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
