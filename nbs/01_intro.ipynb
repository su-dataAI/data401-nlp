{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50520960-9131-44e2-9e86-fd67608d7d60",
   "metadata": {},
   "source": [
    "# Lab 1 - Introduction to the SpaCy Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d17bce-d8ac-428f-82f7-dd2c7ced10c6",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "Welcome to your first hands-on experience with Natural Language Processing! This notebook takes a different approach from traditional NLP courses. Rather than starting with abstract theory, we will learn NLP concepts by working directly with spaCy, a powerful library used by data scientists and engineers in real-world applications.\n",
    "\n",
    "Why this approach? Learning NLP can be overwhelming. Textbooks like Jurafsky and Martin's *Speech and Language Processing* are comprehensive but dense. By grounding our learning in spaCy, you will build practical skills while gaining conceptual understanding. Every term we introduce connects to something you can see and manipulate in code.\n",
    "\n",
    "**What is spaCy?** [SpaCy v.3](https://spacy.io) is an industrial-strength NLP library for Python. Companies use it to build everything from chatbots to document analysis systems. When you learn spaCy, you are learning a tool that employers expect data scientists to know. It processes text quickly, integrates well with other Python libraries, and handles the complex details of language analysis for you.\n",
    "\n",
    "This notebook provides a whirlwind tour of spaCy's capabilities. We will work with two fundamental objects: the **Doc** (a processed text document) and **Token** (individual pieces of text like words and punctuation). By the end, you will understand how spaCy breaks text apart, labels it, and identifies relationships between words.\n",
    "\n",
    "Do not worry if everything does not click immediately. This is an introduction. We will revisit these concepts throughout the course, and each time they will become clearer. The goal today is familiarity, not mastery.\n",
    "\n",
    "We will also begin exploring how traditional NLP methods relate to Large Language Models (LLMs). Traditional methods (like those in spaCy) are fast, predictable, and transparent. LLMs (like ChatGPT) are flexible and capture nuance but are slower and less explainable. Understanding when to use each is a key skill for modern NLP practitioners.\n",
    "\n",
    "**Related resources**\n",
    "- This is a very thorough overview of SpaCy worth skimming! https://deepnote.com/blog/ultimate-guide-to-the-spacy-library-in-python.\n",
    "- You will also be working your way through the spaCy tutorial here (https://course.spacy.io/en) over the first half of this course.\n",
    "\n",
    "**Learning objectives**\n",
    "\n",
    "- Introduction to core NLP components and spaCy pipeline\n",
    "- Introduction to tokens and their attributes\n",
    "- Introduction to language models as probability distributions\n",
    "    - Bigram models\n",
    "    - Neural language models\n",
    "- Thought exercise - Traditional NLP vs LLMs\n",
    "    - Sentiment analysis\n",
    "    - Summarization\n",
    "- Demonstration of flexible SpaCy pipelines incorporating LLM components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095455f7-9d83-47e5-889c-2645b8684215",
   "metadata": {},
   "source": [
    "## How to Use This Notebook\n",
    "\n",
    "**Your goal** is to read the notes and code in this notebook, and answer questions. This is what you will do in each notebook in this class. I used AI copiously to give you a sense of how you might use AI to learn a new library.\n",
    "\n",
    "If there is code you don't understand (and that could be most of it!), ask AI to explain it cell-by-cell. Part of your goal is to become fluent in reading code. Make small changes and experiment. If you write code, make tiny, iterative changes and test. Get familiar with the patterns of what must be done and why.\n",
    "\n",
    "As a student, **you are responsible for answering all questions in the reflection sections and running the last cell in the notebook to submit your answers**. They are ungraded, though we'll talk about your thoughts and questions in class.\n",
    "\n",
    "Note: you will see cells marked with **#| eval: false** throughout these notebooks. These are directives that tell the nbdev framework used by this repository not to test during continuous integration. Since the code in these notebooks are not part of the library, most, if not, all will be marked #| eval: false. You can delete them in your own notebooks, if you like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd50468-d688-4a60-a7bf-2bf4663fb312",
   "metadata": {},
   "source": [
    "## Load Libraries and Models\n",
    "\n",
    "Before we can work with spaCy, we need to import the necessary libraries. Think of this as gathering your tools before starting a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe15e0c-abc5-428f-8037-2bd5be32006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are colab, un-comment the pip install below.\n",
    "# This will not be necessary on DeepNote or your local installation\n",
    "\n",
    "#!pip install data401_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93730c4e-ca8a-44c3-9963-1459ac2b0112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.6\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Environment (must run first)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import data401_nlp\n",
    "print(data401_nlp.__version__)\n",
    "\n",
    "# Core libs\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ML libs\n",
    "import pandas as pd\n",
    "\n",
    "# NLP libs\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "# Tools libs\n",
    "import json\n",
    "import fastcore.tools as fc\n",
    "import orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049e9b1-b762-40a0-81d1-efedac59933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected environment: dotenv\n",
      "SUBMIT_API_KEY present: True\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# This checks to make sure your SUBMIT_API_KEY is present\n",
    "# It can take a moment to load... run again if it fails the first time\n",
    "\n",
    "env = load_env()\n",
    "print(\"Detected environment:\", env)\n",
    "print(\"SUBMIT_API_KEY present:\", bool(os.getenv(\"SUBMIT_API_KEY\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09118458",
   "metadata": {},
   "source": [
    "### Loading a spaCy Language Model\n",
    "\n",
    "SpaCy does not analyze text on its own. It needs a **language model**—a pre-trained set of rules and patterns for a specific language. We are using `en_core_web_sm`, a small English model optimized for CPU processing. The \"sm\" stands for \"small,\" meaning it downloads quickly and runs fast, though larger models exist for more demanding applications.\n",
    "\n",
    "When you visit the [model documentation](https://spacy.io/models/en#en_core_web_sm), you will find details about what text it was trained on, what components it includes, and how accurate it is. We will explore most of these components over the coming weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebebf7-34c5-442e-bac2-4b66e78b29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# load spacy\n",
    "# This helper ensures it will automatically download if not present\n",
    "\n",
    "from data401_nlp.helpers.spacy import ensure_spacy_model\n",
    "\n",
    "def get_nlp():\n",
    "    return ensure_spacy_model(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d5f68",
   "metadata": {},
   "source": [
    "### Setting Up LLM Access\n",
    "\n",
    "Later in this notebook, we will compare traditional NLP methods with LLM-based approaches. The code below sets up access to an LLM through our helper functions. Do not worry about the details here—just know that this gives us a way to ask questions to an AI model like Claude or GPT.\n",
    "\n",
    "Your model is currently set to Claude, though you can change it to OpenAI by modifying `LLM_MODELS[0]` to `LLM_MODELS[1]`. It is easy to extend the helper to accommodate others and send a [pull request](https://github.com/su-dataAI/data401-nlp/pulls) to me, if you use a different model that you'd like added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d16fa-2dc1-4892-b551-dce535ed7090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: anthropic/claude-sonnet-4-5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from data401_nlp.helpers.env import load_env\n",
    "from data401_nlp.helpers.llm import make_chat, LLM_MODELS\n",
    "\n",
    "load_env()\n",
    "DEFAULT_MODEL = LLM_MODELS[0] # Assumes Claude key... adjust if needed.\n",
    "print(\"Selected model:\", DEFAULT_MODEL)\n",
    "chat = make_chat(DEFAULT_MODEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f8fdd-8064-4a12-b66f-ea7692ca80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# You must explicitly opt in, if you want to use and run cells with external LLM calls\n",
    "ENABLE_LLM = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccefbf-3423-440e-93f6-a6c9ab679a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM status: disabled\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_status(chat_fn):\n",
    "    if not ENABLE_LLM:\n",
    "        return \"disabled\"\n",
    "    try:\n",
    "        chat_fn(\"ping\", max_tokens=1)\n",
    "        return \"ready\"\n",
    "    except Exception:\n",
    "        return \"misconfigured\"\n",
    "\n",
    "print(\"LLM status:\", llm_status(chat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a224c-9511-4b3a-9961-eb699653b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def make_and_test_chat(model_name):\n",
    "    if not ENABLE_LLM:\n",
    "        return None  # silent no-op\n",
    "\n",
    "    try:\n",
    "        chat = make_chat(model_name)\n",
    "        chat(\"ping\", max_tokens=1)\n",
    "        return chat\n",
    "    except Exception:\n",
    "        return None  # silent fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989b084-bf52-4bfb-84a9-e4530f6d8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_available():\n",
    "    return ENABLE_LLM and chat is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a584d8-658f-4cd1-9b17-8c76adca251b",
   "metadata": {},
   "source": [
    "The [listette library](https://lisette.answer.ai) wraps the litellm library and makes it possible for us to add models with API keys to this notebook. I've included it in helper functions behind the scenes.\n",
    "\n",
    "You don't need a subscription or API access, if you don't have it already. Use these notebooks as \"read-only\" for those sections. But if you do have a key, do use it!\n",
    "\n",
    "1. **Use Colab or Deepnote's Secrets feature** (recommended) - store keys in Colab's built-in secrets manager\n",
    "2. **Set environment variables** manually in your notebook\n",
    "3. **Use a `.env` file** in your local environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28e34d-b2a3-4001-bca3-9252f1ae2ea9",
   "metadata": {},
   "source": [
    "## Part A: Exploring the SpaCy Pipeline (Tokens, POS, NER, and Parse Trees)\n",
    "\n",
    "In this section, you will learn how spaCy transforms raw text into structured data. This is the foundation of all NLP work: taking unstructured text and adding labels, categories, and relationships that computers can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53153bb8",
   "metadata": {},
   "source": [
    "### The Doc Object: Your Container for Processed Text\n",
    "\n",
    "A **Doc** object is a smart container for data. When you give text to spaCy, it returns a Doc containing your original text plus all the analysis spaCy performs. Every word gets labeled, entities get identified, and grammatical relationships get mapped out—all stored in this single object.\n",
    "\n",
    "The **nlp** object is what does the work. When you call `nlp(text)`, spaCy runs your text through a series of processing steps called a **pipeline**. Each step adds different information: one step breaks text into words, another identifies parts of speech, another finds named entities, and so on.\n",
    "\n",
    "In practice, you create one Doc per document. An Amazon review would be one Doc. A news article would be one Doc. This organization helps when you are processing many documents at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86180d-9136-4fb0-a3b0-51adfb69b72e",
   "metadata": {},
   "source": [
    "The image below captures a high-level overview of the [spaCy API](https://spacy.io/api). Here you can see that text is processed by the **nlp pipeline** which runs the tokenizer. The Doc object itself has Token and Span objects. Let's look at tokens below. (We'll hold off on spans till we have a use for them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0e243-82ff-4b1d-ac63-d76e0d6cf08f",
   "metadata": {},
   "source": [
    "![](images/spacy-api.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f4ac0-a649-43ba-9d29-35ab029f6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dr. Sarah Chen joined Anthropic in San Francisco on January 15, 2024. She previously worked at Google Brain, where she led a team developing language models that could process over 100,000 tokens per second."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Sample text with multiple entities and interesting linguistic features\n",
    "sample_text = \"\"\"Dr. Sarah Chen joined Anthropic in San Francisco on January 15, 2024. She previously worked at Google Brain, where she led a team developing language models that could process over 100,000 tokens per second.\"\"\"\n",
    "\n",
    "# Process with spaCy\n",
    "# We're going to call nlp inside a function so that we don't rely on a global nlp object\n",
    "# for demos\n",
    "\n",
    "nlp = get_nlp()  \n",
    "doc = nlp(sample_text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c6516-d727-498d-947a-3a3bcfa62b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.',\n",
       " 'Sarah',\n",
       " 'Chen',\n",
       " 'joined',\n",
       " 'Anthropic',\n",
       " 'in',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'on',\n",
       " 'January',\n",
       " '15',\n",
       " ',',\n",
       " '2024',\n",
       " '.',\n",
       " 'She',\n",
       " 'previously',\n",
       " 'worked',\n",
       " 'at',\n",
       " 'Google',\n",
       " 'Brain',\n",
       " ',',\n",
       " 'where',\n",
       " 'she',\n",
       " 'led',\n",
       " 'a',\n",
       " 'team',\n",
       " 'developing',\n",
       " 'language',\n",
       " 'models',\n",
       " 'that',\n",
       " 'could',\n",
       " 'process',\n",
       " 'over',\n",
       " '100,000',\n",
       " 'tokens',\n",
       " 'per',\n",
       " 'second',\n",
       " '.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "[word.text for word in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9bce7c-228c-4c50-9b60-a62d88f62e29",
   "metadata": {},
   "source": [
    "Notice how spaCy split the text into individual pieces. \"Dr.\" stays together as one piece. \"San Francisco\" becomes two separate pieces. Punctuation marks like commas and periods each become their own piece. This process of splitting text into pieces is called **tokenization**, and each piece is called a **token**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e475881",
   "metadata": {},
   "source": [
    "### Tokens and Their Attributes\n",
    "\n",
    "A **token** is the basic unit of text in NLP. At its simplest, a token is just a piece of text that has been assigned a number (so computers can work with it). But in spaCy, tokens carry much more: part-of-speech labels, grammatical relationships, and other linguistic information.\n",
    "\n",
    "We will spend significant time on tokenization in the coming weeks because how you split text dramatically affects NLP performance. **Tokenization** has enormous impact on the performance on NLP tasks.\n",
    "\n",
    "For now, just understand that tokens are the building blocks we work with.\n",
    "\n",
    "Each token has many **attributes**—pieces of information attached to it. The [spaCy token documentation](https://spacy.io/api/token#attributes) lists all available attributes, or you can use Python's help function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999868cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# At this point, it can be helpful to look at API documentation. \n",
    "# This is one way to do it. Uncomment the line below line.\n",
    "\n",
    "# help(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beaaf6f-49b9-4299-8af9-73c2e5bcc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. compound Chen PROPN []\n",
      "Sarah compound Chen PROPN []\n",
      "Chen nsubj joined VERB [Dr., Sarah]\n",
      "joined ROOT joined VERB [Chen, Anthropic, in, on, .]\n",
      "Anthropic dobj joined VERB []\n",
      "in prep joined VERB [Francisco]\n",
      "San compound Francisco PROPN []\n",
      "Francisco pobj in ADP [San]\n",
      "on prep joined VERB [January]\n",
      "January pobj on ADP [15, ,, 2024]\n",
      "15 nummod January PROPN []\n",
      ", punct January PROPN []\n",
      "2024 nummod January PROPN []\n",
      ". punct joined VERB []\n",
      "She nsubj worked VERB []\n",
      "previously advmod worked VERB []\n",
      "worked ROOT worked VERB [She, previously, at, .]\n",
      "at prep worked VERB [Brain]\n",
      "Google compound Brain PROPN []\n",
      "Brain pobj at ADP [Google, ,, led]\n",
      ", punct Brain PROPN []\n",
      "where advmod led VERB []\n",
      "she nsubj led VERB []\n",
      "led relcl Brain PROPN [where, she, team]\n",
      "a det team NOUN []\n",
      "team dobj led VERB [a, developing]\n",
      "developing acl team NOUN [models]\n",
      "language compound models NOUN []\n",
      "models dobj developing VERB [language, process]\n",
      "that nsubj process VERB []\n",
      "could aux process VERB []\n",
      "process relcl models NOUN [that, could, tokens]\n",
      "over quantmod 100,000 NUM []\n",
      "100,000 nummod tokens NOUN [over]\n",
      "tokens dobj process VERB [100,000, per]\n",
      "per prep tokens NOUN [second]\n",
      "second pobj per ADP []\n",
      ". punct worked VERB []\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac3350",
   "metadata": {},
   "source": [
    "This output is dense! Do not worry about understanding every detail. The key insight is that each token carries information about its grammatical role (dep_), what word it relates to (head), and what words depend on it (children). We will explore these relationships more in the dependency parsing section.\n",
    "\n",
    "Let us view this information in a cleaner format using a pandas DataFrame, and add a few more commonly used attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8c20d-57bb-4147-8caa-915c166f96e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Token     Lemma     Lower Shape   POS Tag      Dep  Is_Stop  Is_Punct  Is_Digit  Is_Alpha\n",
      "      Dr.       Dr.       dr.   Xx. PROPN NNP compound    False     False     False     False\n",
      "    Sarah     Sarah     sarah Xxxxx PROPN NNP compound    False     False     False      True\n",
      "     Chen      Chen      chen  Xxxx PROPN NNP    nsubj    False     False     False      True\n",
      "   joined      join    joined  xxxx  VERB VBD     ROOT    False     False     False      True\n",
      "Anthropic Anthropic anthropic Xxxxx PROPN NNP     dobj    False     False     False      True\n",
      "       in        in        in    xx   ADP  IN     prep     True     False     False      True\n",
      "      San       San       san   Xxx PROPN NNP compound    False     False     False      True\n",
      "Francisco Francisco francisco Xxxxx PROPN NNP     pobj    False     False     False      True\n",
      "       on        on        on    xx   ADP  IN     prep     True     False     False      True\n",
      "  January   January   january Xxxxx PROPN NNP     pobj    False     False     False      True\n",
      "       15        15        15    dd   NUM  CD   nummod    False     False      True     False\n",
      "        ,         ,         ,     , PUNCT   ,    punct    False      True     False     False\n",
      "     2024      2024      2024  dddd   NUM  CD   nummod    False     False      True     False\n",
      "        .         .         .     . PUNCT   .    punct    False      True     False     False\n",
      "      She       she       she   Xxx  PRON PRP    nsubj     True     False     False      True\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "token_data = []\n",
    "for token in doc:\n",
    "    token_data.append({\n",
    "        \"Token\": token.text,\n",
    "        \"Lemma\": token.lemma_,\n",
    "        \"Lower\": token.lower_,\n",
    "        \"Shape\": token.shape_,\n",
    "        \"POS\": token.pos_,\n",
    "        \"Tag\": token.tag_,\n",
    "        \"Dep\": token.dep_,\n",
    "        \"Is_Stop\": token.is_stop,\n",
    "        \"Is_Punct\": token.is_punct,\n",
    "        \"Is_Digit\": token.is_digit,\n",
    "        \"Is_Alpha\": token.is_alpha\n",
    "    })\n",
    "\n",
    "token_df = pd.DataFrame(token_data)\n",
    "print(token_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd75a4-3745-45d4-bd16-6c2efa71fda9",
   "metadata": {},
   "source": [
    "Here are some observations from the first 15 lines of this token analysis:\n",
    "- Notice how 'joined' has lemma 'join' (verb normalization\n",
    "- 'Dr.' is tagged as NNP (proper noun) despite the period\"\n",
    "- Stop words like 'in', 'on', 'a' are marked True for Is_Stop\"\n",
    "\n",
    "For now, think of a token as a basic unit that you will focus on in NLP. **A token is simply a piece of text that can be represented as an integer.** The first stage in a spaCy pipeline is tokenization to break up text into the smaller bits that we process. As objects, they have the potential to carry a lot of information. We're going to briefly look at the sorts of information they carry in this lab. Don't worry about the details... this is an introduction to terms you will become more familiar with.\n",
    "\n",
    "Now let's look at each type of annotation! What are they, and what might we do with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8701e5ea-5891-402f-a313-fcfa92f0d86d",
   "metadata": {},
   "source": [
    "### Lemmas and Stopwords\n",
    "\n",
    "Two of the most useful token attributes are **lemmas** and **stopword flags**. Understanding these will help you see why preprocessing matters in NLP.\n",
    "\n",
    "**Lemmas** are the base or dictionary form of a word. For example:\n",
    "- \"joined\" → \"join\"\n",
    "- \"running\" → \"run\"  \n",
    "- \"better\" → \"good\"\n",
    "\n",
    "This normalization is useful because it lets you treat different forms of the same word as equivalent. For instance, if you're analyzing sentiment in reviews, you'd want \"loved,\" \"loving,\" and \"loves\" to all be recognized as the same concept.\n",
    "\n",
    "**Stop words** are common words that often don't carry much meaning on their own, like \"the,\" \"is,\" \"at,\" \"in,\" \"a.\" You can see in your token table that words like \"in\" and \"on\" are marked as stop words.\n",
    "\n",
    "They're often filtered out in tasks like:\n",
    "- Document classification (where \"the\" appears everywhere and doesn't help distinguish topics)\n",
    "- Keyword extraction (you want meaningful words, not \"and\" or \"of\")\n",
    "\n",
    "However, stop words ARE very important for some tasks—like machine translation or question answering, where \"not\" or \"who\" can completely change meaning!\n",
    "\n",
    "Looking at your sample text, can you spot why lemmatization might be helpful for analyzing this text? What if you wanted to count how many times people \"work\" at different companies across many documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4df8d-5c6e-440b-8cea-da28dd2d39e0",
   "metadata": {},
   "source": [
    "### Part-of-Speech Tagging\n",
    "\n",
    "**Part-of-speech (POS) tagging** assigns grammatical categories to each word. Is \"book\" a noun (I read a book) or a verb (I will book a flight)? POS tags help answer this question based on context.\n",
    "\n",
    "SpaCy uses two types of POS tags:\n",
    "\n",
    "1. **Coarse-grained tags** (`token.pos_`) - Universal POS tags from the Universal Dependencies project. These are standardized across languages (like NOUN, VERB, ADJ, etc.)\n",
    "\n",
    "2. **Fine-grained tags** (`token.tag_`) - Language-specific tags. For English, these are Penn Treebank tags (like NNP, VBD, JJ, etc.)\n",
    "\n",
    "The best references are:\n",
    "\n",
    "- [**Universal POS tags**](https://universaldependencies.org/u/pos/)\n",
    "- [**Penn Treebank tags**](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
    "- [**SpaCy's own documentation**](https://spacy.io/api/annotation#pos-tagging)\n",
    "\n",
    "You can also see what tags are available in your loaded model by checking `nlp.get_pipe(\"tagger\").labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee098b79-398e-4c23-9ef5-96f539623207",
   "metadata": {},
   "source": [
    "Here's a quick reference for the tags appearing in our token data above:\n",
    "\n",
    "**POS Tags (Universal):**\n",
    "- `PROPN` - Proper noun (Sarah, Chen, Anthropic, San Francisco)\n",
    "- `VERB` - Verb (joined)\n",
    "- `ADP` - Adposition/preposition (in, on)\n",
    "- `NUM` - Number (15, 2024)\n",
    "- `PUNCT` - Punctuation (., ,)\n",
    "- `PRON` - Pronoun (She)\n",
    "\n",
    "**Penn Treebank Tags (detailed):**\n",
    "- `NNP` - Proper noun, singular (Dr., Sarah, Chen)\n",
    "- `VBD` - Verb, past tense (joined)\n",
    "- `IN` - Preposition or subordinating conjunction (in, on)\n",
    "- `CD` - Cardinal number (15, 2024)\n",
    "- `PRP` - Personal pronoun (She)\n",
    "\n",
    "**Dependency Labels:**\n",
    "- `nsubj` - Nominal subject (Chen is the subject of \"joined\")\n",
    "- `dobj` - Direct object (Anthropic is what was joined)\n",
    "- `compound` - Compound modifier (Dr. + Sarah + Chen)\n",
    "- `prep` - Prepositional modifier (in, on)\n",
    "- `pobj` - Object of preposition (Francisco, January)\n",
    "- `nummod` - Numeric modifier (15 modifies January)\n",
    "- `ROOT` - Root of the sentence (joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286728b2",
   "metadata": {},
   "source": [
    "SpaCy's POS tagger uses a neural network model trained on annotated text data. Here's how it works:\n",
    "\n",
    "**Training:** The model learns patterns from large corpora (like OntoNotes for English) where words are already tagged with their parts of speech. It learns contextual clues—for example, that a word after \"the\" is likely a noun.\n",
    "\n",
    "**Prediction:** When you process text with `nlp(text)`, the tagger looks at each token in context (surrounding words, word shape, prefixes/suffixes) and predicts the most likely POS tag using the trained neural network.\n",
    "\n",
    "**Architecture:** Modern SpaCy models (v3+) use transformer-based or CNN-based architectures. The small model you're using (`en_core_web_sm`) uses a more compact architecture for speed.\n",
    "\n",
    "The tagger is one component in the processing pipeline. You can see your pipeline components with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "nlp = get_nlp()\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c12fc9-fde5-4a31-bb94-a54ba4ae3997",
   "metadata": {},
   "source": [
    "This shows the six processing steps that run when you call `nlp(text)`:\n",
    "\n",
    "1. **tok2vec** - Converts tokens into numerical vectors (we will cover this later)\n",
    "2. **tagger** - Assigns POS tags\n",
    "3. **parser** - Analyzes grammatical structure (dependency parsing)\n",
    "4. **attribute_ruler** - Applies rule-based attribute assignments\n",
    "5. **lemmatizer** - Computes lemmas (base forms of words)\n",
    "6. **ner** - Named Entity Recognition\n",
    "\n",
    "Notice that tok2vec comes first. It creates vector representations that other components (like the tagger and parser) use as input. This shared representation is one of spaCy's clever design features—multiple components benefit from the same underlying analysis.\n",
    "\n",
    "As you will inuit over time, even if we didn't use spaCy, we would need an nlp pipeline. In general terms, an NLP pipeline is a sequence of processing steps that transform raw text into increasingly structured representations, where each step adds or refines information that later steps can use.\n",
    "\n",
    "Conceptually:\n",
    "\n",
    "- Input starts as unstructured text\n",
    "- Each component performs a specific analysis (e.g., tokenization, tagging, parsing)\n",
    "- The output is a layered annotation of the same text, not a replacement\n",
    "- Later components can depend on the results of earlier ones\n",
    "\n",
    "The key idea is modularity: complex language understanding is built by composing simple, specialized stages rather than solving everything at once. As we will see later, we can add new components to this pipeline... which makes it possible for us to create hybrid NLP solutions using traditional ML with representation and generative models!\n",
    "\n",
    "Below is a visual depiction of a spaCy pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add525cb-38c2-4745-b5ca-d551ba4a0119",
   "metadata": {},
   "source": [
    "![](images/spacy-pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73be74-1154-4285-a2c2-8da671681711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c367a9-5025-4ffb-9149-c12f67c6448e",
   "metadata": {},
   "source": [
    "We've looked a bit at tokenization, lemmas, and part of speech - let's move on to NER. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b0c2f-2e0b-497e-b441-f2264198baff",
   "metadata": {},
   "source": [
    "### Named Entities\n",
    "\n",
    "**Named Entity Recognition (NER)** identifies and classifies real-world objects in text: people, organizations, locations, dates, and more. This is one of the most practically useful NLP tasks—imagine automatically extracting all company names from thousands of news articles.\n",
    "\n",
    "According to the [SpaCy model reference](https://spacy.io/models), the NER component also uses vectors as input. It is configurable to use its own Tok2Vec model, though by default, uses the pipeline Tok2Vec model. SpaCy is extremely configurable and you can turn components on and off, as long as you are paying attention to dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d02db",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "NER uses all sorts of features as context. For example, it uses punctuation to signal clause boundaries, abbreviations, etc. It also uses lexical features and contextual token features such as neighboring tokens, subword patterns, and other contextual clues. It does not rely on POS tags or dependency parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sarah Chen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " joined Anthropic in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    January 15, 2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". She previously worked at \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ", where she led a team developing language models that could process over \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    100,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " tokens per \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Visualize entities (Colab-friendly)\n",
    "from spacy import displacy\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Render entities\n",
    "html = displacy.render(doc, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae534b",
   "metadata": {},
   "source": [
    "POS tags are useful building blocks for many NLP tasks:\n",
    "\n",
    "**1. Information Extraction** - You can filter for specific patterns. For example, finding all noun phrases (sequences of adjectives + nouns) to extract key concepts, or finding verb-object pairs to understand actions.\n",
    "\n",
    "**2. Text Preprocessing** - You might keep only nouns and verbs for topic modeling, or remove everything except proper nouns to find names and places.\n",
    "\n",
    "**3. Disambiguation** - The word \"book\" could be a noun (read a book) or verb (book a flight). POS tags help distinguish meaning.\n",
    "\n",
    "**4. Feature Engineering** - For classification tasks, POS tag distributions can be features. Academic writing has different POS patterns than casual speech.\n",
    "\n",
    "Looking at your `doc`, what if you wanted to extract just the organizations mentioned? You could filter for proper nouns (`PROPN`), but notice \"Google Brain\" is tagged as `FAC` (facility) in the NER output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e74728-d6e6-4519-a1ff-6c151b0ef87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buildings, airports, highways, bridges, etc.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# You can use spacy.explain categories that are unfamiliar.\n",
    "\n",
    "spacy.explain(\"FAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c35694",
   "metadata": {},
   "source": [
    "Let's play around with 'Google Brain' to look at some other sentences. We want to experiment and see under what sentence contexts it is tagged correctly as an ORG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f33a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">She joined \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " as an engineer</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "doc1 = nlp(\"She joined Google Brain as an engineer\")\n",
    "\n",
    "# Render entities\n",
    "html = displacy.render(doc1, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f77fb-463f-48b5-8329-6feeb3e9e52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is a research organization</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "doc2 = nlp(\"Google Brain is a research organization\")\n",
    "\n",
    "# Render entities\n",
    "html = displacy.render(doc2, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a309a-9134-4efa-81c8-94fcbfc165ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">She worked at the company \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "doc3 = nlp(\"She worked at the company Google Brain\")\n",
    "\n",
    "# Render entities\n",
    "html = displacy.render(doc3, style=\"ent\", jupyter=False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf38b31-6b7b-4b30-8d4d-59ea8c8bd1ee",
   "metadata": {},
   "source": [
    "### Part A Summary\n",
    "\n",
    "In this section, you learned:\n",
    "\n",
    "- **Doc and Token objects** are spaCy's fundamental building blocks. A Doc holds processed text; Tokens are individual pieces with attached information.\n",
    "- **Tokenization** splits text into pieces. How this happens affects everything downstream.\n",
    "- **Token attributes** include lemmas (base forms), POS tags (grammatical categories), and stopword flags.\n",
    "- **Named Entity Recognition** identifies real-world objects but depends heavily on context and sometimes makes mistakes.\n",
    "- **The spaCy pipeline** runs multiple processing steps in sequence, with each step adding information to the Doc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90384d6e",
   "metadata": {},
   "source": [
    "## Part B: Dependency Parsing\n",
    "\n",
    "So far, we have looked at individual tokens in isolation. But language is about relationships—subjects perform actions on objects, adjectives modify nouns, prepositions connect phrases. **Dependency parsing** captures these relationships by connecting each word to the word it depends on.\n",
    "\n",
    "You have been given some [basic study material on a theory of language structure based on \"X-bar\" theory](https://socialsci.libretexts.org/Courses/Canada_College/ENGL_LING_200%3A_Introduction_to_Linguistics/05%3A_Phrases-_Syntax/5.03%3A_Phrase_Structure_Rules_X-Bar_Theory_and_Constituency), which is the theory behind **constituent parsing**. This kind of parsing has a lot of positives. It can tell you about where noun and verb phrases begin and end because it has rich, hierarchical structure. You can plugin a constituent parser into spaCy, but it's not the default.\n",
    "\n",
    "SpaCy chose to implement dependency parsing because it's faster (linear time), low memory, robust token-centric, and works across many languages (i.e. cross-lingual). Like constituent parsing, it's also usedful for downstream tasks. Your linguistics book doesn't talk about dependency parsing, so we'll draw from Jurafsky and Martin and touch on it in this notebook.\n",
    "\n",
    "Note, it's not important to know the details here. Focus on why SpaCy has a dependency parser out of the box -- why it might be useful -- and that it works at the token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"84ab3f580a844df5a9f54dc98b32ef50-0\" class=\"displacy\" width=\"1130\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dr.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Sarah</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Chen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">joined</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Anthropic</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">San</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">Francisco</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">January</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">15,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">2024.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 225.0,47.0 225.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,139.0 L408.0,127.0 392.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-4\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,139.0 L503.0,127.0 487.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-6\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,139.0 L683.0,127.0 667.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-7\" stroke-width=\"2px\" d=\"M340,137.0 C340,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-8\" stroke-width=\"2px\" d=\"M790,137.0 C790,92.0 850.0,92.0 850.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M850.0,139.0 L858.0,127.0 842.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-9\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M940.0,139.0 L948.0,127.0 932.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-0-10\" stroke-width=\"2px\" d=\"M880,137.0 C880,47.0 1035.0,47.0 1035.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1035.0,139.0 L1043.0,127.0 1027.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"84ab3f580a844df5a9f54dc98b32ef50-1\" class=\"displacy\" width=\"2030\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">previously</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">worked</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Google</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Brain,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">where</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">she</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">led</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">team</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">developing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">models</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">could</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">process</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1580\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1580\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1670\">100,000</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1670\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1760\">tokens</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1760\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">per</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1940\">second.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1940\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 225.0,47.0 225.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310.0,139.0 L318.0,127.0 302.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-4\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,139.0 L503.0,127.0 487.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,47.0 765.0,47.0 765.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-6\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,139.0 L692,127.0 708,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-7\" stroke-width=\"2px\" d=\"M520,137.0 C520,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-10\" stroke-width=\"2px\" d=\"M970,137.0 C970,92.0 1030.0,92.0 1030.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030.0,139.0 L1038.0,127.0 1022.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-11\" stroke-width=\"2px\" d=\"M1150,137.0 C1150,92.0 1210.0,92.0 1210.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,139.0 L1142,127.0 1158,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-12\" stroke-width=\"2px\" d=\"M1060,137.0 C1060,47.0 1215.0,47.0 1215.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1215.0,139.0 L1223.0,127.0 1207.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-13\" stroke-width=\"2px\" d=\"M1330,137.0 C1330,47.0 1485.0,47.0 1485.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1330,139.0 L1322,127.0 1338,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-14\" stroke-width=\"2px\" d=\"M1420,137.0 C1420,92.0 1480.0,92.0 1480.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1420,139.0 L1412,127.0 1428,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-15\" stroke-width=\"2px\" d=\"M1240,137.0 C1240,2.0 1490.0,2.0 1490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1490.0,139.0 L1498.0,127.0 1482.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-16\" stroke-width=\"2px\" d=\"M1600,137.0 C1600,92.0 1660.0,92.0 1660.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600,139.0 L1592,127.0 1608,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-17\" stroke-width=\"2px\" d=\"M1690,137.0 C1690,92.0 1750.0,92.0 1750.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1690,139.0 L1682,127.0 1698,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-18\" stroke-width=\"2px\" d=\"M1510,137.0 C1510,47.0 1755.0,47.0 1755.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1755.0,139.0 L1763.0,127.0 1747.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-19\" stroke-width=\"2px\" d=\"M1780,137.0 C1780,92.0 1840.0,92.0 1840.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1840.0,139.0 L1848.0,127.0 1832.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-84ab3f580a844df5a9f54dc98b32ef50-1-20\" stroke-width=\"2px\" d=\"M1870,137.0 C1870,92.0 1930.0,92.0 1930.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-84ab3f580a844df5a9f54dc98b32ef50-1-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1930.0,139.0 L1938.0,127.0 1922.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Visualize entities (Colab-friendly)\n",
    "from spacy import displacy\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "options = {\n",
    "    \"distance\": 90,   # arc length\n",
    "    \"compact\": False,\n",
    "    \"bg\": \"#ffffff\",\n",
    "    \"color\": \"#000000\",\n",
    "    \"font\": \"Arial\"\n",
    "}\n",
    "\n",
    "# Render entities. We need to break out by sentence since this will take a lot of horizontal space, otherwise.\n",
    "html = displacy.render(\n",
    "    list(doc.sents),   # important: avoids cramped multi-sentence trees\n",
    "    style=\"dep\",\n",
    "    options=options,\n",
    "    jupyter=False\n",
    ")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdffbcc1-23c9-4e41-8d65-77d051711839",
   "metadata": {},
   "source": [
    "Looking at the first sentence's dependency chart, here's how to read it:\n",
    "\n",
    "**The arrows show relationships between words**, where:\n",
    "- The arrow points FROM a dependent word TO its head (the word it modifies or relates to)\n",
    "- The label on the arrow tells you the type of relationship\n",
    "\n",
    "**Example from \"Dr. Sarah Chen joined Anthropic...\":**\n",
    "\n",
    "- \"Dr.\" and \"Sarah\" both have arrows pointing to \"Chen\" with label `compound` - they're parts of the compound name\n",
    "- \"Chen\" has an arrow to \"joined\" labeled `nsubj` (nominal subject) - Chen is who performed the action\n",
    "- \"Anthropic\" points to \"joined\" with `dobj` (direct object) - Anthropic is what was joined\n",
    "- \"in\" points to \"joined\" with `prep` (prepositional modifier)\n",
    "- \"Francisco\" points to \"in\" with `pobj` (object of preposition)\n",
    "\n",
    "**The ROOT** is \"joined\" - it's the main verb with no arrow pointing away from it.\n",
    "\n",
    "Try tracing one relationship yourself. Can you explain what the arrow from \"San\" to \"Francisco\" means?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90435b80",
   "metadata": {},
   "source": [
    "This is what a dependency parse looks like compared to a syntax tree constituent analysis and is from [Chapter 19 of Jurafsky & Martin](https://web.stanford.edu/~jurafsky/slp3/19.pdf). Arguments to relations are heads and dependents. Heads are the organizing word and dependents are like modifiers. These are labeled with grammatical functions like \"Nominal subject\" or \"Direct object.\" \n",
    "\n",
    "For example, (**NSUBJ**) **United** canceled the (**DOBJ**) **flight**.\n",
    "\n",
    "The example below shows what a dependency parse sentence diagram looks like. Note the direction of the arrows. \"flight\" and \"me\" are connected to the root \"Book.\" They are dependent on \"Book.\"\n",
    "\n",
    "Similarly, \"morning\" is dependent on \"flight.\" And \"the\" is dependent on \"morning flight.\" In fact, every structure is dependent on another -- starting with the root. \n",
    "\n",
    "![](images/dependency-parse-diagram.png)\n",
    "\n",
    "The Universal Dependencies project is a community effort to align a grammar across more than 100 language with an inventory of [37 dependency relations](https://universaldependencies.org/u/dep/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e2c42-523f-4d7d-a7b6-b7e1525a5010",
   "metadata": {},
   "source": [
    "Notably, dependency parsing answers questions like:\n",
    "- who did what to whom?\n",
    "- what modifies what?\n",
    "- what organizations below to which phrase?\n",
    "\n",
    "Unlike consituency parsers which use the **sentence** as the root of the tree, dependency grammars place the main **verb** as the head of a clause (sentence embedded in a larger sentence). \n",
    "\n",
    "So in our clause \"she previously **worked** at Google Brain\", 'worked' is the root that everything depends on.\n",
    "\n",
    "- **she** is \"who did it\"\n",
    "- **previously** is \"when\"\n",
    "- at **Google Brain** is \"where\" (oblique argument)\n",
    "\n",
    "SpaCy's dependency parser works differently from POS tagging. Instead of assigning labels to individual tokens, it predicts **relationships between tokens** (which token is the head of which other token, and what type of dependency).\n",
    "\n",
    "The parser uses a **transition-based approach**:\n",
    "- It processes the sentence incrementally, making a series of decisions (transitions)\n",
    "- At each step, it can perform actions like \"attach this word to that word with label X\"\n",
    "- It builds up the parse tree through these sequential decisions\n",
    "\n",
    "Like NER, it can use beam search to explore multiple parsing paths and find the most probable complete parse tree.\n",
    "\n",
    "The key difference: POS assigns one label per token independently, while dependency parsing creates a **structure** where every token (except the root) must connect to exactly one head token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02cf656",
   "metadata": {},
   "source": [
    "This diagram is from Jurafsky & Martin Chapter 19.2 and is an illustration of **transition-based** parsing. It demonstrates **shift-reduce parsing** where we have a stack on which we build the parse, a buffer of tokens to parse, and a parser which takes actions on the prase via a predictor called an oracle. It can explore multiple paths, when doing so - though, that will slow this process down.\n",
    "\n",
    "![](images/dependency-parse.png)\n",
    "\n",
    "The parser walks through the sentence left-to-right, successively shifting items\n",
    "from the buffer onto the stack. At each time point we examine the top two elements\n",
    "on the stack, and the oracle makes a decision about what transition to apply to build the parse. \n",
    "\n",
    "These are the tree transition operations on the top two elements of the stack:\n",
    "\n",
    "1. **LEFTARC**: Assert a head-dependent relation between the word at the top of\n",
    "the stack and the second word; remove the second word from the stack.\n",
    "\n",
    "2. **RIGHTARC**: Assert a head-dependent relation between the second word on\n",
    "the stack and the word at the top; remove the top word from the stack.\n",
    "\n",
    "3. **SHIFT**: Remove the word from the front of the input buffer and push it onto\n",
    "the stack.\n",
    "\n",
    "This is a greedy algorithm - the oracle provides a single choice at each step and the parser proceeds with that choice and no other options are explored. There is no backtracking and a single parse is returned in the end.\n",
    "\n",
    "Think of it this way, the Oracle is a trained supervised algorithm that makes a decision over two tokens until there are no more rules to apply. It decides if it will shift a word onto the stack, or if it will assert a relationship (left or right) between two tokens. Recall, **every token must connect to exactly one head token.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4e7c5",
   "metadata": {},
   "source": [
    "Below, we will tell SpaCy to give us the top three parses. Generally, we want a beam_width of 1 (one parse), because this is much faster.\n",
    "\n",
    "A \"beam\" is a set of top-scoring partial parse trees or hypotheses kept by a beam search algorithm. Beam search maintains a \"beam width\" of several promising candidates, expanding them and pruning less likely ones at each stage to avoid exponential complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a36b27-ca8e-48af-b909-42596450b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "nlp = get_nlp()\n",
    "doc = nlp(sample_text)\n",
    "parser = nlp.get_pipe(\"parser\")\n",
    "beams = parser.beam_parse([doc], beam_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a0e63-23ef-412d-b237-6a1893c1425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alternatives: 3\n",
      "Probabilities: [0.7982435893632595, 0.17826448047596988, 0.023491930160770638]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "head_scores, label_scores = parser.scored_parses(beams)\n",
    "print(f\"Number of alternatives: {len(beams[0].histories)}\")\n",
    "print(f\"Probabilities: {beams[0].probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed3213-2c50-4b0a-acc1-56729180bea5",
   "metadata": {},
   "source": [
    "The `beams[0].probs` shows the probabilities for the top 3 complete dependency parse trees:\n",
    "\n",
    "- **79.8%** - The parse tree SpaCy chose (most probable)\n",
    "- **17.8%** - Second-best alternative parse\n",
    "- **2.3%** - Third-best alternative\n",
    "\n",
    "The `head_scores` and `label_scores` from `scored_parses()` give you more detailed information about individual attachment decisions and dependency labels for each token in each parse.\n",
    "\n",
    "Want to look at what's actually different between these three parse trees? We could decode the histories to see where they disagree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7caa0b3-3678-4e33-868c-fffd4e3ed4b1",
   "metadata": {},
   "source": [
    "### Part B Summary\n",
    "\n",
    "In this section, you learned:\n",
    "\n",
    "- **Dependency parsing** captures grammatical relationships between words, showing who did what to whom.\n",
    "- **Each token connects to exactly one head**, creating a tree structure with the main verb as root.\n",
    "- SpaCy uses a **transition-based parser** that makes sequential decisions to build the parse.\n",
    "- **Beam search** lets us see alternative parses and their probabilities, revealing where the parser is uncertain.\n",
    "- This approach is **fast and works across languages**, which is why spaCy chose it over constituency parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793e14b-e7af-4a28-b40f-ca911006212d",
   "metadata": {},
   "source": [
    "## Part C: Language Modeling as Probability Distributions\n",
    "\n",
    "Now we shift from analyzing existing text to understanding how computers predict text. This is the foundation of modern NLP: **language models** assign *probabilities to sequences of words*. When you use autocomplete on your phone or ChatGPT generates a response, language models are predicting what words should come next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b6d68",
   "metadata": {},
   "source": [
    "### Starting Simple: Bigram Models\n",
    "\n",
    "The simplest language model considers only the immediately preceding word. Given \"the quick brown,\" what word is likely to follow? A **bigram model** looks at word pairs and counts how often each pair appeared in training data.\n",
    "\n",
    "The first thing we are going to do is look at a simple bigram model. A bigram is a pair of consecutive units. These models perform surprisingly well! You can also build trigram models -- three consecutive units, and four-gram models. All are simply types of 'n-gram' models.\n",
    "\n",
    "So, for example, \n",
    "\n",
    "- unigram - 'the'\n",
    "- bigram - 'the man'\n",
    "- trigram - 'the man with'\n",
    "- 4-gram - 'the man with the'\n",
    "\n",
    "The larger the chunk, the more context. We'll look at n-grams more in depth later this semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26024430-2d6a-43ff-a838-36a965b063fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "I saw the man with the telescope yesterday.\n",
    "I saw the bird with my binoculars.\n",
    "The man with the hat waved at me.\n",
    "I watched the show with great interest.\n",
    "The telescope with the red lens was expensive.\n",
    "I observed the stars with the telescope.\n",
    "The bird with colorful feathers flew away.\n",
    "She saw him with her own eyes.\n",
    "The man with the briefcase left early.\n",
    "I spotted the deer with the binoculars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "class BigramLM:\n",
    "    \"\"\"A simple bigram language model.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.bigram_counts = defaultdict(Counter)\n",
    "        self.unigram_counts = Counter()\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"Train on a corpus of text.\"\"\"\n",
    "        # Simple tokenization\n",
    "        tokens = text.lower().replace('.', ' .').replace(',', ' ,').split()\n",
    "        \n",
    "        # Count unigrams\n",
    "        self.unigram_counts.update(tokens)\n",
    "        \n",
    "        # Count bigrams\n",
    "        for i in range(len(tokens) - 1):\n",
    "            self.bigram_counts[tokens[i]][tokens[i+1]] += 1\n",
    "            \n",
    "        print(f\"Trained on {len(tokens)} tokens, {len(self.bigram_counts)} unique contexts\")\n",
    "    \n",
    "    def get_next_word_probs(self, context_word, top_k=5):\n",
    "        \"\"\"Get probability distribution over next words given context.\"\"\"\n",
    "        context_word = context_word.lower()\n",
    "        if context_word not in self.bigram_counts:\n",
    "            return []\n",
    "        \n",
    "        counts = self.bigram_counts[context_word]\n",
    "        total = sum(counts.values())\n",
    "        \n",
    "        probs = [(word, count/total) for word, count in counts.most_common(top_k)]\n",
    "        return probs\n",
    "    \n",
    "    def score_sequence(self, words):\n",
    "        \"\"\"Score a sequence of words (log probability).\"\"\"\n",
    "        import math\n",
    "        words = [w.lower() for w in words]\n",
    "        log_prob = 0\n",
    "        for i in range(len(words) - 1):\n",
    "            context = words[i]\n",
    "            next_word = words[i+1]\n",
    "            if context in self.bigram_counts and next_word in self.bigram_counts[context]:\n",
    "                prob = self.bigram_counts[context][next_word] / sum(self.bigram_counts[context].values())\n",
    "                log_prob += math.log(prob)\n",
    "            else:\n",
    "                log_prob += math.log(1e-6)  # Smoothing for unseen\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f46678-abf8-4860-9dd0-720c2aec0248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on 83 tokens, 39 unique contexts\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Train our bigram model\n",
    "bigram_lm = BigramLM()\n",
    "bigram_lm.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b14905-6f2d-408a-b1b9-d5a7c62c6987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 BIGRAM MODEL: Next-word probabilities\n",
      "==================================================\n",
      "\n",
      "After 'the':\n",
      "   man             0.200 ████\n",
      "   telescope       0.200 ████\n",
      "   bird            0.133 ██\n",
      "   hat             0.067 █\n",
      "   show            0.067 █\n",
      "\n",
      "After 'with':\n",
      "   the             0.600 ████████████\n",
      "   my              0.100 ██\n",
      "   great           0.100 ██\n",
      "   colorful        0.100 ██\n",
      "   her             0.100 ██\n",
      "\n",
      "After 'saw':\n",
      "   the             0.667 █████████████\n",
      "   him             0.333 ██████\n",
      "\n",
      "After 'man':\n",
      "   with            1.000 ████████████████████\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Explore next-word probabilities from our bigram model\n",
    "print(\"\\n📊 BIGRAM MODEL: Next-word probabilities\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_contexts = [\"the\", \"with\", \"saw\", \"man\"]\n",
    "\n",
    "for context in test_contexts:\n",
    "    probs = bigram_lm.get_next_word_probs(context, top_k=5)\n",
    "    print(f\"\\nAfter '{context}':\")\n",
    "    for word, prob in probs:\n",
    "        print(f\"   {word:15} {prob:.3f} {'█' * int(prob * 20)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f069bd",
   "metadata": {},
   "source": [
    "Expected Observation:\n",
    "\n",
    "- Limited vocabulary (only words seen in training)\n",
    "- Only looks at ONE previous word (no long-range context)\n",
    "- Sparse: many word pairs never seen → zero probability\n",
    "\n",
    "Play around with different corpora to explore.\n",
    "\n",
    "Now let's see how a neural model handles the tax of next-token probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505760d-3615-41e1-a662-d6904b2f2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local language model (distilgpt2)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Local model loaded!\n",
      "\n",
      "✅ Unified LM interface ready!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# ============================================================\n",
    "# UNIFIED INTERFACE FOR NEXT-TOKEN PROBABILITIES\n",
    "# ============================================================\n",
    "# This has been tested with Claude and ChatGPT\n",
    "# It's designed so we can later swap in a remote model \n",
    "# without changing downstream experiments.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load local model (distilgpt2 - small and fast)\n",
    "print(\"Loading local language model (distilgpt2)...\")\n",
    "local_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "local_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "local_model.eval()\n",
    "print(\"✅ Local model loaded!\")\n",
    "\n",
    "def get_next_token_distribution_local(prompt, k=10):\n",
    "    \"\"\"\n",
    "    Get top-k next token probabilities using local model.\n",
    "    Returns: list of (token_string, probability) tuples\n",
    "    \"\"\"\n",
    "    inputs = local_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = local_model(**inputs)\n",
    "        # Get logits for the last position\n",
    "        next_token_logits = outputs.logits[0, -1, :]\n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        # Get top-k\n",
    "        top_probs, top_indices = torch.topk(probs, k)\n",
    "        \n",
    "    results = []\n",
    "    for prob, idx in zip(top_probs.tolist(), top_indices.tolist()):\n",
    "        token = local_tokenizer.decode([idx])\n",
    "        results.append((token, prob))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def score_continuation_local(prompt, continuation):\n",
    "    \"\"\"\n",
    "    Score a continuation given a prompt using teacher forcing.\n",
    "    Returns: (sum_log_prob, avg_log_prob, num_tokens)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    full_text = prompt + continuation\n",
    "    prompt_ids = local_tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    full_ids = local_tokenizer(full_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    \n",
    "    prompt_len = prompt_ids.shape[1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = local_model(full_ids)\n",
    "        logits = outputs.logits[0]  # [seq_len, vocab_size]\n",
    "        \n",
    "    # Score each token in the continuation\n",
    "    log_probs = []\n",
    "    for i in range(prompt_len - 1, full_ids.shape[1] - 1):\n",
    "        next_token_id = full_ids[0, i + 1].item()\n",
    "        token_logits = logits[i]\n",
    "        token_probs = F.softmax(token_logits, dim=-1)\n",
    "        log_prob = math.log(token_probs[next_token_id].item() + 1e-10)\n",
    "        log_probs.append(log_prob)\n",
    "    \n",
    "    sum_log_prob = sum(log_probs)\n",
    "    avg_log_prob = sum_log_prob / len(log_probs) if log_probs else 0\n",
    "    \n",
    "    return sum_log_prob, avg_log_prob, len(log_probs)\n",
    "\n",
    "# Create unified interface\n",
    "def get_next_token_distribution(prompt, k=10, provider=\"auto\"):\n",
    "    \"\"\"\n",
    "    Unified interface for next-token distributions.\n",
    "\n",
    "    NOTE:\n",
    "    - Currently defaults to a local model (distilgpt2)\n",
    "    - Designed so experiments below do not depend on model source\n",
    "    \"\"\"\n",
    "    if provider == \"auto\":\n",
    "        provider = \"local\"  # Local is most reliable for logprobs\n",
    "    \n",
    "    if provider == \"local\":\n",
    "        return get_next_token_distribution_local(prompt, k)\n",
    "    else:\n",
    "        # Fallback to local\n",
    "        return get_next_token_distribution_local(prompt, k)\n",
    "\n",
    "def score_continuation(prompt, continuation, provider=\"auto\"):\n",
    "    \"\"\"Score a continuation using best available provider.\"\"\"\n",
    "    if provider == \"auto\":\n",
    "        provider = \"local\"\n",
    "    \n",
    "    if provider == \"local\":\n",
    "        return score_continuation_local(prompt, continuation)\n",
    "    else:\n",
    "        return score_continuation_local(prompt, continuation)\n",
    "\n",
    "print(\"\\n✅ Unified LM interface ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550bf5c-cbb6-45b1-b08e-7c985143482a",
   "metadata": {},
   "source": [
    "In get_next_token_distribution_local() above:\n",
    "\n",
    "- A local causal language model (distilgpt2) is loaded using [Hugging Face](https://huggingface.co).\n",
    "- Given a text prompt, the model produces logits for the next token only.\n",
    "- Logits are converted to a probability distribution via softmax.\n",
    "- The function returns the top-k most likely next tokens with their probabilities.\n",
    "\n",
    "In score_continuation_local() above, we want to see how the score changes when we provide all the *correct* tokens before (a technique called **teacher forcing**).\n",
    "\n",
    "- The prompt and continuation are concatenated into one sequence.\n",
    "- The prompt length is recorded so we know which tokens belong to the continuation.\n",
    "- The full sequence is passed through the model once to obtain logits at every position.\n",
    "- For each continuation token, the model’s probability of the actual next token is read from the logits.\n",
    "- These probabilities are converted to log probabilities and summed.\n",
    "\n",
    "Contrast with bigrams: unlike the bigram model, which conditions only on the immediately preceding word and assigns zero probability to unseen pairs, **the neural model conditions on the entire prior context and assigns graded probabilities even to novel continuations.**\n",
    "\n",
    "Later in the course we'll talk about language models and how **log probabilities** and **log liklihood**  (the scoring function over data) works. These concepts are foundational to machine-learning based AI. Fortunately, at the core, these concept are not difficult for non-statisticians!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49b204-3ace-41e2-bcfc-c8844e4762be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Testing next-token distribution...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'The quick brown fox'\n",
      "\n",
      "Top 10 next tokens:\n",
      "   'es        ' : 0.2303 ███████████\n",
      "   ' is       ' : 0.0549 ██\n",
      "   ',         ' : 0.0270 █\n",
      "   '.         ' : 0.0242 █\n",
      "   ' and      ' : 0.0191 \n",
      "   ' has      ' : 0.0187 \n",
      "   ' that     ' : 0.0160 \n",
      "   ' was      ' : 0.0151 \n",
      "   'e         ' : 0.0148 \n",
      "   'y         ' : 0.0104 \n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Test the interface\n",
    "print(\"\\n🧪 Testing next-token distribution...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_prompt = \"The quick brown fox\"\n",
    "results = get_next_token_distribution(test_prompt, k=10)\n",
    "\n",
    "print(f\"Prompt: '{test_prompt}'\")\n",
    "print(f\"\\nTop 10 next tokens:\")\n",
    "for token, prob in results:\n",
    "    bar = '█' * int(prob * 50)\n",
    "    print(f\"   '{token:10}' : {prob:.4f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24045c",
   "metadata": {},
   "source": [
    "Why don't we see 'jump' as in thefamous phrase \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "**1. Training data bias** - DistilGPT2 was trained on a huge corpus of internet text. While \"The quick brown fox jumps over the lazy dog\" is a famous pangram (contains all letters), it's actually quite rare compared to how often the model saw other phrases starting with \"The quick brown fox...\"\n",
    "\n",
    "**2. Token probabilities are spread out** - Notice we're only showing the top 10. \"jumped\" might be ranked 50th or 100th with a very small probability.\n",
    "\n",
    "**3. Tokenization** - \"jumped\" might be split into multiple tokens (like \"jump\" + \"ed\"), making it even less likely to appear as a single next token.\n",
    "\n",
    "Want to check if \"jumped\" appears further down the list? We could increase `k` to see more possibilities, or we could score the specific continuation \"jumped over the lazy dog\" to see what probability the model assigns to it.\n",
    "\n",
    "Notice that we can give the entire context to **DistilGPT2**.\n",
    "\n",
    "- It's considering the entire context \"The quick brown fox\"\n",
    "- It uses sub-tokens, and likely has a lot of \"fox\" followed by \"es\" in training data\n",
    "- It can handle words it's never seen in an exact bigram pair\n",
    "0 It's been trained on massive amounts of text, and has much richer knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07408809",
   "metadata": {},
   "source": [
    "### Experiments: What does ambiguity look like to an LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e4da8",
   "metadata": {},
   "source": [
    "The goal of this first experiment is to look at what \"ambigious\" (multiple possibilities) looks like to the transformer model. Above, we focused on next token probabilities. Now we want to hone in on what happens right at the point where a sentence may diverge into two possible sentence structures. Recall in that we have no possibility for doing this with POS, Named Entities, or Dependency Graphs in SpaCy. They pick the n-best sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93841128-032f-4237-81ab-4ec64d1fa9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: 'I saw the man with the'\n",
      "\n",
      "At this point, the model must 'decide' what comes next.\n",
      "If 'telescope' follows, interpretation leans INSTRUMENT.\n",
      "If a person-attribute word follows (hat, briefcase), it's ATTRIBUTE.\n",
      "\n",
      "Top 10 next-token predictions:\n",
      "----------------------------------------\n",
      "   ' sword      ' : 0.0262 ███████\n",
      "   ' knife      ' : 0.0224 ██████\n",
      "   ' black      ' : 0.0209 ██████\n",
      "   ' gun        ' : 0.0187 █████\n",
      "   ' mask       ' : 0.0167 █████\n",
      "   ' head       ' : 0.0156 ████\n",
      "   ' beard      ' : 0.0136 ████\n",
      "   ' same       ' : 0.0125 ███\n",
      "   ' red        ' : 0.0121 ███\n",
      "   ' right      ' : 0.0099 ██\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# COUPLING EXPERIMENT 1: Distribution at ambiguity point\n",
    "# Cut point: Right after \"with the\" - what comes next?\n",
    "\n",
    "# The cut point for our primary sentence\n",
    "ambiguity_prompt = \"I saw the man with the\"\n",
    "\n",
    "print(f\"\\nPrompt: '{ambiguity_prompt}'\")\n",
    "print(\"\\nAt this point, the model must 'decide' what comes next.\")\n",
    "print(\"If 'telescope' follows, interpretation leans INSTRUMENT.\")\n",
    "print(\"If a person-attribute word follows (hat, briefcase), it's ATTRIBUTE.\\n\")\n",
    "\n",
    "dist = get_next_token_distribution(ambiguity_prompt, k=10)\n",
    "\n",
    "print(\"Top 10 next-token predictions:\")\n",
    "print(\"-\" * 40)\n",
    "for token, prob in dist:\n",
    "    bar = '█' * int(prob * 300)\n",
    "    print(f\"   '{token:12}' : {prob:.4f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd3d6b",
   "metadata": {},
   "source": [
    "Expected Observation:\n",
    "    \n",
    "- Distribution should be relatively SPREAD OUT (flat)\n",
    "- Multiple plausible continuations have non-trivial probability\n",
    "- This 'flatness' reflects genuine ambiguity!\n",
    "- Unlike spaCy's single parse, the LM maintains uncertainty.\n",
    "\n",
    "Let's see what happens when we push the LLM to look at two different structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2677f9-a781-4fd4-9048-90a4aa2835b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base: 'I saw the man with the telescope'\n",
      "\n",
      "Continuation A (INSTRUMENT): ' and got a clear view of his face.'\n",
      "Continuation B (ATTRIBUTE):  ' standing on the corner.'\n",
      "\n",
      "--------------------------------------------------\n",
      "Scores (higher = more likely):\n",
      "   INSTRUMENT: sum=-23.026, avg=-2.558 (9 tokens)\n",
      "   ATTRIBUTE:  sum=-17.139, avg=-3.428 (5 tokens)\n",
      "\n",
      "   Model preference: INSTRUMENT\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# COUPLING EXPERIMENT 2: Forced-Choice Interpretation Scores\n",
    "\n",
    "# Base prompt\n",
    "base = \"I saw the man with the telescope\"\n",
    "\n",
    "# Continuations that force each interpretation\n",
    "instrument_continuation = \" and got a clear view of his face.\"\n",
    "attribute_continuation = \" standing on the corner.\"\n",
    "\n",
    "print(f\"\\nBase: '{base}'\")\n",
    "print(f\"\\nContinuation A (INSTRUMENT): '{instrument_continuation}'\")\n",
    "print(f\"Continuation B (ATTRIBUTE):  '{attribute_continuation}'\")\n",
    "\n",
    "# Score both\n",
    "score_a = score_continuation(base, instrument_continuation)\n",
    "score_b = score_continuation(base, attribute_continuation)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"Scores (higher = more likely):\")\n",
    "print(f\"   INSTRUMENT: sum={score_a[0]:.3f}, avg={score_a[1]:.3f} ({score_a[2]} tokens)\")\n",
    "print(f\"   ATTRIBUTE:  sum={score_b[0]:.3f}, avg={score_b[1]:.3f} ({score_b[2]} tokens)\")\n",
    "\n",
    "winner = \"INSTRUMENT\" if score_a[1] > score_b[1] else \"ATTRIBUTE\"\n",
    "print(f\"\\n   Model preference: {winner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ed2cd",
   "metadata": {},
   "source": [
    "Again, the scoring uses **log probabilities** - here's what that means:\n",
    "\n",
    "**Log probability**: Instead of multiplying tiny probabilities (which gets numerically unstable), we add their logarithms. Since probabilities are between 0 and 1, log probabilities are **negative numbers**. Less negative = more likely.\n",
    "\n",
    "**The two scores reported**:\n",
    "- `sum` - Total log probability across all tokens in the continuation\n",
    "- `avg` - Average log probability per token (sum divided by number of tokens)\n",
    "\n",
    "**Why INSTRUMENT won despite lower sum?**\n",
    "- INSTRUMENT: 9 tokens, sum = -23.026, **avg = -2.558**\n",
    "- ATTRIBUTE: 5 tokens, sum = -17.139, **avg = -3.428**\n",
    "\n",
    "The average is more fair for comparison because longer sequences naturally have more negative sums. The INSTRUMENT continuation has a better average probability per token (-2.558 vs -3.428), meaning each word is more \"expected\" by the model in that context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9dee8-b509-47c4-a40c-7417011015ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "📝 Primary (ambiguous)\n",
      "   Sentence: I saw the man with the telescope.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n",
      "   spaCy: 'with' → man (ATTRIBUTE)\n",
      "   LM top-1: 'sword' (0.026), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "📝 Rewrite 1 (attribute likely)\n",
      "   Sentence: I saw the man with the red hat.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n",
      "   spaCy: 'with' → man (ATTRIBUTE)\n",
      "   LM top-1: '-' (0.069), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "📝 Rewrite 2 (instrument likely)\n",
      "   Sentence: I saw the bird with the telescope.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n",
      "   spaCy: 'with' → saw (INSTRUMENT)\n",
      "   LM top-1: 'eye' (0.027), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "📝 Rewrite 3 (instrument forced)\n",
      "   Sentence: I saw the man with my telescope.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n",
      "   spaCy: 'with' → saw (INSTRUMENT)\n",
      "   LM top-1: 'hands' (0.039), dist=FLAT\n",
      "   LM preference: INSTRUMENT\n",
      "            Sentence spaCy Parse Top-1 Token Distribution LM Preference\n",
      " Primary (ambiguous)   ATTRIBUTE       sword         FLAT    INSTRUMENT\n",
      "Rewrite 1 (attribute   ATTRIBUTE           -         FLAT    INSTRUMENT\n",
      "Rewrite 2 (instrumen  INSTRUMENT         eye         FLAT    INSTRUMENT\n",
      "Rewrite 3 (instrumen  INSTRUMENT       hands         FLAT    INSTRUMENT\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# COUPLING EXPERIMENT 3: Complete side-by-side analysis\n",
    "\n",
    "# Define cut points and continuations for each sentence\n",
    "experiments = [\n",
    "    {\n",
    "        \"label\": \"Primary (ambiguous)\",\n",
    "        \"sentence\": \"I saw the man with the telescope.\",\n",
    "        \"cut_prompt\": \"I saw the man with the\",\n",
    "        \"instrument_cont\": \" telescope and got a clear view.\",\n",
    "        \"attribute_cont\": \" telescope standing nearby.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Rewrite 1 (attribute likely)\",\n",
    "        \"sentence\": \"I saw the man with the red hat.\",\n",
    "        \"cut_prompt\": \"I saw the man with the red\",\n",
    "        \"instrument_cont\": \" hat and got a clear view.\",\n",
    "        \"attribute_cont\": \" hat standing nearby.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Rewrite 2 (instrument likely)\",\n",
    "        \"sentence\": \"I saw the bird with the telescope.\",\n",
    "        \"cut_prompt\": \"I saw the bird with the\",\n",
    "        \"instrument_cont\": \" telescope and got a clear view.\",\n",
    "        \"attribute_cont\": \" telescope perched nearby.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Rewrite 3 (instrument forced)\",\n",
    "        \"sentence\": \"I saw the man with my telescope.\",\n",
    "        \"cut_prompt\": \"I saw the man with my\",\n",
    "        \"instrument_cont\": \" telescope and got a clear view.\",\n",
    "        \"attribute_cont\": \" telescope standing nearby.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results_table = []\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"\\n{'─'*60}\")\n",
    "    print(f\"📝 {exp['label']}\")\n",
    "    print(f\"   Sentence: {exp['sentence']}\")\n",
    "    \n",
    "    # Get spaCy parse\n",
    "    nlp = get_nlp()\n",
    "    doc = nlp(exp['sentence'])\n",
    "    with_token = [t for t in doc if t.text.lower() == \"with\"][0]\n",
    "    spacy_attachment = with_token.head.text\n",
    "    spacy_interp = \"INSTRUMENT\" if spacy_attachment in [\"saw\", \"see\"] else \"ATTRIBUTE\"\n",
    "    \n",
    "    # Get LM distribution\n",
    "    dist = get_next_token_distribution(exp['cut_prompt'], k=5)\n",
    "    top_token = dist[0][0].strip() if dist else \"?\"\n",
    "    top_prob = dist[0][1] if dist else 0\n",
    "    \n",
    "    # Calculate entropy-like measure (is distribution sharp or flat?)\n",
    "    probs = [p for _, p in dist[:5]]\n",
    "    max_prob = max(probs) if probs else 0\n",
    "    sharpness = \"SHARP\" if max_prob > 0.3 else \"FLAT\"\n",
    "    \n",
    "    # Score continuations\n",
    "    instr_score = score_continuation(exp['cut_prompt'], exp['instrument_cont'])\n",
    "    attr_score = score_continuation(exp['cut_prompt'], exp['attribute_cont'])\n",
    "    lm_preference = \"INSTRUMENT\" if instr_score[1] > attr_score[1] else \"ATTRIBUTE\"\n",
    "    \n",
    "    print(f\"   spaCy: 'with' → {spacy_attachment} ({spacy_interp})\")\n",
    "    print(f\"   LM top-1: '{top_token}' ({top_prob:.3f}), dist={sharpness}\")\n",
    "    print(f\"   LM preference: {lm_preference}\")\n",
    "    \n",
    "    results_table.append({\n",
    "        \"Sentence\": exp['label'][:20],\n",
    "        \"spaCy Parse\": spacy_interp,\n",
    "        \"Top-1 Token\": top_token[:10],\n",
    "        \"Distribution\": sharpness,\n",
    "        \"LM Preference\": lm_preference\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(results_table)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a49fba-7283-4444-a034-b0b8a18c7a60",
   "metadata": {},
   "source": [
    "Looking at this summary table, there are some interesting observations:\n",
    "\n",
    "**SpaCy's behavior**: It makes a single parse decision for each sentence. It chose ATTRIBUTE for the ambiguous cases and INSTRUMENT when \"my\" appears (which is a strong syntactic cue).\n",
    "\n",
    "**The LM's behavior**: It consistently prefers INSTRUMENT across all sentences when scoring the two continuations. However, notice the \"Distribution\" column shows FLAT for all - this means at the cut point, the model sees multiple plausible next words with similar probabilities, reflecting genuine uncertainty.\n",
    "\n",
    "**The mismatch**: The LM's top-1 predictions (sword, hands, eye) don't match the actual words in the sentences. This shows the model is considering many possibilities, not committing to one interpretation early.\n",
    "\n",
    "What's particularly interesting is that even though the distribution is FLAT (uncertain), when we force the model to score complete continuations, it shows a preference. Can you think on why this may be?\n",
    "\n",
    "What aspect would you like to explore more - why the LM prefers INSTRUMENT, or how we might design better experiments to test these interpretations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6023107",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What does a next-token objective teach a model about syntax and meaning?\n",
    "\n",
    "2. How does probability relate to ambiguity and \"preference\"?\n",
    "\n",
    "3. Why might the LLM's preference differ from spaCy's parse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_answer = \"Your answer about what next-token prediction teaches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_answer = \"Your answer about how probability relates to ambiguity and preference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e7d6b-2591-4aad-9c7b-f0a8b2a370bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_answer = \"Your answer about differences between LLM and spaCy parser\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e619a24-798d-483f-98b6-c518945cbd04",
   "metadata": {},
   "source": [
    "### Part C Summary\n",
    "\n",
    "In this section, you learned:\n",
    "\n",
    "- **Language models assign probabilities** to sequences of words, predicting what comes next.\n",
    "- **Bigram models** are simple (only one previous word) but suffer from sparsity—many word pairs never appear in training.\n",
    "- **Neural language models** generalize better by learning patterns, not just memorizing pairs.\n",
    "- **Ambiguity shows up as flat distributions**—when many continuations are plausible, no single prediction dominates.\n",
    "- **SpaCy commits to one parse** while language models maintain probability over possibilities.\n",
    "- **Log probabilities** let us compare how \"expected\" different continuations are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e0569d",
   "metadata": {},
   "source": [
    "## Part D: Sentiment Analysis\n",
    "\n",
    "Now let's turn to the application of NLP to real-world problems! We'll look at both sentiment analysis and summarization. In both cases we'll look at traditional, predictive methods and LLM's to see how they differ.\n",
    "\n",
    "Sentiment analysis determines whether text expresses positive, negative, or neutral feelings. This is one of the most common NLP applications—companies analyze customer reviews, social media monitors track brand perception, and researchers study public opinion.\n",
    "\n",
    "We will compare two approaches: a traditional rule-based method (VADER) and an LLM-based method.\n",
    "\n",
    "### Classical Approach: VADER\n",
    "\n",
    "**VADER** (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based sentiment analyzer designed for social media text. It works by looking up words in a sentiment dictionary and applying rules for negation, intensifiers, and punctuation. We may spend time using it because it is easy to use, hack, and understand. Plus, you can use VADER output to help train another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c337f48-9820-4702-8885-38df00bef85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "try:\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Initialize VADER\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84b3ef-5915-447b-946c-7473c644958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment-ambiguous test cases\n",
    "test_utterances = [\n",
    "    \"Oh great, another meeting that could have been an email.\",  # Sarcasm\n",
    "    \"The food was not unpleasant, I suppose.\",  # Double negative, hedged\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d44f81-2070-446f-869f-3c38be057b65",
   "metadata": {},
   "source": [
    "Why VADER? It's a rule-based sentiment analyzer that uses:\n",
    "\n",
    "- A sentiment lexicon (word → score mappings)\n",
    "- Grammatical rules (negation, intensifiers, etc.)\n",
    "- Punctuation and capitalization heuristics\n",
    "- Fast, deterministic, and interpretable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4be16-c06d-4106-b351-dc293ce59c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: \"Oh great, another meeting that could have been an email.\"\n",
      "   Compound: 0.625 → POSITIVE\n",
      "   (pos=0.31, neg=0.00, neu=0.69)\n",
      "\n",
      "Text: \"The food was not unpleasant, I suppose.\"\n",
      "   Compound: 0.372 → POSITIVE\n",
      "   (pos=0.34, neg=0.00, neu=0.66)\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# VADER analysis\n",
    "\n",
    "vader_results = []\n",
    "for text in test_utterances:\n",
    "    scores = vader.polarity_scores(text)\n",
    "    \n",
    "    # Determine label from compound score\n",
    "    if scores['compound'] >= 0.05:\n",
    "        label = \"POSITIVE\"\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        label = \"NEGATIVE\"\n",
    "    else:\n",
    "        label = \"NEUTRAL\"\n",
    "    \n",
    "    vader_results.append({\n",
    "        \"text\": text[:40] + \"...\",\n",
    "        \"label\": label,\n",
    "        \"compound\": scores['compound'],\n",
    "        \"pos\": scores['pos'],\n",
    "        \"neg\": scores['neg'],\n",
    "        \"neu\": scores['neu']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nText: \\\"{text}\\\"\")\n",
    "    print(f\"   Compound: {scores['compound']:.3f} → {label}\")\n",
    "    print(f\"   (pos={scores['pos']:.2f}, neg={scores['neg']:.2f}, neu={scores['neu']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb12844-af85-4a48-99ca-ff80cb73e059",
   "metadata": {},
   "source": [
    "Look at the results: VADER labeled both sentences as positive! The first sentence is sarcastic—\"great\" is used ironically. The second has a double negative (\"not unpleasant\") which VADER handled okay. This illustrates a key limitation of rule-based systems: they cannot understand context, irony, or nuance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1feed9",
   "metadata": {},
   "source": [
    "### LLM Approach\n",
    "\n",
    "LLMs can potentially catch subtleties that rule-based systems miss. If you have API access to an LLM, feel free to play with this to make it work with your API. If not, just read the output and follow along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2feee3a-1ab6-413d-9f7e-b26d1c45c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def safe_llm_unavailable_response(reason=\"LLM unavailable\"):\n",
    "    return {\n",
    "        \"label\": \"neutral\",\n",
    "        \"confidence\": 0.0,\n",
    "        \"rationale\": reason,\n",
    "        \"cues\": []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb53cae-e0c5-4477-80ae-c66c0dbbc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def analyze_sentiment_llm(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment using available LLM.\n",
    "    Always returns (response_text, provider).\n",
    "    Silently falls back if LLM is unavailable.\n",
    "    \"\"\"\n",
    "\n",
    "    if not llm_available():\n",
    "        return (\n",
    "            json.dumps(\n",
    "                safe_llm_unavailable_response(\"LLM unavailable\"),\n",
    "                ensure_ascii=False\n",
    "            ),\n",
    "            \"unavailable\"\n",
    "        )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analyze the sentiment of this text and respond with ONLY valid JSON.\n",
    "\n",
    "Text: \"{text}\"\n",
    "\n",
    "Respond with this exact JSON format (no other text):\n",
    "\n",
    "{{\n",
    "  \"label\": \"positive\" | \"negative\" | \"neutral\" | \"mixed\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"rationale\": \"brief explanation\",\n",
    "  \"cues\": []\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = chat(prompt)\n",
    "        response_text = response.choices[0].message.content\n",
    "        return response_text, \"llm\"\n",
    "    except Exception:\n",
    "        return (\n",
    "            json.dumps(\n",
    "                safe_llm_unavailable_response(\"LLM call failed\"),\n",
    "                ensure_ascii=False\n",
    "            ),\n",
    "            \"error\"\n",
    "        )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96289e-f5e1-469a-9f49-53403ebf827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def parse_sentiment_json(response_text):\n",
    "    \"\"\"Safely parse JSON from LLM response.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Try to extract JSON from response\n",
    "    try:\n",
    "        # First try direct parse\n",
    "        return json.loads(response_text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to find JSON in the response\n",
    "    try:\n",
    "        json_match = re.search(r'\\{[^}]+\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Return error structure\n",
    "    return {\n",
    "        \"label\": \"parse_error\",\n",
    "        \"confidence\": 0,\n",
    "        \"rationale\": f\"Could not parse: {response_text[:100]}\",\n",
    "        \"cues\": []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2523b-7419-4026-830d-d20679221a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: \"Oh great, another meeting that could have been an email.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Provider: llm\n",
      "   Label: negative\n",
      "   Confidence: 0.95\n",
      "   Rationale: The phrase uses sarcasm ('Oh great') to express frustration about an unnecessary meeting, indicating clear dissatisfaction.\n",
      "   Cues: ['Oh great', 'could have been an email', 'sarcastic tone', 'frustration with unnecessary meetings']\n",
      "\n",
      "Text: \"The food was not unpleasant, I suppose.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Provider: llm\n",
      "   Label: mixed\n",
      "   Confidence: 0.75\n",
      "   Rationale: The double negative 'not unpleasant' suggests mild approval, but the hesitant phrase 'I suppose' indicates lukewarm enthusiasm and uncertainty, creating an overall ambivalent tone.\n",
      "   Cues: ['not unpleasant', 'I suppose', 'double negative', 'hesitant tone', 'lack of enthusiasm']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Analyze each utterance\n",
    "llm_results = []\n",
    "\n",
    "for text in test_utterances:\n",
    "    print(f\"\\nText: \\\"{text}\\\"\")\n",
    "    response, provider = analyze_sentiment_llm(text)\n",
    "    print(f\"   Provider: {provider}\")\n",
    "    \n",
    "    parsed = parse_sentiment_json(response)\n",
    "    llm_results.append(parsed)\n",
    "    \n",
    "    print(f\"   Label: {parsed.get('label', 'N/A')}\")\n",
    "    print(f\"   Confidence: {parsed.get('confidence', 'N/A')}\")\n",
    "    print(f\"   Rationale: {parsed.get('rationale', 'N/A')}\")\n",
    "    print(f\"   Cues: {parsed.get('cues', [])}\")\n",
    "if len(llm_results) < len(test_utterances):\n",
    "    print(\"Some LLM sentiment analyses failed; comparison table may be incomplete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c1b56-bb70-4a08-89df-39af8e9fb26c",
   "metadata": {},
   "source": [
    "If you've run this cell and lost the output, you can use this:\n",
    "\n",
    "Text: \"Oh great, another meeting that could have been an email.\"\n",
    "   Provider: llm\n",
    "   Label: negative\n",
    "   Confidence: 0.95\n",
    "   Rationale: The phrase uses sarcasm ('Oh great') to express frustration about an unnecessary meeting, indicating clear dissatisfaction.\n",
    "   Cues: ['Oh great', 'could have been an email', 'sarcastic tone', 'frustration with unnecessary meetings']\n",
    "\n",
    "Text: \"The food was not unpleasant, I suppose.\"\n",
    "   Provider: llm\n",
    "   Label: mixed\n",
    "   Confidence: 0.75\n",
    "   Rationale: The double negative 'not unpleasant' suggests mild approval, but the hesitant phrase 'I suppose' indicates lukewarm enthusiasm and uncertainty, creating an overall ambivalent tone.\n",
    "   Cues: ['not unpleasant', 'I suppose', 'double negative', 'hesitant tone', 'lack of enthusiasm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce95a4",
   "metadata": {},
   "source": [
    "  #### Comparision of VADER and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9c1cd-5fd0-424d-8056-e2440b265754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📊 COMPARISON: VADER vs LLM\n",
      "======================================================================\n",
      "                      Text (truncated) VADER Label VADER Score LLM Label LLM Conf\n",
      "Oh great, another meeting that coul...    POSITIVE        0.62  negative     0.95\n",
      "The food was not unpleasant, I supp...    POSITIVE        0.37     mixed     0.65\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 COMPARISON: VADER vs LLM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = []\n",
    "for i, text in enumerate(test_utterances):\n",
    "    comparison_data.append({\n",
    "        \"Text (truncated)\": text[:35] + \"...\",\n",
    "        \"VADER Label\": vader_results[i]['label'],\n",
    "        \"VADER Score\": f\"{vader_results[i]['compound']:.2f}\",\n",
    "        \"LLM Label\": llm_results[i].get('label', 'N/A'),\n",
    "        \"LLM Conf\": f\"{llm_results[i].get('confidence', 0):.2f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a74f5c-7acb-49ac-a34f-ff3071c2c7f7",
   "metadata": {},
   "source": [
    "- Where did VADER fail? Why?\n",
    "- Did the LLM catch sarcasm/nuance that VADER missed?\n",
    "- What 'cues' did the LLM identify?\n",
    "- Which would you trust more for: customer reviews? tweets? emails?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45f45a",
   "metadata": {},
   "source": [
    "**Submit:** Answer these questions:\n",
    "\n",
    "1. For the sarcastic sentence, how did VADER's label compare to the LLM's? What caused any difference?\n",
    "\n",
    "2. What are two scenarios where you'd prefer VADER over an LLM, and two where you'd prefer the LLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_answer = \"Your analysis of sarcasm handling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_answer =  \"Prefer VADER for scenario 1 or scenario 2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a73ac5-9003-4a5b-9e0b-f7ffb61ca6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_answer = \"Prefer LLM for scenario 1 or scenario 2?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8be90f-a888-4b4c-8047-8f21a98cd123",
   "metadata": {},
   "source": [
    "### Part D Summary\n",
    "\n",
    "In this section, you learned about how to use spaCy for a real-world task.\n",
    "\n",
    "- **Sentiment analysis** classifies text as positive, negative, or neutral.\n",
    "- **VADER** is fast, interpretable, and rule-based, but misses sarcasm, irony, and nuance.\n",
    "- **LLMs** can capture subtleties but are slower, more expensive, and less predictable.\n",
    "- **Choose your tool based on your needs**: high volume and simple text favors VADER; nuanced analysis favors LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d83479",
   "metadata": {},
   "source": [
    "## Part E: SpaCy Pipeline with LLM Summarization\n",
    "\n",
    "One of spaCy's most powerful features is its modular pipeline architecture. You can add, remove, or customize components to build exactly the NLP system you need. In this section, we will explore how to create custom components and compare different approaches to summarization.\n",
    "\n",
    "Let us explore how NLP systems can be built as pipelines of components and how this differs from end-to-end LLM approaches. Again, do not worry about the code details—just think through this conceptually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d336a-9e98-4642-b820-36fb8fdf1073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok2vec: Tok2Vec\n",
      "tagger: Tagger\n",
      "parser: DependencyParser\n",
      "attribute_ruler: AttributeRuler\n",
      "lemmatizer: EnglishLemmatizer\n",
      "ner: EntityRecognizer\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# You've already seen a default spaCy pipeline architecture like this\n",
    "\n",
    "for name, component in nlp.pipeline:\n",
    "    print(f\"{name}: {type(component).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa5517",
   "metadata": {},
   "source": [
    "#### Custom SpaCy component\n",
    "\n",
    "Let's build an component that flags a sentence for both ORG and DATE.\n",
    "\n",
    "**Custom components** are functions that process a `Doc` object and return it (possibly modified). They get added to the pipeline and run automatically when you call `nlp(text)`.\n",
    "\n",
    "Here's the basic structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.custom_component(doc)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "@spacy.Language.component(\"component_name\")\n",
    "def custom_component(doc):\n",
    "    # Do something with doc\n",
    "    # You can add custom attributes, modify tokens, etc.\n",
    "    return doc\n",
    "\n",
    "# Add it to the pipeline\n",
    "nlp.add_pipe(\"component_name\", last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb2039",
   "metadata": {},
   "source": [
    "For this specific task -- flagging sentences with both ORG and DATE entities), we want to:\n",
    "\n",
    "1. Iterate through the doc's sentences\n",
    "2. Check what entity types appear in each sentence\n",
    "3. Store a flag somewhere (maybe as a custom attribute on the **`Span`** - a slice of a doc object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333028c-7e96-470a-b931-dbdd38ed0225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'component_name', 'org_date_flagger']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Create a custom spaCy component\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "@Language.component(\"org_date_flagger\")\n",
    "def org_date_flagger(doc):\n",
    "    \"\"\"Flag sentences that contain both ORG and DATE entities.\"\"\"\n",
    "    # Add custom attribute to doc if not exists\n",
    "    if not doc.has_extension(\"flagged_sentences\"):\n",
    "        from spacy.tokens import Doc\n",
    "        Doc.set_extension(\"flagged_sentences\", default=[])\n",
    "    \n",
    "    flagged = []\n",
    "    for sent in doc.sents:\n",
    "        sent_ents = [ent.label_ for ent in sent.ents]\n",
    "        if \"ORG\" in sent_ents and \"DATE\" in sent_ents:\n",
    "            flagged.append(sent.text)\n",
    "    \n",
    "    doc._.flagged_sentences = flagged\n",
    "    return doc\n",
    "\n",
    "# Add to pipeline (only if not already there)\n",
    "if \"org_date_flagger\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"org_date_flagger\", last=True)\n",
    "\n",
    "print(f\"\\nUpdated pipeline: {nlp.pipe_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd78ed",
   "metadata": {},
   "source": [
    "The `doc._` syntax is spaCy's way of accessing **custom extensions** that you've added to a Doc object.\n",
    "\n",
    "Here's why this design:\n",
    "\n",
    "**Built-in attributes** use direct access:\n",
    "- `doc.ents` (entities)\n",
    "- `doc.text` (text)\n",
    "- `token.pos_` (part of speech)\n",
    "\n",
    "**Custom attributes** use the underscore namespace:\n",
    "- `doc._.flagged_sentences` (your custom attribute)\n",
    "- `token._.custom_score` (if you created this)\n",
    "\n",
    "This separation prevents naming conflicts—your custom `flagged_sentences` won't accidentally override something built into spaCy. It also makes it clear when you're using custom vs. built-in functionality.\n",
    "\n",
    "The underscore is a special namespace that spaCy reserves for user extensions. You must register extensions with `Doc.set_extension()` before using them, which is what the code does with the `if not doc.has_extension()` check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c8288-601a-4bfe-a936-6ea6ff029e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test text:\n",
      "Microsoft announced record earnings on January 24th, 2024.\n",
      "The weather was sunny. Apple plans to release new products in March.\n",
      "John went to the store.\n",
      "\n",
      "\n",
      " Sentences containing both ORG and DATE:\n",
      "\n",
      "\n",
      "Microsoft announced record earnings on January 24th, 2024.\n",
      "\n",
      "Apple plans to release new products in March.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Test the custom component\n",
    "test_text = \"\"\"Microsoft announced record earnings on January 24th, 2024.\n",
    "The weather was sunny. Apple plans to release new products in March.\n",
    "John went to the store.\"\"\"\n",
    "\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"\\nTest text:\")\n",
    "print(test_text)\n",
    "print(\"\\n\\n Sentences containing both ORG and DATE:\\n\\n\")\n",
    "for sent in doc._.flagged_sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a704c3-8ab6-4343-a99a-3af141f54968",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"In the Blue Ridge, the Christmas season was celebrated for days on end, with gatherings of family and friends, good food, and lots of music. This was especially true in the area known as Round Peak, around Mount Airy, North Carolina, and Galax, Virginia. The tradition was called Breaking up Christmas, and December 25th was just the beginning. Starting on Christmas and continuing for 12 days,people in the mountains would go from house to house viisiting neighbors, dancing and playing music.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983a300-4199-480a-bfae-fc07a8bbc770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n",
      "\n",
      "Top sentences (by TF + entity score):\n",
      "\n",
      "1. (score: 0.88)\n",
      "   This was especially true in the area known as Round Peak, around Mount Airy, North Carolina, and Galax, Virginia.\n",
      "\n",
      "2. (score: 0.82)\n",
      "   Starting on Christmas and continuing for 12 days,people in the mountains would go from house to house viisiting neighbors, dancing and playing music.\n",
      "\n",
      "💡 Note: Extractive = select existing sentences, transparent scoring\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Classical extractive summarizer\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def extractive_summarize(text, num_sentences=2):\n",
    "    \"\"\"Simple extractive summarizer using TF and entity presence.\"\"\"\n",
    "    nlp = get_nlp()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Get term frequencies (excluding stop words)\n",
    "    word_freq = Counter()\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha:\n",
    "            word_freq[token.lemma_.lower()] += 1\n",
    "    \n",
    "    # Score each sentence\n",
    "    sentence_scores = []\n",
    "    for sent in doc.sents:\n",
    "        score = 0\n",
    "        # TF score\n",
    "        for token in sent:\n",
    "            if token.lemma_.lower() in word_freq:\n",
    "                score += word_freq[token.lemma_.lower()]\n",
    "        \n",
    "        # Bonus for entities\n",
    "        entity_bonus = len([e for e in sent.ents]) * 2\n",
    "        score += entity_bonus\n",
    "        \n",
    "        # Normalize by length\n",
    "        score = score / (len(list(sent)) + 1)\n",
    "        \n",
    "        sentence_scores.append((sent.text.strip(), score))\n",
    "    \n",
    "    # Sort by score and return top sentences\n",
    "    sorted_sents = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_sents[:num_sentences]\n",
    "\n",
    "\n",
    "extracted = extractive_summarize(article, num_sentences=2)\n",
    "print(\"\\nTop sentences (by TF + entity score):\")\n",
    "for i, (sent, score) in enumerate(extracted, 1):\n",
    "    print(f\"\\n{i}. (score: {score:.2f})\")\n",
    "    print(f\"   {sent}\")\n",
    "\n",
    "print(\"\\n💡 Note: Extractive = select existing sentences, transparent scoring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db629ffa-1d07-4130-9299-2eda457e5525",
   "metadata": {},
   "source": [
    "This simple summarizer ranks existing sentences using a simple heuristic score.\n",
    "\n",
    "- Compute term frequencies over non-stopword lemmas.\n",
    "- Score each sentence by summing its term frequencies, adding a bonus for named entities, and normalizing by sentence length.\n",
    "- Return the top-scoring sentences as the summary.\n",
    "\n",
    "The method is fast, deterministic, and transparent, but it reflects its assumptions (e.g., entities ≈ importance) rather than true semantic understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0110824",
   "metadata": {},
   "source": [
    "Let's think through why that first sentence scored higher:\n",
    "\n",
    "**The first sentence** has:\n",
    "- Multiple entities: \"Round Peak\", \"Mount Airy\", \"North Carolina\", \"Galax\", \"Virginia\" (5 GPE entities!)\n",
    "- Entity bonus: 5 entities × 2 = +10 to the score\n",
    "- This entity bonus significantly boosted its score\n",
    "\n",
    "**The second sentence** has:\n",
    "- More thematic words (\"Christmas\", \"mountains\", \"house\", \"music\")\n",
    "- But fewer named entities\n",
    "- Lower entity bonus\n",
    "\n",
    "The algorithm assumes entities = importance, which isn't always true. The first sentence is actually providing geographic context, while the second describes the actual tradition.\n",
    "\n",
    "This is a classic problem with simple extractive summarizers—they use heuristics (like \"entities are important\") that don't always align with what humans find most relevant.\n",
    "\n",
    "Can you think of how you might modify the scoring to better capture the main idea of this passage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ef10a-399d-4fd3-8bda-eb34ccd93697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_summarize(text):\n",
    "    \"\"\"\n",
    "    Generate abstractive summary using available LLM.\n",
    "    Silently falls back if LLM is unavailable.\n",
    "    Always returns plain text.\n",
    "    \"\"\"\n",
    "\n",
    "    if not llm_available():\n",
    "        return (\n",
    "            \"HEADLINE: Summary unavailable\\n\\n\"\n",
    "            \"• LLM disabled or unavailable\\n\"\n",
    "            \"• Skipping abstractive summarization\\n\"\n",
    "            \"• Proceeding with notebook execution\"\n",
    "        )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Summarize this article in exactly:\n",
    "\n",
    "- 3 bullet points (key facts)\n",
    "- 1 headline (max 10 words)\n",
    "\n",
    "Article:\n",
    "{text}\n",
    "\n",
    "Format exactly as:\n",
    "\n",
    "HEADLINE: <headline>\n",
    "• <bullet 1>\n",
    "• <bullet 2>\n",
    "• <bullet 3>\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = chat(prompt)\n",
    "        # handle both raw string and ModelResponse\n",
    "        if hasattr(response, \"choices\"):\n",
    "            return response.choices[0].message.content\n",
    "        return str(response)\n",
    "\n",
    "    except Exception:\n",
    "        return (\n",
    "            \"HEADLINE: Summary unavailable\\n\\n\"\n",
    "            \"• LLM call failed\\n\"\n",
    "            \"• No impact on remaining analysis\\n\"\n",
    "            \"• Safe fallback applied\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382246c-48b1-4c2f-9de5-7f11662bf25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADLINE: Blue Ridge Christmas Celebrated for 12 Days\n",
      "\n",
      "• Breaking up Christmas was a traditional 12-day celebration in the Blue Ridge region around Mount Airy, NC and Galax, VA\n",
      "• The festivities began on December 25th and featured family gatherings, food, and extensive music and dancing\n",
      "• Mountain residents traveled house to house visiting neighbors throughout the entire celebration period\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "summary_text = llm_summarize(article)\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94152d8-077e-4768-90dc-13c47707c8c5",
   "metadata": {},
   "source": [
    "If you ran this cell and lost the LLM output, you can use this:\n",
    "\n",
    "HEADLINE: Blue Ridge Christmas Celebrated for 12 Days\n",
    "\n",
    "• Breaking up Christmas was a traditional 12-day celebration in the Blue Ridge region around Mount Airy, NC and Galax, VA\n",
    "• The festivities began on December 25th and featured family gatherings, food, and extensive music and dancing\n",
    "• Mountain residents traveled house to house visiting neighbors throughout the entire celebration period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ddf7d-2438-4cb7-9d5c-e153d613af91",
   "metadata": {},
   "source": [
    "As you may already know, LLMs are **non-deterministic** (can produce different outputs from the same input) and can:\n",
    "\n",
    "- Hallucinate facts not in the original\n",
    "- Over-generalize or lose nuance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511358a-5ee0-483d-b383-8100ad585a20",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "**Submit:** \n",
    "\n",
    "1. What are two advantages of spaCy's modular pipeline approach?\n",
    "\n",
    "2. When would you choose extractive over abstractive summarization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_answer = \"Your answer about pipeline advantages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d94da-5c70-405f-81ab-2ebba47cc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q8_answer = \"Your answer about summarization choice\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa0480-811f-4ff9-b513-893de6993f63",
   "metadata": {},
   "source": [
    "### Part E Summary\n",
    "\n",
    "In this section, we tackled a different task and showed you the flexibility of spaCy to incorporate custom components:\n",
    "\n",
    "- **SpaCy pipelines are modular**—you can add custom components that run automatically when processing text.\n",
    "- **Custom extensions** (accessed via `doc._`) let you attach your own data to Doc, Span, or Token objects.\n",
    "- **Extractive summarization** selects existing sentences based on scoring heuristics—transparent but limited.\n",
    "- **Abstractive summarization** (LLM) generates new text—flexible but can hallucinate or lose nuance.\n",
    "- **Choose based on your needs**: extractive for verifiable, traceable summaries; abstractive for readable, condensed versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d57657",
   "metadata": {},
   "source": [
    "## Part F: Reflection\n",
    "\n",
    "Let us summarize everything we covered in this notebook. This lab covered a lot of ground in NLP! Here's what you explored:\n",
    "\n",
    "**Core NLP Components (SpaCy)**:\n",
    "- Tokens and their attributes (lemmas, POS tags, stop words)\n",
    "- Named Entity Recognition (NER) - how models tag entities and why they sometimes get it wrong\n",
    "- Dependency parsing - understanding relationships between words in sentences\n",
    "\n",
    "**Language Models as Probability Distributions**:\n",
    "- Bigram models vs. neural language models (DistilGPT2)\n",
    "- Next-token prediction and what probability distributions reveal about ambiguity\n",
    "- How LMs handle syntactic ambiguity differently than parsers (maintaining uncertainty vs. committing to one parse)\n",
    "\n",
    "**Practical Applications**:\n",
    "- Sentiment analysis: rule-based (VADER) vs. LLM approaches\n",
    "- Summarization: extractive (selecting sentences) vs. abstractive (generating new text)\n",
    "- Building custom SpaCy pipeline components\n",
    "\n",
    "**Key Insight**: Different NLP approaches have different strengths - modular pipelines are transparent and fast, while LLMs capture nuance but are less interpretable.\n",
    "\n",
    "What part did you find most interesting or want to explore more?\n",
    "\n",
    "**Submit:**\n",
    "1. What did you find most interesting in this lab?\n",
    "2. Was there something you found surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d35643",
   "metadata": {},
   "outputs": [],
   "source": [
    "q9_answer = \"What you found most interesting in the lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c61487-8ce4-4be7-b518-8824435a812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_answer = \"Whether you found something surprising\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1a879",
   "metadata": {},
   "source": [
    "## Submit Notebook for credit\n",
    "\n",
    "Instructions: replace \"test_student\" with your name and run the cell. You will see your answers printed as feedback. If you wish to change your answers... just re-submit. \n",
    "\n",
    "Feel free to use AI as feedback on your answers after you've tried to answer questions yourself. I'll scan responses to see what might have been confusing in the lab. Lab questions are ungraded and we can talk about your thoughts or questions in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121b90f-a01c-4111-9611-0cfc45e484f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# REVIEW ONLY — does not submit\n",
    "\n",
    "from data401_nlp.helpers.submit import collect_answers, parse_answers\n",
    "\n",
    "# REVIEW ONLY — does not submit\n",
    "\n",
    "raw = collect_answers(\n",
    "    show=True,\n",
    "    namespace=globals(),   \n",
    ")\n",
    "\n",
    "answers = parse_answers(raw)\n",
    "\n",
    "print(f\"\\nDetected {len(answers)} answers:\")\n",
    "for k in answers:\n",
    "    print(\" \", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0111f3-62e8-43e5-bce9-4c8a563d7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "ALLOW_SUBMISSION = False   # ← student MUST change this\n",
    "\n",
    "def submit_for_credit(student_id):\n",
    "    if not ALLOW_SUBMISSION:\n",
    "        raise RuntimeError(\n",
    "            \"⚠️ Submission is disabled.\\n\\n\"\n",
    "            \"To submit:\\n\"\n",
    "            \"  1. Set ALLOW_SUBMISSION = True\\n\"\n",
    "            \"  2. Re-run this cell\"\n",
    "        )\n",
    "\n",
    "    submit_answers(\n",
    "        student_id=student_id,\n",
    "        answers=answers,   # uses reviewed answers\n",
    "    )\n",
    "\n",
    "    print(\"✅ Submission complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4d274",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "⚠️ Submission is currently disabled.\n\nTo submit:\n  1. Review your answers\n  2. Set ALLOW_SUBMISSION = True\n  3. Re-run this cell",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| eval: false\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Don't forget to edit with your name\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msubmit_for_credit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myour name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36msubmit_for_credit\u001b[39m\u001b[34m(student_id)\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSUBMIT_API_KEY not found. Did you run the environment setup cell at the top of the notebook?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_SUBMISSION:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m⚠️ Submission is currently disabled.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo submit:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m  1. Review your answers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m  2. Set ALLOW_SUBMISSION = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m  3. Re-run this cell\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m     )\n\u001b[32m     30\u001b[39m submit_answers(\n\u001b[32m     31\u001b[39m     student_id=student_id,\n\u001b[32m     32\u001b[39m     path=NOTEBOOK_PATH,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: ⚠️ Submission is currently disabled.\n\nTo submit:\n  1. Review your answers\n  2. Set ALLOW_SUBMISSION = True\n  3. Re-run this cell"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "⚠️ Submission is disabled.\n\nTo submit:\n  1. Set ALLOW_SUBMISSION = True\n  2. Re-run this cell",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| eval: false\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Don't forget to edit with your name\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msubmit_for_credit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myour name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36msubmit_for_credit\u001b[39m\u001b[34m(student_id)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msubmit_for_credit\u001b[39m(student_id):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_SUBMISSION:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m      8\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m⚠️ Submission is disabled.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTo submit:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m  1. Set ALLOW_SUBMISSION = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m  2. Re-run this cell\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m         )\n\u001b[32m     14\u001b[39m     submit_answers(\n\u001b[32m     15\u001b[39m         student_id=student_id,\n\u001b[32m     16\u001b[39m         answers=answers,   \u001b[38;5;66;03m# uses reviewed answers\u001b[39;00m\n\u001b[32m     17\u001b[39m     )\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Submission complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: ⚠️ Submission is disabled.\n\nTo submit:\n  1. Set ALLOW_SUBMISSION = True\n  2. Re-run this cell"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Don't forget to edit with your name\n",
    "submit_for_credit(\"your name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8161910-bd37-45ff-adfe-e2dc98010477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "data401_nlp",
   "language": "python",
   "name": "data401_nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
