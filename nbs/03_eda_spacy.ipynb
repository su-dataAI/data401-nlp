{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0834ddfd",
   "metadata": {},
   "source": [
    "# Lab 2 - Leveraging spaCy for Comparative Textual EDA (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c29260",
   "metadata": {},
   "source": [
    "In the last lab you learned about:\n",
    "- Text preprocessing including vocabulary, frequency counts, and analyses.\n",
    "- Raw frequency, normalization, and relative measures for comparing different groups.\n",
    "- Dispersion showing where language appears in the corpus.\n",
    "- Distributional patterns - observable in visualizations like KWIC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e30256-2335-4c32-92e5-902066d439c1",
   "metadata": {},
   "source": [
    "Objectives: \n",
    "- Analyze **distributional patterns** in text using normalized frequency counts to **compare language use across groups**.\n",
    "- Operationalize **word association through bigrams and collocations**, and explain how association measures differ from raw frequency.\n",
    "- Compute and **interpret Pointwise Mutual Information (PMI) to identify exclusive or slogan-like word pairings**, while understanding its bias toward rare events.\n",
    "- Apply linguistic annotation with spaCy (POS tagging and NER) to **explore grammatical and entity-level patterns in text**.\n",
    "- Evaluate the **limits of linguistic annotation on social media data**, recognizing noise introduced by hashtags, emojis, and non-standard syntax.\n",
    "- Use **sampling and normalization** responsibly to make comparisons across corpora of different sizes.\n",
    "- **Reflect on how statistical association methods** connect to modern NLP and LLMs, particularly how embeddings internalize frequency and surprise signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a0ea9-08e9-41d7-b977-ce81f53b5803",
   "metadata": {},
   "source": [
    "**Useful References:**\n",
    "\n",
    "- Brezina, Vaclav (2018). [Statistics in Corpus Linguistics](http://corpora.lancs.ac.uk/stats/materials.php): A Practical Guide.\n",
    "- [SpaCy API](https://spacy.io/api). https://spacy.io/api\n",
    "- [Possibility and Necessity. Chapter 16-16.2](https://socialsci.libretexts.org/Bookshelves/Linguistics/Analyzing_Meaning_-_An_Introduction_to_Semantics_and_Pragmatics_(Kroeger)/16%3A_Modality/16.01%3A_16.1_Possibility_and_necessity) in Analyzing Meaning - An Introduction to Semantics and Pragmatics (Kroeger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77239b37-7928-4e15-ae6b-794be8a5076d",
   "metadata": {},
   "source": [
    "Note about this lab: your focus should be on speculating and introspecting on observed phenomena. You'll be asked to consider how or why an LLM can do things that pose challenges for traditional NLP and statistical methods. As before, think and respond before asking an AI model for insight. We'll go much more deeply into how things work as we go in this class.\n",
    "\n",
    "While this lab is labeled EDA part 2, non of it is strictly needed by your EDA. This lab should stimulate your thinking about EDA beyond reporting relative frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf4b23-f946-4f1c-9fab-fc107fad12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are colab, un-comment the pip install below.\n",
    "# This will not be necessary on DeepNote or your local installation\n",
    "\n",
    "#!pip install data401_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef92c8d-e887-46f4-a1f9-434de1cf00ca",
   "metadata": {},
   "source": [
    "## Load libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.7\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Environment (must run first)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import data401_nlp\n",
    "print(data401_nlp.__version__)\n",
    "\n",
    "# Core libs\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0687314-d114-41eb-bd6f-ed0829b2a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: anthropic/claude-sonnet-4-5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from data401_nlp.helpers.env import load_env\n",
    "from data401_nlp.helpers.llm import make_chat, LLM_MODELS\n",
    "\n",
    "load_env()\n",
    "DEFAULT_MODEL = LLM_MODELS[0] # Assumes Claude key... adjust if needed.\n",
    "print(\"Selected model:\", DEFAULT_MODEL)\n",
    "chat = make_chat(DEFAULT_MODEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec9d3b-99bb-4a2c-a28f-57adbbb5efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: enable: false\n",
    "\n",
    "# You must explicitly opt in, if you want to use and run cells with external LLM calls\n",
    "ENABLE_LLM = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed74821-f651-4d5b-b7fd-e412d91af5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM status: ready\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_status(chat_fn):\n",
    "    if not ENABLE_LLM:\n",
    "        return \"disabled\"\n",
    "    try:\n",
    "        chat_fn(\"ping\", max_tokens=1)\n",
    "        return \"ready\"\n",
    "    except Exception:\n",
    "        return \"misconfigured\"\n",
    "\n",
    "print(\"LLM status:\", llm_status(chat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e801f-6c79-44c7-83ed-11947de37e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def make_and_test_chat(model_name):\n",
    "    if not ENABLE_LLM:\n",
    "        return None  # silent no-op\n",
    "\n",
    "    try:\n",
    "        chat = make_chat(model_name)\n",
    "        chat(\"ping\", max_tokens=1)\n",
    "        return chat\n",
    "    except Exception:\n",
    "        return None  # silent fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48689f00-b1bf-4781-bf75-502891443f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_available():\n",
    "    return ENABLE_LLM and chat is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0f383-4861-4e47-bc2e-3229b175cd69",
   "metadata": {},
   "source": [
    "## Set up the Dataframe from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab6214-9733-4532-83b5-3b87a2fe1a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-31 02:08:31</td>\n",
       "      <td>2020sucks trumpisscar ihateithere wearamask</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>#2020sucks #trumpisscar #ihateithere #wearamas...</td>\n",
       "      <td>promask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-31 02:07:58</td>\n",
       "      <td>antimasker antimasking DOJ pandemic</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>This is probably one of the most ridiculous of...</td>\n",
       "      <td>promask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-31 02:07:28</td>\n",
       "      <td>wearamask maskuphoosiers</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>Just, like, do it. #wearamask #maskuphoosiers ...</td>\n",
       "      <td>promask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-31 02:07:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>So one day a guy will be bragging how he didn’...</td>\n",
       "      <td>promask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>2020-08-31 02:03:58</td>\n",
       "      <td>COVID19 covidhoax</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>6% Of all #COVID19 Deaths were from just the v...</td>\n",
       "      <td>antimask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>2020-08-31 02:03:35</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>#COVID19 is a hoax.  Fuck masks. If you don’t ...</td>\n",
       "      <td>antimask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>2020-08-31 02:02:55</td>\n",
       "      <td>COVID19 CovidHoax</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>@ProfPCDoherty There was no need to shut the b...</td>\n",
       "      <td>antimask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>2020-08-31 02:01:45</td>\n",
       "      <td>CovidHoax</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>#CovidHoax is over... Let's OPEN the world and...</td>\n",
       "      <td>antimask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_date                                     hashtags  \\\n",
       "0     2020-08-31 02:08:31  2020sucks trumpisscar ihateithere wearamask   \n",
       "1     2020-08-31 02:07:58          antimasker antimasking DOJ pandemic   \n",
       "2     2020-08-31 02:07:28                     wearamask maskuphoosiers   \n",
       "3     2020-08-31 02:07:16                                          NaN   \n",
       "5000  2020-08-31 02:03:58                            COVID19 covidhoax   \n",
       "5001  2020-08-31 02:03:35                                      COVID19   \n",
       "5002  2020-08-31 02:02:55                            COVID19 CovidHoax   \n",
       "5003  2020-08-31 02:01:45                                    CovidHoax   \n",
       "\n",
       "      num_hashtags  tweet_length  \\\n",
       "0                4            90   \n",
       "1                4           137   \n",
       "2                2            69   \n",
       "3                0           140   \n",
       "5000             2           125   \n",
       "5001             1           140   \n",
       "5002             2           148   \n",
       "5003             1           140   \n",
       "\n",
       "                                             tweet_text     group  \n",
       "0     #2020sucks #trumpisscar #ihateithere #wearamas...   promask  \n",
       "1     This is probably one of the most ridiculous of...   promask  \n",
       "2     Just, like, do it. #wearamask #maskuphoosiers ...   promask  \n",
       "3     So one day a guy will be bragging how he didn’...   promask  \n",
       "5000  6% Of all #COVID19 Deaths were from just the v...  antimask  \n",
       "5001  #COVID19 is a hoax.  Fuck masks. If you don’t ...  antimask  \n",
       "5002  @ProfPCDoherty There was no need to shut the b...  antimask  \n",
       "5003  #CovidHoax is over... Let's OPEN the world and...  antimask  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from data401_nlp.helpers.spacy import ensure_spacy_model\n",
    "\n",
    "def get_nlp():\n",
    "    return ensure_spacy_model(\"en_core_web_sm\")\n",
    "    \n",
    "nlp = get_nlp()\n",
    "\n",
    "df1 = pd.read_csv(\"data/covidisreal_OR_wearamask_hashtag.csv\")\n",
    "df2 = pd.read_csv(\"data/covidhoax_OR_notomasks_hashtag.csv\")\n",
    "\n",
    "df1['group'] = 'promask'\n",
    "df2['group'] = 'antimask'\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.groupby('group').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9e29f-c58e-48d8-8ab2-d9a0e73b8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return text.lower().replace(\"\\n\", \" \")\n",
    "\n",
    "def process_tweet(text):\n",
    "    nlp = get_nlp()\n",
    "    return nlp(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91067b-c66d-48d8-9395-c01e4e3b299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "df[\"clean_text\"] = df[\"tweet_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587c92f-07ff-49a2-b77d-607d300bc0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>group</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-31 02:08:31</td>\n",
       "      <td>2020sucks trumpisscar ihateithere wearamask</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>#2020sucks #trumpisscar #ihateithere #wearamas...</td>\n",
       "      <td>promask</td>\n",
       "      <td>#2020sucks #trumpisscar #ihateithere #wearamas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-31 02:07:58</td>\n",
       "      <td>antimasker antimasking DOJ pandemic</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>This is probably one of the most ridiculous of...</td>\n",
       "      <td>promask</td>\n",
       "      <td>this is probably one of the most ridiculous of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-31 02:07:28</td>\n",
       "      <td>wearamask maskuphoosiers</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>Just, like, do it. #wearamask #maskuphoosiers ...</td>\n",
       "      <td>promask</td>\n",
       "      <td>just, like, do it. #wearamask #maskuphoosiers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>2020-08-31 02:03:58</td>\n",
       "      <td>COVID19 covidhoax</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>6% Of all #COVID19 Deaths were from just the v...</td>\n",
       "      <td>antimask</td>\n",
       "      <td>6% of all #covid19 deaths were from just the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>2020-08-31 02:03:35</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>#COVID19 is a hoax.  Fuck masks. If you don’t ...</td>\n",
       "      <td>antimask</td>\n",
       "      <td>#covid19 is a hoax.  fuck masks. if you don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>2020-08-31 02:02:55</td>\n",
       "      <td>COVID19 CovidHoax</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>@ProfPCDoherty There was no need to shut the b...</td>\n",
       "      <td>antimask</td>\n",
       "      <td>@profpcdoherty there was no need to shut the b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_date                                     hashtags  \\\n",
       "0     2020-08-31 02:08:31  2020sucks trumpisscar ihateithere wearamask   \n",
       "1     2020-08-31 02:07:58          antimasker antimasking DOJ pandemic   \n",
       "2     2020-08-31 02:07:28                     wearamask maskuphoosiers   \n",
       "5000  2020-08-31 02:03:58                            COVID19 covidhoax   \n",
       "5001  2020-08-31 02:03:35                                      COVID19   \n",
       "5002  2020-08-31 02:02:55                            COVID19 CovidHoax   \n",
       "\n",
       "      num_hashtags  tweet_length  \\\n",
       "0                4            90   \n",
       "1                4           137   \n",
       "2                2            69   \n",
       "5000             2           125   \n",
       "5001             1           140   \n",
       "5002             2           148   \n",
       "\n",
       "                                             tweet_text     group  \\\n",
       "0     #2020sucks #trumpisscar #ihateithere #wearamas...   promask   \n",
       "1     This is probably one of the most ridiculous of...   promask   \n",
       "2     Just, like, do it. #wearamask #maskuphoosiers ...   promask   \n",
       "5000  6% Of all #COVID19 Deaths were from just the v...  antimask   \n",
       "5001  #COVID19 is a hoax.  Fuck masks. If you don’t ...  antimask   \n",
       "5002  @ProfPCDoherty There was no need to shut the b...  antimask   \n",
       "\n",
       "                                             clean_text  \n",
       "0     #2020sucks #trumpisscar #ihateithere #wearamas...  \n",
       "1     this is probably one of the most ridiculous of...  \n",
       "2     just, like, do it. #wearamask #maskuphoosiers ...  \n",
       "5000  6% of all #covid19 deaths were from just the v...  \n",
       "5001  #covid19 is a hoax.  fuck masks. if you don’t ...  \n",
       "5002  @profpcdoherty there was no need to shut the b...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "df.groupby('group').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7712bc-9971-4895-aad5-0a9858513a93",
   "metadata": {},
   "source": [
    "## Preface - Distributional Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d21d6-472c-420a-ad2c-02f338719104",
   "metadata": {},
   "source": [
    "Section A on word association patterns will introduce measures that are not intended to be part of your EDA project. Instead, it sets up how we use statistics to tease out patterns in language. These patterns are the thread that connect linguistic analysis, to traditional NLP, to  modern LLMs. We'll come back to the same statistical principles repeatedly through this course. \n",
    "\n",
    "**Association patterns** make explicit distributional analysis at a very local level. **Distributional analysis** rest on a single, core idea: *A word's meaning (or function) is reflected in how it is distributed across contexts.* Two groups may share the use of a set of words, and yet those words take on different meaning in different contexts.\n",
    "\n",
    "For example, in the promask context: 'mask' occurs with words such as protect, safe, others, community, health. In the antimask context, it appears with words such as forced, control, lie, hoax, freedom. Although both groups use the word “mask” frequently, its meaning is shaped by the associative context in which it appears. Neither is right nor wrong -- this is an observation about how language is used... which is observable in the data. **Meaning is not just about which words are used, but about the contexts in which they are used.**\n",
    "\n",
    "In section A, we'll use this idea to observe differences in how language is used between two groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69817e4b",
   "metadata": {},
   "source": [
    "## A - Word Association Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b9f837",
   "metadata": {},
   "source": [
    "Before we move on to playing with other spaCy pipeline capabilities on this data, let's talk about the utility of **word associations** to reveal patterns in data. These techniques are used to reveal patterns in language. Very similar statistical methods are used to build word embeddings, which we'll explore soon. Embeddings are a key tool for LLMs. \n",
    "\n",
    "What I hope you draw from this is that we have more tools at our disposal for looking at patterns in language data when it comes to squishy questions around the **social use** of language such as attitude, opinion, ideology, power, etc. If statistics excites you, this is an interesting area of study and could be valuable tool in investigative journalism, mental health, social justice, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43171392",
   "metadata": {},
   "source": [
    "At the heart of of statistical methods for studying language use is co-occurence and frequencies of words and word patterns. \n",
    "\n",
    "A basic way to study **co-occurrence patterns** is through **bigrams**, which are adjacent pairs of tokens. Bigrams define what counts as a co-occurrence.\n",
    "\n",
    "Once we have bigram counts, we can ask whether two tokens appear together more often than we would expect by chance, given their individual frequencies. \n",
    "\n",
    "The underlying assumption is token independence: if two words are unrelated, the probability of seeing them together should be predictable from their unigram frequencies. Association measures test departures from this assumption. Thus association measures evaluate whether that co-occurence is statistically meaningful. \n",
    "\n",
    "Statistical such as Pointwise Mutual Information (PMI), t-score, or log-likelihood quantify this likelihood of association by comparing observed bigram frequencies to expected frequencies under an independence assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971191c-ca84-45e6-89bd-b6a104ca4580",
   "metadata": {},
   "source": [
    "While this lab is too long to go into depth about any of these inferential techniques, let's focus on normalizing our frequencies and incorporate sampling. If your data set is large, this is what you will need to do. Below, we'll reduce the number of documents to 1000. Sampling is a great way to work out ideas before you do a full analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163e5f4-4749-4483-a94b-3cc1f067f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "nlp = get_nlp()\n",
    "\n",
    "df[\"token_count\"] = df[\"clean_text\"].apply(\n",
    "    lambda text: len(\n",
    "        [tok for tok in nlp(text) if not tok.is_space]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c03d0b-458a-41dc-a29a-2bcb524a5364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# sample rows *with* group so alignment is preserved\n",
    "MAX_DOCS = 1000\n",
    "df_s = (\n",
    "    df[[\"clean_text\", \"group\", \"token_count\"]]\n",
    "    .dropna(subset=[\"clean_text\", \"group\"])\n",
    "    .sample(n=min(MAX_DOCS, len(df)), random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "nlp = get_nlp()\n",
    "docs_s = list(nlp.pipe(df_s[\"clean_text\"], batch_size=1000))\n",
    "\n",
    "docs_promask = [d for d, g in zip(docs_s, df_s[\"group\"]) if g == \"promask\"]\n",
    "docs_antimask = [d for d, g in zip(docs_s, df_s[\"group\"]) if g == \"antimask\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17392a89-aa05-4afd-b65f-b60f3ad81e96",
   "metadata": {},
   "source": [
    "Below, let's recall how we normalize frequencies to compare patterns across groups. I played around with removing things we're less interested in for this analysis such as punctuation and spaces. Freel free to play around with this, as well! When you filter out text like this, you must report \n",
    "that you did so. There will be an effect on your both word counts and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Get word frequencies\n",
    "\n",
    "def get_word_freqs(texts):\n",
    "    freqs = Counter()\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for tok in doc:\n",
    "            if not tok.is_punct and not tok.is_space:\n",
    "                freqs[tok.text.lower()] += 1\n",
    "    return freqs\n",
    "nlp = get_nlp()\n",
    "promask_freqs = get_word_freqs(df[df['group']=='promask']['clean_text'])\n",
    "antimask_freqs = get_word_freqs(df[df['group']=='antimask']['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Let's compare by frequency by normalizing per 1000 tokens\n",
    "\n",
    "# Get totals first\n",
    "total_promask = sum(promask_freqs.values())\n",
    "total_antimask = sum(antimask_freqs.values())\n",
    "\n",
    "norm_promask = {w: (f / total_promask) * 1000 for w, f in promask_freqs.items()}\n",
    "norm_antimask = {w: (f / total_antimask) * 1000 for w, f in antimask_freqs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce194c-966b-4f58-b05c-5ce76d1b3d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>rate_per_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wearamask</td>\n",
       "      <td>26.855802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>24.659245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>22.404883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>20.358617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>14.901906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>12.728471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>you</td>\n",
       "      <td>12.497254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>11.768922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>11.086833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>10.867178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mask</td>\n",
       "      <td>10.138846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for</td>\n",
       "      <td>9.595487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it</td>\n",
       "      <td>8.809350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>this</td>\n",
       "      <td>8.057897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>are</td>\n",
       "      <td>7.109909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>we</td>\n",
       "      <td>6.936496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>on</td>\n",
       "      <td>5.976948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>that</td>\n",
       "      <td>5.826657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>your</td>\n",
       "      <td>5.410467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>do</td>\n",
       "      <td>5.329541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  rate_per_1000\n",
       "0   wearamask      26.855802\n",
       "1         the      24.659245\n",
       "2          to      22.404883\n",
       "3           a      20.358617\n",
       "4         and      14.901906\n",
       "5           i      12.728471\n",
       "6         you      12.497254\n",
       "7          of      11.768922\n",
       "8          in      11.086833\n",
       "9          is      10.867178\n",
       "10       mask      10.138846\n",
       "11        for       9.595487\n",
       "12         it       8.809350\n",
       "13       this       8.057897\n",
       "14        are       7.109909\n",
       "15         we       6.936496\n",
       "16         on       5.976948\n",
       "17       that       5.826657\n",
       "18       your       5.410467\n",
       "19         do       5.329541"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    Counter(norm_promask).most_common(20),\n",
    "    columns=[\"token\", \"rate_per_1000\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741ca27-4e28-42d1-b41e-bf6fe861bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>rate_per_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>39.600619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covidhoax</td>\n",
       "      <td>29.025454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>19.040923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>18.112783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>15.609619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>14.259598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>11.897061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you</td>\n",
       "      <td>11.531430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this</td>\n",
       "      <td>11.503305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>11.137674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>are</td>\n",
       "      <td>9.872029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>9.309520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i</td>\n",
       "      <td>8.465757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>that</td>\n",
       "      <td>8.409506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>for</td>\n",
       "      <td>7.875123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>they</td>\n",
       "      <td>6.581353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>all</td>\n",
       "      <td>6.131346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>not</td>\n",
       "      <td>5.878217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we</td>\n",
       "      <td>5.681339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>have</td>\n",
       "      <td>5.343833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  rate_per_1000\n",
       "0         the      39.600619\n",
       "1   covidhoax      29.025454\n",
       "2          to      19.040923\n",
       "3          is      18.112783\n",
       "4           a      15.609619\n",
       "5          of      14.259598\n",
       "6         and      11.897061\n",
       "7         you      11.531430\n",
       "8        this      11.503305\n",
       "9          in      11.137674\n",
       "10        are       9.872029\n",
       "11         it       9.309520\n",
       "12          i       8.465757\n",
       "13       that       8.409506\n",
       "14        for       7.875123\n",
       "15       they       6.581353\n",
       "16        all       6.131346\n",
       "17        not       5.878217\n",
       "18         we       5.681339\n",
       "19       have       5.343833"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "pd.DataFrame(\n",
    "    Counter(norm_antimask).most_common(20),\n",
    "    columns=[\"token\", \"rate_per_1000\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9160a-8109-4b05-b26c-ae637c700ab6",
   "metadata": {},
   "source": [
    "The normalized word frequencies above are included to reinforce how corpus size and pre-processing affects comparisons; the **collocation statistics below rely instead on raw unigram and bigram counts**, which are required for computing association measures like PMI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d28d0-ddfb-4402-bd01-cd808b1b621c",
   "metadata": {},
   "source": [
    "Frequency tells us which words are common, but it does not tell us which words tend to appear together. Two words can be frequent without being meaningfully related. To capture relationships between words, we need to look at co-occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a530d55",
   "metadata": {},
   "source": [
    "### Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b1223",
   "metadata": {},
   "source": [
    "While comparing termlists against other term lists is interesting, let's shift to looking at the co-occurence of words with other words. The simplest way to do this is to look at bigrams. \n",
    "\n",
    "Bigrams in our context are **pairs of words or tokens**. Here's an example below. We'll need to use bigrams and unigrams (single word/token frequencies) for some of the statistics below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61549e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n",
      "[('I', 'love'), ('love', 'wearing'), ('wearing', 'masks')]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "nlp = get_nlp()\n",
    "doc = nlp(\"I love wearing masks\")\n",
    "bigrams = [(doc[i].text, doc[i+1].text) for i in range(len(doc)-1)]\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584eae",
   "metadata": {},
   "source": [
    "**Collocations** are sequences of words that co-occur unusually frequently and that, over time, start to take on a meaning or a salience that resists the token sequence being broken down into its individual parts. \n",
    "\n",
    "Often words that start off as collocations become increasingly fixed as lexical items, especially when they are used with great frequency. This process is called **lexicalization**. \n",
    "\n",
    "For example, as noun-noun collocations such as 'ice chest', 'data base' or 'war game' become increasingly cemented in the vocabulary of English, even native speakers pause to wonder 'Does ice-chest have a hyphen? Is database all one word? **That is a sign of the increasing lexicalization of the collocation.**\n",
    "\n",
    "In some cases, you can introspect about whether a collocation has a non-compositional meaning by trying to substitute it with a single synonym, such as 'cooler' for 'icechest' or 'assassin' for 'hit man' (or is that hitman?) Collocations can consist of numerous combinations of parts-of-speech, but most have in common the somewhat idiosyncratic nature of their meaning, which can exhibit differing degrees of compositionality.\n",
    "\n",
    "This is a challenge for second language learners, and websites such as 7esl devote some effort to helping people master them. For the purposes of natural language processing, when setting out to answer an analytic question with natural language data, it is important to consider whether and to what degree identifying collocations is relevant and necessary. How you treat collocations can affect everything from first order frequency counts to the quality of word embeddings, which are so widely used in contemporary machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f024203-72ba-4bbd-acc0-567bd1fc63e5",
   "metadata": {},
   "source": [
    "**n-grams** (also written **ngrams**), are collcations. We'll talk about this term many times throughout the course, because n-grams are so central to language modeling in NLP. The *n* in n-gram is meant to represent a variable of any length. The gram in n-gram is a graphical representation of some chunk of language, which might be characters, morphemes, tokens, or words. Some of the shorter n-grams have special names, such as bigram or trigram, which are 2-grams and 3-grams, respectively.\n",
    "\n",
    "Collocation measures of words are a kind of **association measure** that calculates the strength of association between words. There are many different association measures, but they all work on the same basic principle: they compare the observed frequency of a pair of words with the expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb17d0b",
   "metadata": {},
   "source": [
    "Useful to data scientists are the collocation graphs. Collocation graphs visually map which words commonly appear together in language. By treating words as nodes and their relationships as edges, they help us see patterns of meaning, usage, and discourse structure.\n",
    "\n",
    "![](images/collocation-graph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f2467",
   "metadata": {},
   "source": [
    "For collocation analysis (word associations within a corpus), these are fairly typical statistics that we can use. I won't go into how these are calculated, since this is just a demonstration. \n",
    "\n",
    "There are a number of different statistics. To choose one, you have to define the type of collocation that you are interested in. Here is a chart from page 74 in Brezina's \"Statistics in Corpus Linguistics\" book.\n",
    "\n",
    "![](images/freq-exclusivity-scale.png)\n",
    "\n",
    "This image highlights that some terms occur more frequently together, and some words predominantly occur only with one another.\n",
    "\n",
    "All of these tests start with the same idea - what gets weighted: surprise vs frequency.  They all compare observed co-occurence to expected co-occurence under independence. But they differ in how much they pernalize or reward rare events.\n",
    "\n",
    "We'll look at PMI, in particular. It's the measure up in the top left corner labeled as MI (Mutual Information).\n",
    "\n",
    "PMI answers a specific question: Are these two words appearing together more often than we would expect, given how often they appear individually?\n",
    "\n",
    "**PMI (Pointwise Mutual Information)** captures how much more likely words co-occur than by chance (strength of association). It measures how *surprising* the co-occurence of x and y are. It favors rare, but exclusive pairs. For example, a bigram occuring even once can get a very high PMI.\n",
    "\n",
    "$$\n",
    "PMI(x,y)=\\log \\frac{P(x,y)}{P(x)P(y)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876d93e-346a-4b4b-8c40-9d55b7ce6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def extract_filtered_tokens(docs):\n",
    "    return [\n",
    "        tok.text.lower()\n",
    "        for doc in docs\n",
    "        for tok in doc\n",
    "        if tok.is_alpha and not tok.is_stop\n",
    "    ]\n",
    "\n",
    "tokens_promask = extract_filtered_tokens(docs_promask)\n",
    "tokens_antimask = extract_filtered_tokens(docs_antimask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def count_bigrams(tokens):\n",
    "    \"\"\"\n",
    "    Count bigrams from a pre-filtered token sequence.\n",
    "    Assumes tokens are already lowercased, alphabetic,\n",
    "    and stopwords have been removed.\n",
    "    \"\"\"\n",
    "    return Counter(zip(tokens, tokens[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6474a89-cc64-480b-8454-4c281bec9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "bigrams_promask = count_bigrams(tokens_promask)\n",
    "bigrams_antimask = count_bigrams(tokens_antimask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7aae09-9ff1-4941-9c36-38d71ac9c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bigrams — promask\n",
      "wear mask: 35\n",
      "wearing mask: 22\n",
      "face mask: 14\n",
      "writingcommunity stayathomesavelives: 13\n",
      "stayathomesavelives wearamask: 13\n",
      "mask wearamask: 13\n",
      "wearing masks: 10\n",
      "wearamask wearadamnmask: 9\n",
      "thanks following: 8\n",
      "wearamask wearamask: 8\n",
      "\n",
      "Top 10 bigrams — antimask\n",
      "covidhoax plandemic: 10\n",
      "plandemic covidhoax: 7\n",
      "covid covidhoax: 6\n",
      "covidhoax covidhoax: 6\n",
      "covidhoax forced: 5\n",
      "forced quarantine: 5\n",
      "quarantine camps: 5\n",
      "camps operating: 5\n",
      "operating bc: 5\n",
      "bc canada: 5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "print(\"Top 10 bigrams — promask\")\n",
    "for (w1, w2), c in bigrams_promask.most_common(10):\n",
    "    print(f\"{w1} {w2}: {c}\")\n",
    "\n",
    "print(\"\\nTop 10 bigrams — antimask\")\n",
    "for (w1, w2), c in bigrams_antimask.most_common(10):\n",
    "    print(f\"{w1} {w2}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbd2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def count_unigrams(tokens):\n",
    "    \"\"\"\n",
    "    Count unigrams from a pre-filtered token sequence.\n",
    "    Must match the token criteria used for bigrams.\n",
    "    \"\"\"\n",
    "    return Counter(tokens)\n",
    "\n",
    "# Unigrams derived from the SAME tokens as bigrams\n",
    "unigrams_promask = count_unigrams(tokens_promask)\n",
    "unigrams_antimask = count_unigrams(tokens_antimask)\n",
    "\n",
    "# We can test this!\n",
    "set(bigrams_promask).issubset(\n",
    "    {(w1, w2) for w1 in unigrams_promask for w2 in unigrams_promask}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('wakeup', 'lied'), 9.836839359748716, 5),\n",
       " (('trying', 'understand'), 9.421801860469873, 6),\n",
       " (('understand', 'graph'), 9.421801860469873, 6),\n",
       " (('social', 'distancing'), 9.09987376558251, 5),\n",
       " (('writingcommunity', 'stayathomesavelives'), 8.72136214232878, 13),\n",
       " (('follow', 'writingcommunity'), 8.043290237216143, 5),\n",
       " (('following', 'writingcommunity'), 7.84689302441264, 6),\n",
       " (('stay', 'safe'), 7.633899301078441, 8),\n",
       " (('thanks', 'following'), 7.438808285775562, 8),\n",
       " (('thanks', 'follow'), 7.220167999300222, 5),\n",
       " (('wearing', 'masks'), 4.894324854409477, 10),\n",
       " (('wear', 'mask'), 4.70265754339091, 35),\n",
       " (('face', 'masks'), 4.608020669252835, 6),\n",
       " (('wearing', 'mask'), 4.557897189826999, 22),\n",
       " (('face', 'mask'), 4.3564819022568715, 14),\n",
       " (('stayathomesavelives', 'wearamask'), 4.046762429122948, 13),\n",
       " (('people', 'wearing'), 3.926746332101854, 5),\n",
       " (('wear', 'masks'), 3.6322682154995127, 6),\n",
       " (('wearamask', 'wearadamnmask'), 3.516247712424168, 9),\n",
       " (('people', 'wear'), 3.4016552873580963, 5)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_pmi(bigram_counts, unigram_counts, min_freq=5):\n",
    "    \"\"\"\n",
    "    Calculate PMI for bigrams given aligned unigram counts.\n",
    "    Assumes both were derived from the same token stream.\n",
    "    \"\"\"\n",
    "    N = sum(bigram_counts.values())\n",
    "    results = []\n",
    "\n",
    "    for (w1, w2), count in bigram_counts.items():\n",
    "        if count >= min_freq and w1 in unigram_counts and w2 in unigram_counts:\n",
    "            pmi = math.log2(\n",
    "                (count * N) / (unigram_counts[w1] * unigram_counts[w2])\n",
    "            )\n",
    "            results.append(((w1, w2), pmi, count))\n",
    "\n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Calculate PMI using the already-aligned counts\n",
    "pmi_promask = calculate_pmi(\n",
    "    bigrams_promask,\n",
    "    unigrams_promask,\n",
    "    min_freq=5\n",
    ")\n",
    "\n",
    "pmi_promask[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0defa-b40f-4866-bda6-8dd8800220de",
   "metadata": {},
   "source": [
    "Recall PMI is driven by exclusivity... which are the terms that nearly always occur with one another? 'Wakeup' might occur infrequently, but when it does it appears next to lied (e.g., \"wakeup, you've been lied to.\" Since we've removed stop words -- the proximity of these two words is more apparent.\n",
    "\n",
    "The highest-PMI pairs are not necessarily the most frequent or the most important topics. Instead, they often reveal formulaic or slogan-like language—phrases that occur rarely, but almost always together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37900f50-be46-4de3-8cbb-027066834bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('writingcommunity', 'stayathomesavelives'), 8.72136214232878, 13),\n",
       " (('stay', 'safe'), 7.633899301078441, 8),\n",
       " (('thanks', 'following'), 7.438808285775562, 8),\n",
       " (('wearing', 'masks'), 4.894324854409477, 10),\n",
       " (('wear', 'mask'), 4.70265754339091, 35),\n",
       " (('wearing', 'mask'), 4.557897189826999, 22),\n",
       " (('face', 'mask'), 4.3564819022568715, 14),\n",
       " (('stayathomesavelives', 'wearamask'), 4.046762429122948, 13),\n",
       " (('wearamask', 'wearadamnmask'), 3.516247712424168, 9),\n",
       " (('mask', 'wearamask'), 0.7814178626019529, 13),\n",
       " (('wearamask', 'wearamask'), -1.328277002223977, 8)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "pmi_promask = calculate_pmi(\n",
    "    bigrams_promask,\n",
    "    unigrams_promask,\n",
    "    min_freq=8\n",
    ")\n",
    "\n",
    "pmi_promask[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2abab8-8451-4b5e-86bf-1b1163007369",
   "metadata": {},
   "source": [
    "You can play with min_freq to see how it changes as you increase and decrease it. Because we're working with a small sample of texts, we don't see quite as much as we might on the full corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b6e67",
   "metadata": {},
   "source": [
    "Lest you think we must rely on sophisticated NLP *tools* using for studying study language use - here are a couple of examples using sophisticated *statistical methods* to study language use.\n",
    "\n",
    "1. Islentyeva (2023) — [British Media Representations of EU Migrants](https://www.lancaster.ac.uk/fass/journals/cadaad/wp-content/uploads/2023/06/Islentyeva.pdf?utm_source=chatgpt.com)\n",
    "\n",
    "A corpus-assisted analysis of two specialised corpora (500 articles each) across mainstream British newspapers before and after the Brexit referendum.\n",
    "\n",
    "It traces linguistic patterns and ideological bias in how European migrants were discussed, noting differences between left- and right-leaning outlet\n",
    "\n",
    "2. Gabrielatos & Baker et al. (2006/2007) — [Tabloids vs. Broadsheets on Immigration](https://www.researchgate.net/publication/261708737_Representation_of_refugees_and_asylum_seekers_in_UK_newspapers_Towards_a_corpus-based_comparison_of_the_stance_of_tabloids_and_broadsheets)\n",
    "\n",
    "Work presented at CADAAD 2006 and in later publications explores how refugees, asylum seekers, and immigrants are framed in UK newspapers, with a focus on contrasting broadsheets vs. tabloids.\n",
    "\n",
    "The project uses collocation and frequency analysis within a corpus framework to quantify differences in stance and lexical choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd183c5e-41bf-4336-b57a-dcdfd35a9b40",
   "metadata": {},
   "source": [
    "### Word Associations Summary\n",
    "\n",
    "- **Bigrams operationalize co-occurrence**, giving us a concrete unit for studying how words appear together in text.\n",
    "- **Association measures** compare observed vs. expected frequencies under an assumption of independence, allowing us to distinguish meaningful patterns from chance.\n",
    "- PMI emphasizes surprise and exclusivity, often surfacing rare but rhetorically distinctive phrases or slogans. \n",
    "- No single measure is “correct” -- interpretation depends on the analytic goal.\n",
    "\n",
    "In a couple of weeks, we'll see that word embeddings implicitly learn both surprise and frequency signals at once and internalize these patterns across contexts. This allows them to generalize beyond fixed bigrams/trigrams... and as a result, they can recognize meaningful associations even when rare, indirect, or distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbea7e",
   "metadata": {},
   "source": [
    "## B - Parts-of-Speech Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68318dd3",
   "metadata": {},
   "source": [
    "So far, we’ve treated text primarily as sequences of tokens, asking which words tend to appear together and how strongly those associations depart from chance. Another way to surface structure in language is to step back from which words are used and look instead at how grammatical resources are distributed. **It's not only \"words\" or tokens that have distributional patterns -- grammatical categories do, too!**\n",
    "\n",
    "This is where linguistic annotation—specifically part-of-speech (POS) tagging—becomes useful. Rather than measuring association between specific lexical items, POS patterns let us examine higher-level distributional constructs, such as whether a group relies more on nouns versus verbs, descriptive adjectives versus evaluative ones, or personal pronouns versus impersonal constructions. In this section, we return to spaCy’s pipeline annotations to explore how grammatical patterns can complement word-level association analysis.\n",
    "\n",
    "We won't use POS for this EDA because it is not reliable on Twitter data. Tweets contain nonstandard spelling, emojis, hashtags, and fragmented syntax, which fall outside the data most POS taggers are trained on.\n",
    "\n",
    "The spaCy POS tagger was primarily trained on newswire, magazines, blogs and other well formed, and cleaned texts. If your EDA is centered on this sort of text, POS may be useful in your EDA.\n",
    "\n",
    "POS can be useful for examining:\n",
    "- NOUN density. How much is information-heavy vs opinion-heavy\n",
    "- ADJ frequency. Evaluative language\n",
    "- PRON patterns. Personal involvement\n",
    "\n",
    "First, we'll take a peek at how compute a POS distribution. Then we will play around with modal verbs. I hope that exploring patterns via POS gives you ideas about how to use these sorts of annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce538744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_pos_distribution(texts, nlp, allowed_pos=None):\n",
    "    \"\"\"\n",
    "    Compute normalized POS tag distribution using batched spaCy processing.\n",
    "    \"\"\"\n",
    "    if allowed_pos is None:\n",
    "        allowed_pos = {\n",
    "            \"NOUN\", \"PROPN\", \"VERB\", \"ADJ\", \"ADV\",\n",
    "            \"PRON\", \"DET\", \"ADP\", \"AUX\"\n",
    "        }\n",
    "\n",
    "    pos_counts = Counter()\n",
    "\n",
    "    for doc in nlp.pipe(texts, batch_size=1000):\n",
    "        for tok in doc:\n",
    "            if tok.pos_ in allowed_pos:\n",
    "                pos_counts[tok.pos_] += 1\n",
    "\n",
    "    total = sum(pos_counts.values())\n",
    "    return {pos: count / total for pos, count in pos_counts.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2ce17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NOUN': 0.31143695766415874,\n",
       "  'ADP': 0.08735051718171215,\n",
       "  'PROPN': 0.11481818531383381,\n",
       "  'PRON': 0.10053961214575936,\n",
       "  'AUX': 0.0600751099091247,\n",
       "  'ADV': 0.04566836283469411,\n",
       "  'DET': 0.06581730091387995,\n",
       "  'ADJ': 0.07186710929388995,\n",
       "  'VERB': 0.14242684474294723},\n",
       " {'NOUN': 0.2847861563568064,\n",
       "  'ADP': 0.08756966468577762,\n",
       "  'PRON': 0.09951658096499061,\n",
       "  'AUX': 0.07383686916895034,\n",
       "  'ADV': 0.05055885703728793,\n",
       "  'DET': 0.07907134279644056,\n",
       "  'VERB': 0.13954490870462175,\n",
       "  'ADJ': 0.08430581642393079,\n",
       "  'PROPN': 0.10080980386119408})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "pos_dist_promask = get_pos_distribution(\n",
    "    df[df['group'] == 'promask']['clean_text'], nlp\n",
    ")\n",
    "\n",
    "pos_dist_antimask = get_pos_distribution(\n",
    "    df[df['group'] == 'antimask']['clean_text'], nlp\n",
    ")\n",
    "\n",
    "pos_dist_promask, pos_dist_antimask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5313f",
   "metadata": {},
   "source": [
    "Because POS tagging is noisy on Twitter, small differences should be treated as suggestive patterns, not explanations.\n",
    "\n",
    "If we're just looking at proportionality of POS, a few patterns stand out:\n",
    "\n",
    "1. **PROPN (proper nouns)** — These are slightly more frequent in promask tweets. This *could* reflects more use of named entities.\n",
    "\n",
    "2. **DET (determiners)** and **AUX (auxiliaries)** — These are slightly more frequent in antimask tweets. We don't know why, though may correlate with more declarative constructions.\n",
    "\n",
    "3. **ADV (adverbs)** and **ADJ (adjectives)** — Little differences across groups. This could suggest evaluative language is present in both groups. Evaluative language uses words and phrases to express judgment, opinion, or attitude (positive, negative, or neutral) about a topic, rather than just stating facts.\n",
    "\n",
    "POS tags capture surface grammatical categories, not meaning. On short, informal texts like tweets, POS distributions are especially sensitive to:\n",
    "- emoji and punctuation\n",
    "- hashtags and mentions\n",
    "- fragmented or non-standard syntax\n",
    "\n",
    "For our analysis of twitter data, it is best treated as contextual, and not explanatory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa580f2e",
   "metadata": {},
   "source": [
    "Now let's look at the frequency of modal verbs. **Modal verbs**\n",
    "(typically auxiliary verbs) express modality—obligation, permission, or possibility—and often signal prescriptive or normative language.\n",
    "\n",
    "We'll look at several types of modality:\n",
    "- Strong obligation: must, need to\n",
    "- Weaker obligation: should, ought to \n",
    "- Prohibition: can't, must not, shouldn't\n",
    "\n",
    "We could also consider imperative verbs (e.g., \"wear!\", \"stop!\", \"wake up!\") — they're prescriptive too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03579730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "modals = {\n",
    "    'strong': ['must', 'need', 'have'],  # \"have to\" needs special handling\n",
    "    'medium': ['should', 'ought'],\n",
    "    'weak': ['can', 'could', 'may', 'might']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c29237-e620-47dc-84a0-7edf3de31f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# build inverse mapping: lemma -> strength\n",
    "modal_to_strength = {\n",
    "    modal: strength\n",
    "    for strength, modal_list in modals.items()\n",
    "    for modal in modal_list\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b93c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'weak': 83, 'strong': 51, 'medium': 12}),\n",
       " Counter({'strong': 35, 'weak': 29, 'medium': 3}))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_modal_counts_from_docs(docs):\n",
    "    \"\"\"\n",
    "    Count modal verbs from pre-parsed spaCy Docs.\n",
    "    Restricts to AUX tokens to avoid false positives.\n",
    "    \"\"\"\n",
    "    modal_counts = Counter()\n",
    "\n",
    "    for doc in docs:\n",
    "        for tok in doc:\n",
    "            if tok.pos_ == \"AUX\":\n",
    "                strength = modal_to_strength.get(tok.lemma_.lower())\n",
    "                if strength:\n",
    "                    modal_counts[strength] += 1\n",
    "\n",
    "    return modal_counts\n",
    "\n",
    "modals_promask = get_modal_counts_from_docs(docs_promask)\n",
    "modals_antimask = get_modal_counts_from_docs(docs_antimask)\n",
    "\n",
    "modals_promask, modals_antimask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3998f1-74b2-454c-9bd3-7d5931b6a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 286)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "len(docs_promask), len(docs_antimask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d3f62-2d00-478b-8809-0b2e667e8549",
   "metadata": {},
   "source": [
    "Because the two groups contain different numbers of tweets and tokens, raw counts are not directly comparable. To account for corpus size, we normalize modal counts per 1,000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c4d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.3320266562132494), np.float64(5.868544600938967))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Normalized modal rates per 1000 tokens (same sample as modal counts)\n",
    "total_promask_tokens = df_s[df_s[\"group\"] == \"promask\"][\"token_count\"].sum()\n",
    "total_antimask_tokens = df_s[df_s[\"group\"] == \"antimask\"][\"token_count\"].sum()\n",
    "\n",
    "rate_strong_promask = modals_promask.get(\"strong\", 0) / total_promask_tokens * 1000\n",
    "rate_strong_antimask = modals_antimask.get(\"strong\", 0) / total_antimask_tokens * 1000\n",
    "\n",
    "rate_strong_promask, rate_strong_antimask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ec6d3-ccf2-477d-9b94-f538dc037c26",
   "metadata": {},
   "source": [
    "Modal verbs appear in both corpora, which tells us that normative and possibility-oriented language is common across the discourse. When normalized by token count, strong modals (e.g. must, need (to), have (to)) occur more frequently in antimask tweets. \n",
    "\n",
    "We can only make a cautious interpretation without pulling out KWIC and studying these tweets by eye - possibly, they represent more prescriptive framing. This sort of analysis could go into an EDA, though you can draw no conclusions without carefully examining the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ad42e",
   "metadata": {},
   "source": [
    "## C - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ba79e",
   "metadata": {},
   "source": [
    "So far, we’ve used token counts, collocations, and POS patterns to surface lexical and grammatical regularities in the corpus. Another common way to structure text analytically is to identify named entities—mentions of people, organizations, locations, and other real-world referents. This is the goal of Named Entity Recognition (NER).\n",
    "\n",
    "As with POS tagging, spaCy’s NER component was trained primarily on edited, well-formed text, not social media, so we should expect noisy and imperfect results on Twitter data. Nonetheless, examining entity types and co-occurrence patterns is still useful for understanding what kinds of actors and institutions are being referenced and for practicing how entity-based analyses are performed. In this section, we briefly explore NER as another surface-level annotation that complements earlier frequency and association analyses.\n",
    "\n",
    "Some patterns we might be interested in:\n",
    " \n",
    "Aggregate across corpus\n",
    "- PERSON mentions (authorities, politicians, scientists)\n",
    "- ORG mentions (CDC, WHO, government agencies)\n",
    "- GPE (locations - local vs. national vs. international framing)\n",
    "- DATE (temporal framing differences)\n",
    "\n",
    "How well might we be able to detect people mentions?\n",
    "\n",
    "How well might we be able to find interesting patterns of co-occurence of entities?\n",
    "    - Which entities appear together in tweets?\n",
    "    - Example: \"Fauci\" + \"lie\" vs. \"Fauci\" + \"expert\"\n",
    "    - Simple co-occurrence matrix for top 10 entities\n",
    "\n",
    "Later, we will talk about how must evaluate the quality of NER. For now, let's just practice using it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model 'en_core_web_sm' loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('PERSON', 2304),\n",
       "  ('CARDINAL', 1891),\n",
       "  ('ORG', 1698),\n",
       "  ('DATE', 911),\n",
       "  ('MONEY', 818),\n",
       "  ('GPE', 671),\n",
       "  ('NORP', 211),\n",
       "  ('TIME', 142),\n",
       "  ('PRODUCT', 112),\n",
       "  ('ORDINAL', 92)],\n",
       " [('PERSON', 943),\n",
       "  ('ORG', 858),\n",
       "  ('CARDINAL', 654),\n",
       "  ('PRODUCT', 528),\n",
       "  ('MONEY', 296),\n",
       "  ('GPE', 291),\n",
       "  ('DATE', 273),\n",
       "  ('NORP', 155),\n",
       "  ('PERCENT', 78),\n",
       "  ('ORDINAL', 35)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# We'll speed this up by disabling a few components since we're only looking at entity types\n",
    "\n",
    "def get_entity_types(texts, nlp):\n",
    "    ent_counts = Counter()\n",
    "    for doc in nlp.pipe(\n",
    "    texts,\n",
    "    batch_size=1000,\n",
    "    disable=[\"tagger\", \"parser\", \"lemmatizer\"]\n",
    "):\n",
    "        ent_counts.update(ent.label_ for ent in doc.ents)\n",
    "    return ent_counts\n",
    "\n",
    "ents_promask = get_entity_types(\n",
    "    df[df[\"group\"] == \"promask\"][\"tweet_text\"],\n",
    "    nlp\n",
    ")\n",
    "\n",
    "nlp = get_nlp()\n",
    "ents_antimask = get_entity_types(\n",
    "    df[df[\"group\"] == \"antimask\"][\"tweet_text\"],\n",
    "    nlp\n",
    ")\n",
    "ents_promask.most_common(10), ents_antimask.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc47575-77e4-42c0-b89e-06cce837dd6d",
   "metadata": {},
   "source": [
    "We use [nlp.pipe()](https://spacy.io/usage/processing-pipelines#section-pipelines) rather than calling nlp(text) in a loop because spaCy is optimized for batch processing. On larger datasets, this can reduce runtime by an order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5320de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def get_entities_by_type(texts, ent_type, nlp):\n",
    "    ents = Counter()\n",
    "    for doc in nlp.pipe(\n",
    "        texts,\n",
    "        batch_size=1000,\n",
    "        disable=[\"tagger\", \"parser\", \"lemmatizer\"]\n",
    "    ):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == ent_type:\n",
    "                ents[ent.text] += 1\n",
    "    return ents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da892fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CovidHoax', 87),\n",
       " ('CDC', 50),\n",
       " ('COVIDIOTS', 19),\n",
       " ('BC Canada', 16),\n",
       " ('COVIDHOAX', 15),\n",
       " ('NHS', 12),\n",
       " ('NEVER', 9),\n",
       " ('COVID-19', 8),\n",
       " ('Trump', 7),\n",
       " ('MSM', 7),\n",
       " ('BBC', 6),\n",
       " ('NFL', 6),\n",
       " ('Plandemic', 6),\n",
       " ('BS', 5),\n",
       " ('RNC', 5),\n",
       " ('CovidHoax &', 4),\n",
       " ('UN', 4),\n",
       " ('BLM', 4),\n",
       " ('NJ', 4),\n",
       " ('the W H O  wanna', 4)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "get_entities_by_type(\n",
    "    df[df['group'] == 'promask']['tweet_text'],\n",
    "    'ORG',\n",
    "    nlp\n",
    ").most_common(20),\n",
    "\n",
    "get_entities_by_type(\n",
    "    df[df['group'] == 'antimask']['tweet_text'],\n",
    "    'ORG',\n",
    "    nlp\n",
    ").most_common(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cecd23-8c45-4f9e-a941-8cee6f8fcda5",
   "metadata": {},
   "source": [
    "### Interpreting these results\n",
    "\n",
    "The NER analysis provides a coarse, descriptive view of referential structure, rather than a reliable account of who or what is being discussed in detail. At an aggregate level, spaCy’s NER surfaces broad patterns—such as the prominence of PERSON, ORG, GPE, and DATE mention. However, on Twitter data the results are noisy and unstable at the token level. Hashtags, emojis, creative spellings, and slogans seem to be misclassified as entities.\n",
    "\n",
    "While potentially interesting, this exploratory analysis is not particularly revealing about stance, irony, causality, or implied meaning. Differences should be interpreted as *descriptive patterns*, not explanations. \n",
    "\n",
    "We include NER here not because it performs well on Twitter, but because it is a standard NLP technique that illustrates where classical annotation begins to break down. The main lesson here is not what entities are mentioned, but how brittle entity-based analysis becomes in informal, ideological discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04ff04",
   "metadata": {},
   "source": [
    "### Reflection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e6cc8",
   "metadata": {},
   "source": [
    "1. What aspects of linguistic variety were detectable using word frequency, corpus statistics, and spaCy’s rule-based or statistical methods? What kinds of variation were not well captured?\n",
    "\n",
    "2. Based on examples from our EDA this week and last, what analytical tasks might best suited to:\n",
    "- Corpus statistics (e.g., frequency, dispersion, collocations)?\n",
    "- Classical NLP methods (rules, POS tagging, NER)?\n",
    "\n",
    "Explain why each method is appropriate for those tasks, and give at least one concrete example that you can extrapolate from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57e108-d354-49aa-b9f0-26725e03779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_answer = \"What aspects of variety were we able to detect with statistical methods or spaCy classical NLP methods? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed369c0-a73e-432a-9819-924f63f306b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_answer = \"What tasks might benefit from corpus statistics methods vs classical NLP methods?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e522ecd",
   "metadata": {},
   "source": [
    "## D - LLM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d6de7f-b615-49f9-8fc3-17325c3abec6",
   "metadata": {},
   "source": [
    "Up to this point, we’ve relied on corpus statistics and spaCy’s linguistic annotations to surface patterns in word choice, grammatical structure, and reference. These methods scale well, are transparent, and make their assumptions explicit—but they also operate largely at the level of surface form. As we’ve seen, they struggle with phenomena that depend on broader context, such as sarcasm, irony, implied stance, emoji usage, and the internal semantics of hashtags.\n",
    "\n",
    "Large Language Models (LLMs) approach text from a different angle. Rather than counting or labeling isolated units, they model language as a conditional sequence, integrating information across entire utterances and drawing on patterns learned from massive amounts of prior text. This allows them to infer pragmatic meaning, ideological signals, and non-literal usage that classical methods leave opaque. In this section, we explore what LLM-based analysis can reveal about this same dataset—and how its strengths complement, rather than replace, the methods we’ve used so far.\n",
    "\n",
    "Classical NLP excels at counting and labeling what is explicit; LLMs excel at inferring what is implicit and contextual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902130e2",
   "metadata": {},
   "source": [
    "### D.1 - Hashtags\n",
    "\n",
    "Hashtags are interesting and linguistically odd:\n",
    "- No spaces: #CovidIsntReal\n",
    "- Mixed case semantics: #wearAMask vs #WearAMask vs #WEARAMASK\n",
    "- Compound meanings: #DoYourOwnResearch (literal + ideological signal)\n",
    "- Emoji integration: #MaskUp😷 or #NoMasks🙅‍♂️\n",
    "- Sarcasm markers: #TrustTheScience (could be genuine or mocking)\n",
    "\n",
    "Could we create custom functions to break hashtags into words? With some effort and degree of error, yes. As it stands, spaCy treats hashtags as proper nouns, doesn't parse internal structure, and can't interpret emoji semantics. POS won't help us much... nor will NER or spaCy dependency parsing. Let's see what an LLM can tell us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962aa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#                    SYM        #\n",
      "DoYourOwnResearch    NOUN       doyourownresearch\n",
      "🐑                    NOUN       🐑\n",
      "#                    SYM        #\n",
      "WakeUp               PROPN      WakeUp\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Example tweets illustrating how hashtags and emoji carry meaning\n",
    "# that classical NLP struggles to represent\n",
    "\n",
    "doc = nlp(\"#DoYourOwnResearch 🐑 #WakeUp\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:20} {token.pos_:10} {token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"#DoYourOwnResearch 🐑 #WakeUp Don't let them tell you what to think\",\n",
    "    \n",
    "    \"Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️\",\n",
    "    \n",
    "    \"#TrustTheScience right into the grave 💀 #CovidHoax\",\n",
    "    \n",
    "    \"My freedoms > your fears 🇺🇸 #NoMasks #LiveFree or don't idc\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ea353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Tweet Analysis\n",
       "\n",
       "## Tweet 1: \"#DoYourOwnResearch 🐑 #WakeUp Don't let them tell you what to think\"\n",
       "\n",
       "**#DoYourOwnResearch**\n",
       "- *Literal meaning:* Conduct independent investigation\n",
       "- *Ideological signal:* Anti-establishment, skepticism of mainstream sources/authorities\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* Commonly associated with conspiracy-adjacent communities; implies mainstream information is unreliable\n",
       "\n",
       "**#WakeUp**\n",
       "- *Literal meaning:* Become alert/aware\n",
       "- *Ideological signal:* Suggests others are \"asleep\" to hidden truths; positions speaker as enlightened\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* Classic conspiratorial framing; implies special knowledge\n",
       "\n",
       "**🐑 (sheep emoji)**\n",
       "- *Signal:* Calls others \"sheep\" for following mainstream guidance\n",
       "- *Tone:* Sincere contempt/superiority\n",
       "- *Reasoning:* Dehumanizing language for perceived conformists\n",
       "\n",
       "**Overall Profile:** Anti-establishment, libertarian/populist right, contrarian identity\n",
       "\n",
       "---\n",
       "\n",
       "## Tweet 2: \"Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️\"\n",
       "\n",
       "**#WearAMask**\n",
       "- *Literal meaning:* Advocacy for mask-wearing\n",
       "- *Ideological signal:* Pro-public health measures, collective responsibility\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* Positive framing (\"proud\"), supportive emoji\n",
       "\n",
       "**#InThisTogether**\n",
       "- *Literal meaning:* Shared experience/collective action\n",
       "- *Ideological signal:* Communitarian values, social solidarity\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* Heart emoji reinforces genuine sentiment; emphasizes community over individualism\n",
       "\n",
       "**Overall Profile:** Progressive/liberal, community-oriented, trust in institutions\n",
       "\n",
       "---\n",
       "\n",
       "## Tweet 3: \"#TrustTheScience right into the grave 💀 #CovidHoax\"\n",
       "\n",
       "**#TrustTheScience**\n",
       "- *Literal meaning:* Follow scientific consensus\n",
       "- *Ideological signal:* Mockery of pro-science messaging\n",
       "- *Tone:* **Ironic/sarcastic**\n",
       "- *Reasoning:* Paired with \"into the grave\" - subverts the typical pro-science hashtag to suggest science is dangerous\n",
       "\n",
       "**#CovidHoax**\n",
       "- *Literal meaning:* COVID-19 is fabricated/exaggerated\n",
       "- *Ideological signal:* Conspiracy theorist, pandemic denialist\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* Direct claim; skull emoji reinforces belief that official narrative is deadly\n",
       "\n",
       "**Overall Profile:** Conspiracy theorist, hard anti-establishment, possibly far-right\n",
       "\n",
       "---\n",
       "\n",
       "## Tweet 4: \"My freedoms > your fears 🇺🇸 #NoMasks #LiveFree or don't idc\"\n",
       "\n",
       "**\"My freedoms > your fears\"**\n",
       "- *Signal:* Libertarian individualism, dismissal of others' concerns\n",
       "- *Tone:* Sincere but aggressive\n",
       "- *Reasoning:* Mathematical notation emphasizes hierarchy of values\n",
       "\n",
       "**#NoMasks**\n",
       "- *Literal meaning:* Opposition to mask mandates\n",
       "- *Ideological signal:* Individual liberty over collective measures\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* Aligns with American flag and freedom rhetoric\n",
       "\n",
       "**#LiveFree**\n",
       "- *Literal meaning:* Live without restrictions\n",
       "- *Ideological signal:* Libertarian values; references \"Live Free or Die\"\n",
       "- *Tone:* Sincere\n",
       "- *Reasoning:* American patriotic framing\n",
       "\n",
       "**\"or don't idc\" (I don't care)**\n",
       "- *Signal:* **Ambiguous** - could be:\n",
       "  - Performative indifference (still cares about signaling)\n",
       "  - Genuine libertarian \"you do you\" \n",
       "  - Passive-aggressive dismissal\n",
       "- *Reasoning:* Contradicts the effort of posting; likely performative\n",
       "\n",
       "**Overall Profile:** Libertarian-right, individualist, American nationalism/patriotism\n",
       "\n",
       "---\n",
       "\n",
       "## Key Linguistic Patterns:\n",
       "\n",
       "**In-group signaling:** All tweets use hashtags as tribal markers rather than organizational tools\n",
       "\n",
       "**Moral framing:** \n",
       "- Tweets 1, 3, 4: Individual autonomy, anti-coercion\n",
       "- Tweet 2: Collective care, social responsibility\n",
       "\n",
       "**Emotional registers:**\n",
       "- Tweet 1: Superiority/contempt\n",
       "- Tweet 2: Pride/warmth\n",
       "- Tweet 3: Anger/mockery\n",
       "- Tweet 4: Defiance/indifference\n",
       "\n",
       "**Certainty levels:** All express high certainty despite opposing views - characteristic of polarized discourse\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-fd02e082-3092-487f-a948-86f3fe881f51`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=1131, prompt_tokens=169, total_tokens=1300, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-fd02e082-3092-487f-a948-86f3fe881f51', created=1769628225, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='# Tweet Analysis\\n\\n## Tweet 1: \"#DoYourOwnResearch 🐑 #WakeUp Don\\'t let them tell you what to think\"\\n\\n**#DoYourOwnResearch**\\n- *Literal meaning:* Conduct independent investigation\\n- *Ideological signal:* Anti-establishment, skepticism of mainstream sources/authorities\\n- *Tone:* Sincere\\n- *Reasoning:* Commonly associated with conspiracy-adjacent communities; implies mainstream information is unreliable\\n\\n**#WakeUp**\\n- *Literal meaning:* Become alert/aware\\n- *Ideological signal:* Suggests others are \"asleep\" to hidden truths; positions speaker as enlightened\\n- *Tone:* Sincere\\n- *Reasoning:* Classic conspiratorial framing; implies special knowledge\\n\\n**🐑 (sheep emoji)**\\n- *Signal:* Calls others \"sheep\" for following mainstream guidance\\n- *Tone:* Sincere contempt/superiority\\n- *Reasoning:* Dehumanizing language for perceived conformists\\n\\n**Overall Profile:** Anti-establishment, libertarian/populist right, contrarian identity\\n\\n---\\n\\n## Tweet 2: \"Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️\"\\n\\n**#WearAMask**\\n- *Literal meaning:* Advocacy for mask-wearing\\n- *Ideological signal:* Pro-public health measures, collective responsibility\\n- *Tone:* Sincere\\n- *Reasoning:* Positive framing (\"proud\"), supportive emoji\\n\\n**#InThisTogether**\\n- *Literal meaning:* Shared experience/collective action\\n- *Ideological signal:* Communitarian values, social solidarity\\n- *Tone:* Sincere\\n- *Reasoning:* Heart emoji reinforces genuine sentiment; emphasizes community over individualism\\n\\n**Overall Profile:** Progressive/liberal, community-oriented, trust in institutions\\n\\n---\\n\\n## Tweet 3: \"#TrustTheScience right into the grave 💀 #CovidHoax\"\\n\\n**#TrustTheScience**\\n- *Literal meaning:* Follow scientific consensus\\n- *Ideological signal:* Mockery of pro-science messaging\\n- *Tone:* **Ironic/sarcastic**\\n- *Reasoning:* Paired with \"into the grave\" - subverts the typical pro-science hashtag to suggest science is dangerous\\n\\n**#CovidHoax**\\n- *Literal meaning:* COVID-19 is fabricated/exaggerated\\n- *Ideological signal:* Conspiracy theorist, pandemic denialist\\n- *Tone:* Sincere\\n- *Reasoning:* Direct claim; skull emoji reinforces belief that official narrative is deadly\\n\\n**Overall Profile:** Conspiracy theorist, hard anti-establishment, possibly far-right\\n\\n---\\n\\n## Tweet 4: \"My freedoms > your fears 🇺🇸 #NoMasks #LiveFree or don\\'t idc\"\\n\\n**\"My freedoms > your fears\"**\\n- *Signal:* Libertarian individualism, dismissal of others\\' concerns\\n- *Tone:* Sincere but aggressive\\n- *Reasoning:* Mathematical notation emphasizes hierarchy of values\\n\\n**#NoMasks**\\n- *Literal meaning:* Opposition to mask mandates\\n- *Ideological signal:* Individual liberty over collective measures\\n- *Tone:* Sincere\\n- *Reasoning:* Aligns with American flag and freedom rhetoric\\n\\n**#LiveFree**\\n- *Literal meaning:* Live without restrictions\\n- *Ideological signal:* Libertarian values; references \"Live Free or Die\"\\n- *Tone:* Sincere\\n- *Reasoning:* American patriotic framing\\n\\n**\"or don\\'t idc\" (I don\\'t care)**\\n- *Signal:* **Ambiguous** - could be:\\n  - Performative indifference (still cares about signaling)\\n  - Genuine libertarian \"you do you\" \\n  - Passive-aggressive dismissal\\n- *Reasoning:* Contradicts the effort of posting; likely performative\\n\\n**Overall Profile:** Libertarian-right, individualist, American nationalism/patriotism\\n\\n---\\n\\n## Key Linguistic Patterns:\\n\\n**In-group signaling:** All tweets use hashtags as tribal markers rather than organizational tools\\n\\n**Moral framing:** \\n- Tweets 1, 3, 4: Individual autonomy, anti-coercion\\n- Tweet 2: Collective care, social responsibility\\n\\n**Emotional registers:**\\n- Tweet 1: Superiority/contempt\\n- Tweet 2: Pride/warmth\\n- Tweet 3: Anger/mockery\\n- Tweet 4: Defiance/indifference\\n\\n**Certainty levels:** All express high certainty despite opposing views - characteristic of polarized discourse', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=1131, prompt_tokens=169, total_tokens=1300, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_analyze_tweet(text, model=DEFAULT_MODEL):\n",
    "    \"Analyze tweet for hashtag semantics, ideological signals, and ambiguity\"\n",
    "\n",
    "    if not llm_available():\n",
    "        return (\n",
    "            \"Summary unavailable\\n\\n\"\n",
    "            \"• LLM disabled or unavailable\\n\"\n",
    "            \"• Skipping abstractive summarization\\n\"\n",
    "            \"• Proceeding with notebook execution\"\n",
    "        )\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this tweet for linguistic and social signals:\n",
    "\n",
    "1. \"#DoYourOwnResearch 🐑 #WakeUp Don't let them tell you what to think\"\n",
    "    \n",
    "2. \"Proud to #WearAMask 😷 Protecting my community! #InThisTogether ❤️\"\n",
    "    \n",
    "3. \"#TrustTheScience right into the grave 💀 #CovidHoax\"\n",
    "    \n",
    "4. \"My freedoms > your fears 🇺🇸 #NoMasks #LiveFree or don't idc\"\n",
    "\n",
    "For each hashtag, convey literal meaning, ideological signal, and whether it's sincere/ironic/ambiguous. Explain reasoning.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat = make_chat(model)\n",
    "        return chat(prompt)\n",
    "\n",
    "    except Exception:\n",
    "        return (\n",
    "            \"HEADLINE: Analysis unavailable\\n\\n\"\n",
    "            \"• LLM call failed\\n\"\n",
    "            \"• Safe fallback applied\"\n",
    "        )\n",
    "    \n",
    "\n",
    "llm_analyze_tweet(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb38c662-de50-42e0-96c9-55607066c2e8",
   "metadata": {},
   "source": [
    "Hashtags encode compressed semantic and ideological meaning, not just topical labels. While classical NLP treats hashtags as atomic tokens and misses the many ways in which they are used to express feelings, stance, irony, group signaling - LLMs can infer them. \n",
    "\n",
    "That said, LLM interpretations are plausible analyses, not ground truth. Unlike POS tags or frequency counts, their outputs cannot be directly validated. Claims about stance, irony, or intent should therefore be treated as hypotheses that require external validation (e.g., human annotation, inter-annotator agreement, or task-based evaluation). The value of LLM analysis here lies in sense-making and exploration, not definitive measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b8ac5",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "1. What signals were invisible to corpus stats and spaCy?\n",
    "   \n",
    "2. How do you think the LLM 'knows' that 🐑 is being used ironically here? Where does that knowledge come from? (Consider distributional information.)\n",
    "\n",
    "3. The LLM recognizes '#DoYourOwnResearch' as ideologically loaded. How do you think it learn that association? Could we build that classically?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2f64e-b6aa-4ee9-a701-0762a66bc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_answer = \"What information did LLMs infer that SpaCy components couldn't?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dfe73e-025a-4371-b9bd-c957fe0216d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_answer = \"How did the LLM know that 🐑 indicated irony?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefda74-5d1d-455d-b143-023af46c8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_answer = \"How did the LLM recognizes an association of #DoYourOwnResearch to ideology?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404cd6",
   "metadata": {},
   "source": [
    "### D.2 Stance Detection\n",
    "\n",
    "While, hashtags and emoji can signal ideology, irony, or group identity without explicitly stating a position, stance asks how a speaker positions themselves toward a target. For example, they can indicate whether they support, reject, mock, or distance themselves from an idea.**'Stance' indicates a position on a target (e.g., a topic).** \n",
    "\n",
    "Unlike sentiment, which captures positive or negative tone, stance captures a position **toward a specific target**, even when sentiment is ambiguous or ironic.\n",
    "\n",
    "Stance isn't always explicit. People signal positions through:\n",
    "- Sarcasm and irony\n",
    "- Rhetorical questions\n",
    "- Tone and affect\n",
    "\n",
    "Let's look at tweet pairs that look superficially similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83f8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Linguistic and Social Signal Analysis\n",
       "\n",
       "## Tweet 1: \"Wow, masks really work 😂\"\n",
       "\n",
       "1. **Explicit stance:** Anti-mask\n",
       "2. **Confidence level:** High\n",
       "3. **Key linguistic cues:**\n",
       "   - \"Wow\" - mock surprise/exaggeration\n",
       "   - \"really\" - intensifier used sarcastically\n",
       "   - Simple declarative flipped by context\n",
       "4. **Irony/Sarcasm:** Heavy sarcasm throughout. The speaker means the opposite of what's literally stated.\n",
       "5. **Emoji/Punctuation impact:** \n",
       "   - 😂 (laughing emoji) is crucial—transforms apparent agreement into mockery\n",
       "   - Signals the entire statement should be read ironically\n",
       "\n",
       "---\n",
       "\n",
       "## Tweet 2: \"Science says masks work. Period.\"\n",
       "\n",
       "1. **Explicit stance:** Pro-mask\n",
       "2. **Confidence level:** High\n",
       "3. **Key linguistic cues:**\n",
       "   - \"Science says\" - appeals to authority\n",
       "   - \"Period\" - conversation-ender, brooking no debate\n",
       "   - Declarative sentence structure\n",
       "4. **Irony/Sarcasm:** None. Direct, literal statement.\n",
       "5. **Emoji/Punctuation impact:**\n",
       "   - Period after \"Period\" creates finality\n",
       "   - Emphatic punctuation reinforces certainty\n",
       "   - No softening elements\n",
       "\n",
       "---\n",
       "\n",
       "## Tweet 3: \"Sure, trust the 'experts' 🙄\"\n",
       "\n",
       "1. **Explicit stance:** Anti-establishment/Anti-mask (implied)\n",
       "2. **Confidence level:** High\n",
       "3. **Key linguistic cues:**\n",
       "   - \"Sure\" - dismissive agreement (sarcastic)\n",
       "   - Scare quotes around 'experts' - delegitimizes authority\n",
       "   - Imperative verb \"trust\" used sarcastically\n",
       "4. **Irony/Sarcasm:** Strong sarcasm. \"Sure\" signals insincere agreement.\n",
       "5. **Emoji/Punctuation impact:**\n",
       "   - 🙄 (eye roll) confirms sarcastic reading\n",
       "   - Scare quotes are critical—suggest experts are fraudulent or misguided\n",
       "   - Combined effect: complete meaning reversal\n",
       "\n",
       "---\n",
       "\n",
       "## Tweet 4: \"Trust the experts. They know what they're doing.\"\n",
       "\n",
       "1. **Explicit stance:** Pro-establishment/Pro-mask (implied)\n",
       "2. **Confidence level:** High\n",
       "3. **Key linguistic cues:**\n",
       "   - Imperative \"Trust\" - direct instruction\n",
       "   - \"They know what they're doing\" - competence assertion\n",
       "   - Two reinforcing statements\n",
       "4. **Irony/Sarcasm:** None apparent. Sincere statement.\n",
       "5. **Emoji/Punctuation impact:**\n",
       "   - Standard punctuation only\n",
       "   - Absence of emoji/special punctuation suggests straightforward reading\n",
       "   - Could potentially be sarcastic without contextual cues, but default reading is sincere\n",
       "\n",
       "---\n",
       "\n",
       "## Key Comparative Observations:\n",
       "\n",
       "**Sarcasm Markers:**\n",
       "- Emojis (😂, 🙄) are the strongest sarcasm indicators\n",
       "- Scare quotes signal delegitimization\n",
       "- Words like \"Sure,\" \"Wow,\" \"really\" become sarcastic markers in context\n",
       "\n",
       "**Sincerity Markers:**\n",
       "- \"Period\" as emphatic closer\n",
       "- Absence of emojis/irony signals\n",
       "- Straightforward syntax\n",
       "\n",
       "**Critical Insight:** Tweets 1 and 3 vs. Tweets 2 and 4 show nearly identical surface content with opposite meanings—demonstrating how digital paralinguistic cues (emoji, quotes, punctuation) are essential for meaning-making in online discourse.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `chatcmpl-001d2e0e-39fb-44b5-9b5e-1ff742d9bed7`\n",
       "- model: `claude-sonnet-4-5-20250929`\n",
       "- finish_reason: `stop`\n",
       "- usage: `Usage(completion_tokens=839, prompt_tokens=157, total_tokens=996, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0)`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ModelResponse(id='chatcmpl-001d2e0e-39fb-44b5-9b5e-1ff742d9bed7', created=1769628296, model='claude-sonnet-4-5-20250929', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='# Linguistic and Social Signal Analysis\\n\\n## Tweet 1: \"Wow, masks really work 😂\"\\n\\n1. **Explicit stance:** Anti-mask\\n2. **Confidence level:** High\\n3. **Key linguistic cues:**\\n   - \"Wow\" - mock surprise/exaggeration\\n   - \"really\" - intensifier used sarcastically\\n   - Simple declarative flipped by context\\n4. **Irony/Sarcasm:** Heavy sarcasm throughout. The speaker means the opposite of what\\'s literally stated.\\n5. **Emoji/Punctuation impact:** \\n   - 😂 (laughing emoji) is crucial—transforms apparent agreement into mockery\\n   - Signals the entire statement should be read ironically\\n\\n---\\n\\n## Tweet 2: \"Science says masks work. Period.\"\\n\\n1. **Explicit stance:** Pro-mask\\n2. **Confidence level:** High\\n3. **Key linguistic cues:**\\n   - \"Science says\" - appeals to authority\\n   - \"Period\" - conversation-ender, brooking no debate\\n   - Declarative sentence structure\\n4. **Irony/Sarcasm:** None. Direct, literal statement.\\n5. **Emoji/Punctuation impact:**\\n   - Period after \"Period\" creates finality\\n   - Emphatic punctuation reinforces certainty\\n   - No softening elements\\n\\n---\\n\\n## Tweet 3: \"Sure, trust the \\'experts\\' 🙄\"\\n\\n1. **Explicit stance:** Anti-establishment/Anti-mask (implied)\\n2. **Confidence level:** High\\n3. **Key linguistic cues:**\\n   - \"Sure\" - dismissive agreement (sarcastic)\\n   - Scare quotes around \\'experts\\' - delegitimizes authority\\n   - Imperative verb \"trust\" used sarcastically\\n4. **Irony/Sarcasm:** Strong sarcasm. \"Sure\" signals insincere agreement.\\n5. **Emoji/Punctuation impact:**\\n   - 🙄 (eye roll) confirms sarcastic reading\\n   - Scare quotes are critical—suggest experts are fraudulent or misguided\\n   - Combined effect: complete meaning reversal\\n\\n---\\n\\n## Tweet 4: \"Trust the experts. They know what they\\'re doing.\"\\n\\n1. **Explicit stance:** Pro-establishment/Pro-mask (implied)\\n2. **Confidence level:** High\\n3. **Key linguistic cues:**\\n   - Imperative \"Trust\" - direct instruction\\n   - \"They know what they\\'re doing\" - competence assertion\\n   - Two reinforcing statements\\n4. **Irony/Sarcasm:** None apparent. Sincere statement.\\n5. **Emoji/Punctuation impact:**\\n   - Standard punctuation only\\n   - Absence of emoji/special punctuation suggests straightforward reading\\n   - Could potentially be sarcastic without contextual cues, but default reading is sincere\\n\\n---\\n\\n## Key Comparative Observations:\\n\\n**Sarcasm Markers:**\\n- Emojis (😂, 🙄) are the strongest sarcasm indicators\\n- Scare quotes signal delegitimization\\n- Words like \"Sure,\" \"Wow,\" \"really\" become sarcastic markers in context\\n\\n**Sincerity Markers:**\\n- \"Period\" as emphatic closer\\n- Absence of emojis/irony signals\\n- Straightforward syntax\\n\\n**Critical Insight:** Tweets 1 and 3 vs. Tweets 2 and 4 show nearly identical surface content with opposite meanings—demonstrating how digital paralinguistic cues (emoji, quotes, punctuation) are essential for meaning-making in online discourse.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'citations': None, 'thinking_blocks': None}))], usage=Usage(completion_tokens=839, prompt_tokens=157, total_tokens=996, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=0, text_tokens=None, image_tokens=None, cache_creation_tokens=0, cache_creation_token_details=CacheCreationTokenDetails(ephemeral_5m_input_tokens=0, ephemeral_1h_input_tokens=0)), cache_creation_input_tokens=0, cache_read_input_tokens=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "def llm_analyze_tweet(model=DEFAULT_MODEL):\n",
    "    \"Analyze stance and use of language and emoji\"\n",
    "\n",
    "    if not llm_available():\n",
    "        return (\n",
    "            \"Summary unavailable\\n\\n\"\n",
    "            \"• LLM disabled or unavailable\\n\"\n",
    "            \"• Skipping abstractive summarization\\n\"\n",
    "            \"• Proceeding with notebook execution\"\n",
    "        )\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this tweet for linguistic and social signals:\n",
    "   \n",
    "Tweet 1: , \"Wow, masks really work 😂\"\n",
    "\n",
    "Tweet 2: \"Science says masks work. Period.\"\n",
    "\n",
    "Tweet 3: \"Sure, trust the 'experts' 🙄\"\n",
    "\n",
    "Tweet 4: \"Trust the experts. They know what they're doing.\"\n",
    "\n",
    "For each tweet, determine:\n",
    "1. Explicit stance (pro-mask, anti-mask, neutral)\n",
    "2. Confidence level (high/medium/low)\n",
    "3. Key linguistic cues that reveal stance\n",
    "4. Any irony, sarcasm, or non-literal language\n",
    "5. How emoji/punctuation modifies meaning\"\"\"\n",
    "    \n",
    "    try:\n",
    "        chat = make_chat(model)\n",
    "        return chat(prompt)\n",
    "            \n",
    "    except Exception:\n",
    "        return (\n",
    "            \"Analysis unavailable\\n\\n\"\n",
    "            \"• LLM call failed\\n\"\n",
    "            \"• Safe fallback applied\"\n",
    "        )\n",
    "\n",
    "llm_analyze_tweet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583a078-321e-4f0d-8327-2561032e1027",
   "metadata": {},
   "source": [
    "The stance analysis illustrates what LLMs are particularly good at: integrating multiple weak signals—lexical choice, punctuation, emoji, quotation marks, and pragmatic cues—into a coherent interpretation of how a position is being taken. Tweets that appear superficially similar can express sharply different stances.\n",
    "\n",
    "That said, resuts should be read interpretively and not determinitically. The LLM is not \"detecting\" stance, but generating plausible explanations based on patterns learned over very large amounts of text. LLMs are great for exploring ideas, generating hypotheses and filling in gaps where surface-level signals break down.\n",
    "\n",
    "The stance analysis is best understood as interpretive sense-making, not a classification result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c22170",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "1. The LLM 'knows' that 😂 + positive claim often = sarcasm. How did it learn this? Could we build an ML model to detect this or encode it as a rule?\n",
    "\n",
    "2. Are these confidence levels real or simply generated patterns? How could we tell?\n",
    "\n",
    "3. How do we know the LLM is right? For spaCy, we can check POS tags manually. For stance detection, what's our ground truth?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6416df-93ae-43b4-b31d-7eded86f124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_answer = \"Could we use rules or ML to detect sarcasm?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba30fc-0883-48aa-99d7-46f624cb4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_answer = \"Are confidence levels given by an LLM real or simply generated?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30275d94-f9b0-4f6b-9e26-6f1e1b880e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_answer = \"How could we validate whether an LLM is right?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f5d20-0286-45cb-9d35-b3c1e3289266",
   "metadata": {},
   "source": [
    "## Lab Summary\n",
    "\n",
    "In this lab, you explored how different analytical approaches surface different kinds of structure in text. Using corpus statistics and spaCy’s linguistic annotations, you examined lexical patterns, word associations, grammatical distributions, and referential structure across two contrasting Twitter corpora. You saw how frequency counts, bigrams, and association measures like PMI highlight recurring and slogan-like language, while POS tagging and modal analysis offer a coarse view of grammatical and normative patterns—albeit with clear limitations on informal social media data.\n",
    "\n",
    "You also observed where classical NLP methods begin to break down. POS tagging and NER, while standard and scalable, proved noisy and brittle in the presence of hashtags, emojis, sarcasm, and fragmented syntax. In contrast, LLM-based analyses demonstrated an ability to integrate multiple weak signals—lexical choice, punctuation, emoji, and pragmatic context—to generate plausible interpretations of stance, irony, and ideological signaling. However, these interpretations remain exploratory and hypothesis-generating rather than directly verifiable.\n",
    "\n",
    "Taken together, the lab illustrates a core theme of the course: corpus statistics and classical NLP excel at transparent, scalable description of surface patterns, while LLMs excel at contextual sense-making. These tools may be complementary when combined. The goal of the reflection that follows is to help you reason about when to use each method, how they might be combined, and what kinds of linguistic insight each can—and cannot—support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addab5c7",
   "metadata": {},
   "source": [
    "## Lab Reflection \n",
    "\n",
    "In this lab reflection, I'd like you to speculate and use your intuition, even though you don't have the tools yet to understand LLMs that well yet. We'll circle back to these questions again.\n",
    "\n",
    "1. Scalability vs. depth trade-off:\n",
    "    - spaCy: 10,000 tweets, POS tags, in 10 seconds\n",
    "    - LLM: 10 tweets, deep analysis, in 30 seconds\n",
    "    - \"When do you need which?\"\n",
    "\n",
    "2. How might you combine both traditional NLP methods with LLMs?\n",
    "\n",
    "3. The LLM was trained on internet text that includes political discourse. Could it have learned political biases? How would we detect that?\n",
    "\n",
    "4. What did you find most interesting from this lab?\n",
    "  \n",
    "5. What did you find most surprising from this lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d269c2d-648f-4bf1-8749-cdabe3547ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_answer = \"For what tasks might we prefer the scalability of spaCy vs depth of an LLM?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80911c49-d5c7-4a8e-83da-0efc1fdc586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_answer = \"How might we combine traditional NLP methods with LLMs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447277f-4f11-4672-b93f-3650659a06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q8_answer = \"Could an LLM learn political biases and how could we tell?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bc762-4a5d-4e9b-9ed9-ddf913335066",
   "metadata": {},
   "outputs": [],
   "source": [
    "q9_answer = \"What did you find most interesting from this lab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e1b9c-f1d1-427f-a726-8a99138e7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_answer = \"What did you find most surprising from this lab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4365f-11d7-42b2-b0aa-9b4192a7ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# REVIEW ONLY — does not submit\n",
    "\n",
    "from data401_nlp.helpers.submit import collect_answers, parse_answers\n",
    "\n",
    "# REVIEW ONLY — does not submit\n",
    "\n",
    "raw = collect_answers(\n",
    "    show=True,\n",
    "    namespace=globals(),   \n",
    ")\n",
    "\n",
    "answers = parse_answers(raw)\n",
    "\n",
    "print(f\"\\nDetected {len(answers)} answers:\")\n",
    "for k in answers:\n",
    "    print(\" \", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4598458-a89b-4a81-97ab-3216ac3e4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "ALLOW_SUBMISSION = False   # ← student MUST change this\n",
    "\n",
    "def submit_for_credit(student_id):\n",
    "    if not ALLOW_SUBMISSION:\n",
    "        raise RuntimeError(\n",
    "            \"⚠️ Submission is disabled.\\n\\n\"\n",
    "            \"To submit:\\n\"\n",
    "            \"  1. Set ALLOW_SUBMISSION = True\\n\"\n",
    "            \"  2. Re-run this cell\"\n",
    "        )\n",
    "\n",
    "    submit_answers(\n",
    "        student_id=student_id,\n",
    "        answers=answers,   # uses reviewed answers\n",
    "    )\n",
    "\n",
    "    print(\"✅ Submission complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8fdf5-dcdd-45eb-bbcc-1aeddd3ba528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Don't forget to edit with your name\n",
    "submit_for_credit(\"your name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data401_nlp",
   "language": "python",
   "name": "data401_nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
