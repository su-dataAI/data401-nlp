{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdc4fc2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for NLP\n",
    "## Assignment Template for Intro to NLP\n",
    "\n",
    "**Objective:** Conduct a systematic exploratory data analysis (EDA) of a text classification corpus, documenting your findings in a reproducible notebook.\n",
    "\n",
    "**Why this matters:** Before building any NLP model, you need to understand your data. EDA reveals label imbalance, text length variation, data quality issues, and vocabulary patterns that directly impact modeling decisions. This assignment builds habits you'll use throughout your NLP career.\n",
    "\n",
    "---\n",
    "## Deliverables\n",
    "\n",
    "1. **Google Colab or Deepnote notebook** (.ipynb) with all code cells executed\n",
    "2. All sections below completed with **prose explanations** (not just code output)\n",
    "3. Visualizations with proper labels and titles\n",
    "\n",
    "---\n",
    "\n",
    "## Grading Rubric (Quick Reference)\n",
    "\n",
    "| Section | Complete âœ… | Partial âš ï¸ | Incomplete âŒ |\n",
    "|---------|------------|-----------|--------------|\n",
    "| 0. Summary | All 6 fields filled | Missing 1-2 fields | Missing 3+ fields |\n",
    "| 1. Dataset Card | All required items + evidence | Prose but missing table/examples | Missing source or dictionary |\n",
    "| 2. Preprocessing | Filter log + before/after examples | Log OR examples, not both | No documentation of steps |\n",
    "| 3. Core EDA | All 4 subsections with plots/tables | 2-3 subsections complete | Fewer than 2 subsections |\n",
    "| 4. Vocabulary | Top terms + interpretation | Terms listed, no interpretation | Missing entirely |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026917cb",
   "metadata": {},
   "source": [
    "---\n",
    "# Assignment Sections\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Executive Summary (Complete Last, Display First)\n",
    "\n",
    "*Fill this in after completing your analysis. This is your \"elevator pitch\" for the dataset.*\n",
    "\n",
    "| Item | Your Answer |\n",
    "|------|-------------|\n",
    "| **Dataset name** | |\n",
    "| **Task** | (e.g., binary sentiment classification) |\n",
    "| **Unit of analysis** | (e.g., movie review, tweet, news article) |\n",
    "| **Size after cleaning** | ___ documents, ___ tokens |\n",
    "| **Key finding #1** | (e.g., \"Classes are imbalanced 3:1\") |\n",
    "| **Key finding #2** | (e.g., \"Reviews range from 10 to 2,500 words\") |\n",
    "| **Recommended eval metric** | (e.g., \"Macro-F1 due to imbalance\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5d06a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Dataset Card\n",
    "\n",
    "*Document what this dataset is and where it comes from.*\n",
    "\n",
    "### 1.1 Source and Citation\n",
    "\n",
    "- **Data source name:**\n",
    "- **Collection method:**\n",
    "- **Time period covered:**\n",
    "- **Languages/locales (expected):**\n",
    "- **Citation:** (cite paper or link to official source)\n",
    "- **URL:** (Hugging Face, Kaggle, official site)\n",
    "- **License (Access conditions/ToS constraints):**\n",
    "- **Original task:**\n",
    "\n",
    "> ðŸ’¡ **Tip:** Most established datasets have a paper. Cite it. If using Hugging Face `datasets`, the citation is usually in the dataset card.\n",
    "\n",
    "### 1.2 Intended Use\n",
    "\n",
    "Answer in 2-3 sentences each:\n",
    "- What is this dataset designed for?\n",
    "- What should this dataset NOT be used for?\n",
    "- Who created it and why?\n",
    "\n",
    "### 1.3 Data Dictionary\n",
    "\n",
    "Create a table describing each field/column in the dataset:\n",
    "\n",
    "| Field | Type | Description | Example |\n",
    "|-------|------|-------------|--------|\n",
    "| `text` | string | | |\n",
    "| `label` | int/string | | |\n",
    "| ... | | | |\n",
    "\n",
    "**Required evidence:** Show 3 example rows from your dataset (truncate long text to ~100 chars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 3 example rows from your dataset\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7c726",
   "metadata": {},
   "source": [
    "### 1.4 Known Limitations\n",
    "\n",
    "Based on the dataset paper or documentation, note:\n",
    "- Any known biases (e.g., \"all reviews are from US users\")\n",
    "- Time period of collection\n",
    "- What's NOT included (e.g., \"neutral reviews were filtered out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b86de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "*Make your pipeline reproducible. Someone should be able to re-run your notebook and get identical results.*\n",
    "\n",
    "### 2.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72211771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document how you loaded the data\n",
    "# Example:\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aae09e",
   "metadata": {},
   "source": [
    "- **Raw size:** ___ train, ___ test (or total if no official split)\n",
    "- **Format:** (Hugging Face Dataset, CSV, JSON, etc.)\n",
    "\n",
    "### 2.2 Cleaning and Filtering (minimal + conservative)\n",
    "\n",
    "For each cleaning step, document:\n",
    "\n",
    "| Step | Rule | Rationale | Records Removed | % Removed |\n",
    "|------|------|-----------|-----------------|----------|\n",
    "| 1 | Remove exact duplicates | Prevent train/test leakage | | |\n",
    "| 2 | Remove empty texts | Cannot analyze empty strings | | |\n",
    "| 3 | (your step) | | | |\n",
    "| **Total** | | | | |\n",
    "\n",
    "**Required evidence:** The filter log table above, filled in with your actual numbers. 1-3 bullets describing sampling constraints (filters, empty texts, rate limits, duplicates, etc.)\n",
    "\n",
    "> ðŸ’¡ **Tip:** For well-curated datasets (IMDb, SST-2), you may find few or no records to remove. That's fineâ€”document that you checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7abb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your cleaning and filtering code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52277eff",
   "metadata": {},
   "source": [
    "### 2.3 Text Preprocessing\n",
    "\n",
    "Document your preprocessing choices:\n",
    "\n",
    "| Preprocessing Step | Applied? | Method/Tool | Rationale |\n",
    "|--------------------|----------|-------------|----------|\n",
    "| Lowercasing | Yes/No | | |\n",
    "| URL handling | Yes/No | | |\n",
    "| HTML tag removal | Yes/No | | |\n",
    "| Punctuation removal | Yes/No | | |\n",
    "| Stopword removal | Yes/No | | |\n",
    "| Tokenization | Yes/No | (which tokenizer?) | |\n",
    "| Other | | | |\n",
    "\n",
    "**Some preprocessing choices to consider:**\n",
    "\n",
    "* Over-filtering short texts (e.g., \"ok\", \"no\", \"ðŸ˜­\")\n",
    "* Stripping punctuation/emoji/hashtags (may erase meaning)\n",
    "* Removing URLs/handles (may remove domain signal)\n",
    "* Dedup choices (templates/retweets might be meaningful)\n",
    "* Casefold() or .lower() (may lose acronyms/proper nouns). Casefold handles more edge-cases, but both are appropriate.\n",
    "* Unicode normalization (NFKC) to collapse visually different forms (e.g., quotes)\n",
    "* Whitespace normalization (collapse multiple spaces/newlines) so length stats arenâ€™t inflated.\n",
    "\n",
    "For this EDA, you only need to do what SpaCy lets you do. Below is an example of lowercasing and whitespace compression. \n",
    "\n",
    "If you feel confident that you can add other things such as unicode normalization, and wish to do so, please do!\n",
    "\n",
    "**What you decided to do and why:**\n",
    "- (e.g., I did normalization for casefolding, unicode, and whitespace to remove noise. I didn't strip punctuation or emojis because it might change the meaning.)\n",
    "\n",
    "**Required evidence:** Show before/after for 3 documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show before/after for 3 documents\n",
    "# Example structure:\n",
    "# for i in range(3):\n",
    "#     print(f\"BEFORE: {original_texts[i][:200]}...\")\n",
    "#     print(f\"AFTER:  {processed_texts[i][:200]}...\")\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7285fd5",
   "metadata": {},
   "source": [
    "### 2.4 Ethical + Legal Notes\n",
    "\n",
    "* **PII/sensitive content present?** \n",
    "* **De-identification steps (if any):** \n",
    "* **Known/suspected biases/skews:** \n",
    "* **Usage restrictions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfa842",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Core EDA\n",
    "\n",
    "*These analyses are required for every text classification dataset.*\n",
    "\n",
    "### 3.1 Dataset Size and Missingness\n",
    "\n",
    "After all cleaning:\n",
    "- **Total documents:**\n",
    "- **Total tokens:** (sum of all document lengths after tokenization)\n",
    "- **Vocabulary size:** (unique tokens)\n",
    "\n",
    "**Missingness check:**\n",
    "\n",
    "| Field | Non-null Count | Missing Count | % Missing |\n",
    "|-------|----------------|---------------|-----------|\n",
    "| text | | | |\n",
    "| label | | | |\n",
    "\n",
    "> ðŸ’¡ **Note:** Established datasets rarely have missing values, but always verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea88c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dataset size and check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb802c0",
   "metadata": {},
   "source": [
    "### 3.2 Document Length Distribution\n",
    "\n",
    "**Required evidence:** \n",
    "1. A histogram or density plot of document lengths (in tokens or words)\n",
    "2. A percentile table\n",
    "\n",
    "| Statistic | Value (tokens) |\n",
    "|-----------|---------------|\n",
    "| Min | |\n",
    "| 25th percentile | |\n",
    "| Median | |\n",
    "| 75th percentile | |\n",
    "| Max | |\n",
    "| Mean | |\n",
    "| Std Dev | |\n",
    "\n",
    "**Interpretation (2-3 sentences):** What does this distribution tell you? Are there outliers? How might this affect model input length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of document lengths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your histogram code here\n",
    "# plt.xlabel(\"Document Length (tokens)\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Distribution of Document Lengths\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c673748",
   "metadata": {},
   "source": [
    "### 3.3 Label Distribution (Optional)\n",
    "\n",
    "**Required evidence:**\n",
    "1. A bar chart of label counts\n",
    "2. A table with counts and percentages\n",
    "\n",
    "| Label | Count | Percentage |\n",
    "|-------|-------|------------|\n",
    "| | | |\n",
    "| | | |\n",
    "| **Total** | | 100% |\n",
    "\n",
    "**Imbalance assessment:**\n",
    "- Majority class percentage: ____%\n",
    "- Is this dataset imbalanced? (Rule of thumb: >60% in one class = some imbalance; >80% = severe)\n",
    "\n",
    "**Interpretation (2-3 sentences):** What are the implications for model training and evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart of label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cf744",
   "metadata": {},
   "source": [
    "### 3.4 Data Quality Checks\n",
    "\n",
    "#### Duplicates\n",
    "\n",
    "- **Exact duplicates found:** ___\n",
    "- **Method used:** (e.g., `df.duplicated()`, hash-based)\n",
    "\n",
    "If duplicates exist, show 2-3 examples. If none, state \"No exact duplicates found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2661bfb",
   "metadata": {},
   "source": [
    "#### Outliers\n",
    "\n",
    "Identify documents that are unusually short or long:\n",
    "- **Very short documents** (bottom 1%): How many? Example?\n",
    "- **Very long documents** (top 1%): How many? Example?\n",
    "\n",
    "Should these be removed or kept? Justify your decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1cc43",
   "metadata": {},
   "source": [
    "#### Train/Test Overlap (if applicable)\n",
    "\n",
    "If your dataset has official train/test splits:\n",
    "- **Duplicate texts across splits:** ___ (this would be a serious problem!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for train/test overlap\n",
    "# train_texts = set(train_df['text'])\n",
    "# test_texts = set(test_df['text'])\n",
    "# overlap = train_texts.intersection(test_texts)\n",
    "# print(f\"Overlapping texts: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8addbef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Vocabulary Analysis\n",
    "\n",
    "*Understand what words and patterns appear in your corpus.*\n",
    "\n",
    "### 4.1 Top Terms by Frequency\n",
    "\n",
    "After your preprocessing (state whether stopwords were removed):\n",
    "\n",
    "**Top 20 Unigrams:**\n",
    "\n",
    "| Rank | Term | Count |\n",
    "|------|------|-------|\n",
    "| 1 | | |\n",
    "| 2 | | |\n",
    "| ... | | |\n",
    "\n",
    "**Top 10 Bigrams (optional but recommended):**\n",
    "\n",
    "| Rank | Bigram | Count |\n",
    "|------|--------|-------|\n",
    "| 1 | | |\n",
    "| ... | | |\n",
    "\n",
    "**Interpretation (3-5 sentences):** \n",
    "- Are the top terms what you expected for this domain?\n",
    "- Do you see any artifacts (HTML tags, encoding issues, boilerplate)?\n",
    "- Are there terms that might be predictive of labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bda585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top unigrams and bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716257e",
   "metadata": {},
   "source": [
    "### 4.1b Optional: Group Comparisons (only if a group column exists)\n",
    "\n",
    "If comparing groups (e.g., `group_field`):\n",
    "Report:\n",
    "\n",
    "* docs per group\n",
    "* avg/median token length per group\n",
    "* top terms per group with **per-1k normalization**\n",
    "\n",
    "**Required evidence:**\n",
    "\n",
    "* Group summary stats table\n",
    "* Per-group top-term tables (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group comparisons (if applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875bbad",
   "metadata": {},
   "source": [
    "### 4.2 Label-Specific Vocabulary (Optional, Though Insightful)\n",
    "\n",
    "Compare top terms across labels. What words appear frequently in one class but not others?\n",
    "\n",
    "| Term | Count (Label A) | Count (Label B) | Ratio |\n",
    "|------|-----------------|-----------------|-------|\n",
    "| | | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facff106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-specific vocabulary analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee27e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Summary\n",
    "\n",
    "### 5.1 Structural Facts (2â€“5 bullets)\n",
    "\n",
    "High level description of what this corpus is, how it's distributed, and what constraints.\n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "### 5.2 Anomalies/Surprises (2â€“5 bullets)\n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "### 5.3 Open Questions for Follow-up EDA (not modeling)\n",
    "\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38183683",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Reproducibility Checklist\n",
    "\n",
    "Before submitting, verify:\n",
    "\n",
    "- [ ] All code cells have been executed in order\n",
    "- [ ] No hardcoded file paths (use relative paths or download within notebook)\n",
    "- [ ] All required tables and plots are present\n",
    "- [ ] Interpretations are written in prose, not just code comments\n",
    "\n",
    "**Environment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell and include output\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "# Add other key packages\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# print(f\"pandas: {pd.__version__}\")\n",
    "# print(f\"numpy: {np.__version__}\")\n",
    "# print(f\"matplotlib: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b9e1e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission\n",
    "\n",
    "1. **File name:** `EDA_[YourName]_[Dataset].ipynb`\n",
    "2. **Ensure** the notebook runs top-to-bottom without errors. (Hint: restart and run all cells before submitting to be sure it runs.)\n",
    "3. Submit via Colab or Deepnote and share with instructor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe71826-6de3-4d9e-a5a4-aabac169a93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
