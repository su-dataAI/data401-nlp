{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labs\n",
    "\n",
    "> Shenandoah DATA-401 Intro to NLP Spring 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The course website is located [here](https://www.notion.so/Intro-to-Natural-Language-Processing-28b213a83886806982a5c03b425595c4?source=copy_link). Lecture materials, assignments, quizzes, etc. can be accessed at that link.\n",
    "\n",
    "This site contains jupyter notebooks, data and other code artifacts associated with this course. I recommend you run these notebooks in Google Colab since they are tested in that environment. However, you are free to download and run elsewhere.\n",
    "\n",
    "I will add further instructions for running locally or on some other environment if course-specific modules are needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Installation\n\n### For Students (Google Colab / Deepnote)\n\nThe easiest way to use this package is in Google Colab or Deepnote. In the first cell of your notebook, run:\n\n```python\n# Install the package with all NLP dependencies\n!pip install -q data401-nlp[all]\n\n# The spaCy model will be automatically downloaded when needed\nfrom data401_nlp.helpers.spacy import ensure_spacy_model\nnlp = ensure_spacy_model(\"en_core_web_sm\")\n```\n\n### For Local Development\n\nIf you want to run the notebooks locally:\n\n```bash\n# Clone the repository\ngit clone https://github.com/su-dataAI/data401-nlp.git\ncd data401-nlp\n\n# Install with all dependencies\npip install -e \".[dev,all]\"\n\n# Download spaCy model\npython -m spacy download en_core_web_sm\n\n# Start Jupyter Lab\njupyter lab\n```\n\n### Installation Options\n\nThe package supports flexible installation based on your needs:\n\n```bash\n# Minimal installation (core utilities only)\npip install data401-nlp\n\n# With NLP tools (spaCy, NLTK)\npip install data401-nlp[nlp]\n\n# With transformers and PyTorch\npip install data401-nlp[transformers]\n\n# With API support (FastAPI, Pydantic)\npip install data401-nlp[api]\n\n# Everything (recommended for students)\npip install data401-nlp[all]\n```\n\n### Platform Support\n\n✅ Google Colab  \n✅ Deepnote  \n✅ Jupyter Lab  \n✅ Local Python 3.11+\n\n### Helper Modules\n\nThe package includes several helper modules to make your NLP work easier:\n\n- `data401_nlp.helpers.env` - Environment detection and API key loading\n- `data401_nlp.helpers.spacy` - Automatic spaCy model management\n- `data401_nlp.helpers.submit` - Assignment submission utilities\n- `data401_nlp.helpers.llm` - LLM integration helpers",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Lab | Colab | GitHub | \n",
    "| ---- | ---- | ------ |\n",
    "| Intro (Jan 15) | [![Open In Colab](https://img.shields.io/badge/Open%20in%20Colab-blue?logo=google-colab&style=flat-square)](https://colab.research.google.com/github/su-dataAI/data401-nlp/blob/main/nbs/01-intro.ipynb) | [![Open In GitHub](https://img.shields.io/badge/Open%20in%20GitHub-gray?logo=github&style=flat-square)](https://github.com/su-dataAI/data401-nlp/blob/main/nbs/01-intro.ipynb) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solveit",
   "language": "python",
   "name": "solveit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}